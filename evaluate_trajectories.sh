#!/bin/bash
#
# Evaluate Generated Trajectories
#
# This script evaluates trajectories generated by all models
# against the test suites.
#
# Usage:
#   ./evaluate_trajectories.sh <output_base_dir> <f2p_file> <docker_image_prefix>
#
# Example:
#   ./evaluate_trajectories.sh outputs data/tasks.jsonl mswebench

set -e

# Configuration
OUTPUT_BASE=${1:-"outputs"}
F2P_FILE=${2:-"data/tasks.jsonl"}
DOCKER_PREFIX=${3:-"mswebench"}
TIMEOUT=600

# Models to evaluate
MODEL_NAMES=("Claude_Opus_4.6" "Kimi_2.5" "Qwen3_Coder" "GPT_4o")

# Change to VeloraHarness directory
cd "$(dirname "$0")/jaeger/VeloraHarness"
export PYTHONPATH="$(pwd):$PYTHONPATH"

# Set environment variables
export DOCKER_BUILDKIT=0
export EVAL_DOCKER_IMAGE_PREFIX=$DOCKER_PREFIX
export USE_INSTANCE_IMAGE=true

echo "========================================="
echo "Trajectory Evaluation Configuration"
echo "========================================="
echo "Output base: $OUTPUT_BASE"
echo "F2P file: $F2P_FILE"
echo "Docker prefix: $DOCKER_PREFIX"
echo "Timeout: ${TIMEOUT}s"
echo "Models: ${MODEL_NAMES[@]}"
echo "========================================="
echo

# Function to evaluate a model's trajectories
evaluate_model() {
    local model_name=$1
    local traj_dir="$OUTPUT_BASE/$model_name"
    local traj_file="$traj_dir/output.jsonl"

    if [ ! -f "$traj_file" ]; then
        echo "⚠ Skipping $model_name - trajectory file not found: $traj_file"
        return
    fi

    echo "========================================="
    echo "Evaluating: $model_name"
    echo "========================================="

    # Run evaluation
    poetry run python evaluation/velora3_eval_multilang.py \
        --trajectory-file "$traj_file" \
        --f2p-file "$F2P_FILE" \
        --output-file "$traj_dir/eval_output.jsonl" \
        --timeout $TIMEOUT \
        2>&1 | tee "$traj_dir/evaluation.log"

    echo "✓ Completed evaluation: $model_name"
    echo "  Results: $traj_dir/eval_output.jsonl"
    echo
}

# Evaluate all models
for model_name in "${MODEL_NAMES[@]}"; do
    evaluate_model "$model_name"
done

echo "========================================="
echo "All evaluations complete!"
echo "========================================="
echo
echo "Results summary:"
for model_name in "${MODEL_NAMES[@]}"; do
    eval_file="$OUTPUT_BASE/$model_name/eval_output.jsonl"
    if [ -f "$eval_file" ]; then
        resolved=$(grep -o '"resolved":true' "$eval_file" | wc -l || echo "0")
        total=$(wc -l < "$eval_file")
        echo "  $model_name: $resolved/$total resolved"
    fi
done
