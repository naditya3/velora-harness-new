###################### VeloraHarness Configuration ######################
#
# IMPORTANT: Add your actual API keys before running
# This file is included in the repository with placeholder keys
# for easier teammate setup
#
##########################################################################

#################################### Core ####################################
[core]
workspace_base = "./workspace"
cache_dir = "/tmp/cache"
max_iterations = 200
runtime = "docker"

#################################### LLM Configurations ##################################

[llm.gpt]
model = "gpt-5.1-2025-11-13"
api_key = "YOUR_OPENAI_API_KEY_HERE"  # ← ADD YOUR KEY
temperature = 0.2
max_input_tokens = 120000
max_output_tokens = 65536

[llm.claude]
model = "claude-sonnet-4-5-20250929"
api_key = "YOUR_ANTHROPIC_API_KEY_HERE"  # ← ADD YOUR KEY
temperature = 0.2
max_input_tokens = 120000
max_output_tokens = 65536

[llm.kimi]
model = "kimi-k2-thinking-turbo"
api_key = "YOUR_MOONSHOT_API_KEY_HERE"  # ← ADD YOUR KEY
base_url = "https://api.moonshot.cn/v1"
temperature = 0.2

[llm.qwen]
model = "qwen"
api_key = "YOUR_QWEN_API_KEY_HERE"  # ← ADD YOUR KEY
base_url = "YOUR_QWEN_ENDPOINT_HERE"
temperature = 0.2

# Gemini 3 Pro with High Reasoning Mode
# Docs: https://ai.google.dev/gemini-api/docs/thinking
[llm.gemini]
model = "gemini/gemini-3-pro-preview"
api_key = "REDACTED_GOOGLE_API_KEY"
max_input_tokens = 200000
max_output_tokens = 8192

[llm.gemini.completion_kwargs]
thinkingLevel = "high"

# GPT-5.2-codex with HIGH Reasoning Effort (Maximum available)
# Docs: https://platform.openai.com/docs/guides/reasoning
# Valid values: 'low', 'medium', 'high' ('xhigh' does NOT exist)
[llm.gpt_codex]
model = "gpt-5.2-codex"
api_key = "REDACTED_OPENAI_API_KEY"
reasoning_effort = "xhigh" # DISABLED FOR TESTING  # VALIDATED: xhigh is official GPT-5.2 feature (Dec 11, 2025)
temperature = 0.2
max_input_tokens = 120000
max_output_tokens = 65536
native_tool_calling = false  # Use mock function calling with Responses API
timeout = 7200  # 2 hours for reasoning calls
num_retries = 8
retry_min_wait = 15
retry_max_wait = 120
drop_params = true
log_completions = true
caching_prompt = true

#################################### Sandbox ###################################
[sandbox]
runtime_container_image = ""
timeout = 300
use_host_network = false
