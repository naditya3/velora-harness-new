###################### VeloraHarness Configuration ######################
#
# IMPORTANT: Copy this file to config.toml and add your actual API keys
# DO NOT commit config.toml - it is gitignored for security
#
# cp config.toml.example config.toml
# Then edit config.toml with your keys
#
##########################################################################

#################################### Core ####################################
[core]
workspace_base = "./workspace"
cache_dir = "/tmp/cache"
max_iterations = 200
runtime = "docker"

#################################### LLM Configurations ##################################

[llm.gpt]
model = "gpt-5.1-2025-11-13"
api_key = "YOUR_OPENAI_API_KEY_HERE"  # ← ADD YOUR KEY
temperature = 0.2
max_input_tokens = 120000
max_output_tokens = 65536

[llm.claude]
model = "claude-sonnet-4-5-20250929"
api_key = "YOUR_ANTHROPIC_API_KEY_HERE"  # ← ADD YOUR KEY
temperature = 0.2
max_input_tokens = 120000
max_output_tokens = 65536

[llm.kimi]
model = "kimi-k2-thinking-turbo"
api_key = "YOUR_MOONSHOT_API_KEY_HERE"  # ← ADD YOUR KEY
base_url = "https://api.moonshot.cn/v1"
temperature = 0.2

[llm.qwen]
model = "qwen"
api_key = "YOUR_QWEN_API_KEY_HERE"  # ← ADD YOUR KEY
base_url = "YOUR_QWEN_ENDPOINT_HERE"
temperature = 0.2

# Gemini 3 Pro with High Reasoning Mode (thinkingLevel=high)
# Docs: https://ai.google.dev/gemini-api/docs/thinking
# NOTE: Uses liteLLM path with thinking_blocks preservation for thought_signatures
# Rate limit handling: Gemini preview has strict RPM limits, use aggressive retries
[llm.gemini]
model = "gemini/gemini-3-pro-preview"
api_key = "YOUR_GOOGLE_API_KEY_HERE"  # ← ADD YOUR KEY
temperature = 1.0
timeout = 600  # 10 minutes for thinking-enabled calls
num_retries = 12  # More retries for rate limits
retry_min_wait = 30  # Start with 30s wait (rate limit typically resets in 60s)
retry_max_wait = 180  # Up to 3 minutes between retries

[llm.gemini.completion_kwargs]
thinkingLevel = "high"

# GPT-5.2-codex with Reasoning Effort
# Docs: https://platform.openai.com/docs/guides/reasoning
# Valid values: 'low', 'medium', 'high', 'xhigh'
[llm.gpt_codex]
model = "gpt-5.2-codex"
api_key = "YOUR_OPENAI_API_KEY_HERE"  # ← ADD YOUR KEY
reasoning_effort = "xhigh"
temperature = 1.0
native_tool_calling = false  # Use mock function calling with Responses API
timeout = 7200  # 2 hours for reasoning calls
num_retries = 8
retry_min_wait = 15
retry_max_wait = 120
drop_params = true
log_completions = true
caching_prompt = true

#################################### Sandbox ###################################
[sandbox]
runtime_container_image = ""
timeout = 300
use_host_network = false
