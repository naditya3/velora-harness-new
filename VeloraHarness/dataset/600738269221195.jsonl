{"instance_id": "600738269221195", "repo": "metomi/fab", "base_commit": "4649173903997440b7546eb495732602d5e0a492", "problem_statement": "Streamlining list of files for some stages:\\nOnce #280 is merged, I want to get rid of the many differences places from which files for compilation etc are being picked up. \\r\\nWhen I needed to introduce a new step before running PSyclone, I found it very hard to identify from which artefact stores to pick up files :( \\r\\n\\r\\nFirst issue: preprocessing Fortran files will copy .f90 files into the build directory, but does not add it to any artefact. So a new step has no easy way of finding all Fortran files!\\r\\n\\r\\nFollow up example (analysis)\\r\\n```\\r\\nDEFAULT_SOURCE_GETTER = CollectionConcat([\\r\\n    SuffixFilter('all_source', '.f90'),\\r\\n    'preprocessed_c',\\r\\n    'preprocessed_fortran',\\r\\n\\r\\n    # todo: this is lfric stuff so might be better placed elsewhere\\r\\n    SuffixFilter('psyclone_output', '.f90'),\\r\\n    'preprocessed_psyclone',  # todo: this is no longer a collection, remove\\r\\n    'configurator_output',\\r\\n])\\r\\n```\\r\\nSo this picks up a mixture of files from `all_source` (the aforementioned .f90 files that are copied but not added to an artefact), then the two preprocessed ones, then psyclone output files, and config output. Imho these files should be all in ONE artefact store.\\r\\n\\r\\nI don't mean necessary abandoning the stores we have, it might make sense to have all psyclone output files in one artefact (and ditto for cofigurator etc), but there should be a place where all f90 and all c files can be found - so that means in some cases to add files to more than one artefact store.\\r\\n\\r\\nThere are two obvious ways of implementing this:\\r\\n1. We just use some new custom artefact names, and no further code change. This is easy, what I don't like here is that we then need to import & use the name of these new stores\\r\\n2. We supply custom functions (which will internally use a custom name, but that name does not need to be exposed).\\r\\n\\r\\nFor now I have implemented the 2.nd way, but if you prefer 1. or something entirely different, I won't mind. Example:\\r\\n```\\r\\nclass ArtefactStore: \\r\\n...\\r\\n    def add_fortran_build_files(self, files: Union[str, List[str], Set[str]]):\\r\\n        self._add_files_to_artefact(self.FORTRAN_BUILD_FILES, files)\\r\\n\\r\\n    def get_fortran_build_files(self):\\r\\n        return self[self.FORTRAN_BUILD_FILES]\\r\\n\\r\\n    def add_c_build_files(self, files: Union[str, List[str], Set[str]]):\\r\\n        self._add_files_to_artefact(self.C_BUILD_FILES, files)\\r\\n\\r\\n    def add_x90_build_files(self, files: Union[str, List[str], Set[str]]):\\r\\n        self._add_files_to_artefact(self.X90_BUILD_FILES, files)\\r\\n...\\r\\n```\\r\\n\\r\\nSo, if for example the .f90 files are copied into the build tree, they will be added using `add_fortran_build_files`, and the analysis and compilation stage can just use `get_fortran_build_files` to get all files, as can custom steps (and they could e.g. remove and add files depending on what they do). No more need to pick files from three or four different places. \\r\\n\\r\\nPSyclone would add its output files to the fortran build files as well.\\r\\n\\r\\nAdditionally, as indicated in the comment of the analysis step above - psyclone is very LFRic-specific, so the code will be much easier to understand.", "FAIL_TO_PASS": ["tests/unit_tests/steps/test_link.py::TestLinkExe::test_run", "tests/unit_tests/steps/test_cleanup_prebuilds.py::TestCleanupPrebuilds::test_init_no_args"], "PASS_TO_PASS": ["tests/unit_tests/parse/test_x90.py::TestAnalysedX90::test_from_dict", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_gfortran_12", "tests/unit_tests/test_util.py::Test_input_to_output_fpath::test_vanilla", "tests/unit_tests/steps/test_compile_fortran.py::Test_get_compile_next::test_vanilla", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_command_failure", "tests/unit_tests/steps/test_compile_fortran.py::Test_constructor::test_ifort_managed_flags", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_ifort_19", "tests/unit_tests/steps/test_compile_fortran.py::Test_get_compile_next::test_unable_to_compile_anything", "tests/unit_tests/test_util.py::Test_input_to_output_fpath::test_already_output", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_eq_different_module_defs", "tests/unit_tests/steps/test_compile_fortran.py::Test_constructor::test_gfortran_managed_flags", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_hash_different_psyclone_kernels", "tests/system_tests/svn_fcm/test_svn_fcm_system_test.py::TestCheckout::test_working_copy[svn_checkout]", "tests/unit_tests/steps/test_psyclone_unit_test.py::Test_check_override::test_override", "tests/unit_tests/test_tools.py::Test_remove_managed_flags::test_ifort", "tests/unit_tests/steps/test_compile_fortran.py::Test_constructor::test_no_compiler", "tests/unit_tests/steps/test_grab.py::TestGrabFcm::test_revision", "tests/unit_tests/test_util.py::TestSuffixFilter::test_constructor_suffix_vector", "tests/unit_tests/parse/test_init.py::TestAnalysedFile::test_hash_different_fpath", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_gfortran_10", "tests/unit_tests/steps/test_analyse.py::Test_add_manual_results::test_vanilla", "tests/unit_tests/steps/grab/test_svn_fcm_unit_test.py::TestRevision::test_url_revision", "tests/unit_tests/steps/test_analyse.py::Test_gen_symbol_table::test_duplicate_symbol", "tests/unit_tests/steps/test_psyclone_unit_test.py::Test_gen_prebuild_hash::test_trans_script", "tests/unit_tests/steps/grab/test_svn_fcm_unit_test.py::TestRevision::test_revision_param", "tests/unit_tests/steps/test_analyse.py::Test_add_unreferenced_deps::test_vanilla", "tests/system_tests/grab_archive/test_grab_archive.py::TestGrabArchive::test", "tests/unit_tests/steps/test_grab.py::TestGrabFolder::test_trailing_slash", "tests/unit_tests/test_util.py::Test_suffix_filter::test_vanilla", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_to_dict", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_hash_different_module_deps", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_hash_different_symbol_defs", "tests/unit_tests/parse/fortran/test_typed_child.py::Test_typed_child::test_false", "tests/unit_tests/parse/test_x90.py::TestAnalysedX90::test_save_load", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_to_dict", "tests/unit_tests/steps/test_analyse.py::Test_gen_symbol_table::test_vanilla", "tests/unit_tests/steps/test_compile_fortran.py::Test_get_fortran_compiler::test_empty_env_ifort", "tests/system_tests/svn_fcm/test_svn_fcm_system_test.py::TestCheckout::test_not_working_copy[svn_export-svn_checkout]", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_add_module_dep", "tests/unit_tests/parse/test_init.py::TestAnalysedFile::test_hash_different_file_hash", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_from_dict", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_eq_different_symbol_defs", "tests/system_tests/svn_fcm/test_svn_fcm_system_test.py::TestMerge::test_revision[svn_checkout-svn_merge]", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_ifort_17", "tests/unit_tests/steps/test_compile_fortran.py::Test_store_artefacts::test_vanilla", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_eq_different_file_deps", "tests/unit_tests/parse/test_init.py::TestAnalysedFile::test_eq", "tests/unit_tests/test_util.py::Test_file_walk::test_ignore", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_eq_different_mo_commented_file_deps", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_unknown_command_response", "tests/system_tests/svn_fcm/test_svn_fcm_system_test.py::TestMerge::test_vanilla[svn_checkout-svn_merge]", "tests/unit_tests/parse/fortran/test_typed_child.py::Test_typed_child::test_true", "tests/system_tests/svn_fcm/test_svn_fcm_system_test.py::TestMerge::test_not_working_copy[svn_export-svn_merge]", "tests/unit_tests/steps/test_analyse.py::Test_gen_file_deps::test_vanilla", "tests/unit_tests/test_tools.py::Test_run_command::test_error", "tests/unit_tests/steps/grab/test_svn_fcm_unit_test.py::TestRevision::test_both_different", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_mod_filenames", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_add_symbol_dep", "tests/unit_tests/steps/test_cleanup_prebuilds.py::TestCleanupPrebuilds::test_by_age_current", "tests/unit_tests/test_tools.py::Test_remove_managed_flags::test_unknown_compiler", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_ifort_15", "tests/unit_tests/steps/test_c_pragma_injector.py::Test_inject_pragmas::test_vanilla", "tests/unit_tests/parse/test_c.py::TestAnalysedC::test_save_load", "tests/unit_tests/test_artefacts.py::TestFilterBuildTrees::test_multiple_suffixes", "tests/unit_tests/parse/fortran/test_has_ancestor_type.py::Test_has_ancestor_type::test_false", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_gfortran_4", "tests/unit_tests/parse/test_init.py::TestAnalysedFile::test_eq_different_fpath", "tests/unit_tests/steps/test_compile_fortran.py::Test_get_fortran_preprocessor::test_empty_env_fpp", "tests/unit_tests/steps/test_cleanup_prebuilds.py::test_get_prebuild_file_groups", "tests/unit_tests/test_tools.py::Test_remove_managed_flags::test_gfortran", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_hash", "tests/unit_tests/steps/test_psyclone_unit_test.py::Test_check_override::test_no_override", "tests/unit_tests/steps/test_compile_fortran.py::Test_get_fortran_compiler::test_from_env", "tests/unit_tests/parse/test_x90.py::TestAnalysedX90::test_hash", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_ifort_14", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_eq_different_symbol_deps", "tests/system_tests/svn_fcm/test_svn_fcm_system_test.py::TestCheckout::test_new_folder[svn_checkout]", "tests/unit_tests/test_tools.py::Test_flags_checksum::test_vanilla", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_eq", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_add_symbol_def", "tests/unit_tests/test_util.py::Test_input_to_output_fpath::test_outside_project", "tests/unit_tests/parse/fortran/test_iter_content.py::Test_iter_content::test_deep", "tests/unit_tests/test_build_config.py::TestBuildConfig::test_error_newlines", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_hash_different_module_defs", "tests/unit_tests/steps/test_compile_fortran.py::Test_constructor::test_unknown_compiler", "tests/unit_tests/steps/test_compile_fortran.py::Test_constructor::test_with_flags", "tests/unit_tests/steps/grab/test_svn_fcm_unit_test.py::TestRevision::test_no_revision", "tests/unit_tests/parse/fortran/test_has_ancestor_type.py::Test_has_ancestor_type::test_true", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_eq_different_module_deps", "tests/unit_tests/steps/test_cleanup_prebuilds.py::TestCleanupPrebuilds::test_by_version_age_current", "tests/unit_tests/test_tools.py::Test_run_command::test_no_error", "tests/unit_tests/parse/fortran/test_fortran_analyser.py::Test_process_variable_binding::test_define_without_bind_name", "tests/unit_tests/steps/test_steps.py::Test_check_for_errors::test_error", "tests/system_tests/svn_fcm/test_svn_fcm_system_test.py::TestExport::test_export[svn_export]", "tests/unit_tests/steps/test_psyclone_unit_test.py::Test_gen_prebuild_hash::test_cli_args", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_add_module_def", "tests/unit_tests/parse/fortran/test_iter_content.py::Test_iter_content::test_empty", "tests/unit_tests/steps/test_psyclone_unit_test.py::Test_gen_prebuild_hash::test_kernal_deps", "tests/unit_tests/steps/test_compile_fortran.py::Test_constructor::test_bare", "tests/unit_tests/steps/test_compile_fortran.py::Test_get_fortran_compiler::test_empty_env_gfortran", "tests/unit_tests/steps/test_cleanup_prebuilds.py::TestCleanupPrebuilds::test_by_version_age", "tests/unit_tests/parse/test_x90.py::TestAnalysedX90::test_hash_different_kernel_deps", "tests/unit_tests/steps/test_cleanup_prebuilds.py::TestCleanupPrebuilds::test_by_age", "tests/system_tests/svn_fcm/test_svn_fcm_system_test.py::TestMerge::test_multiple_merges[svn_checkout-svn_merge]", "tests/unit_tests/parse/test_init.py::TestAnalysedFile::test_hash", "tests/unit_tests/steps/test_psyclone_unit_test.py::Test_gen_prebuild_hash::test_vanilla", "tests/unit_tests/steps/test_cleanup_prebuilds.py::TestCleanupPrebuilds::test_init_bad_args", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_save_load", "tests/unit_tests/steps/test_compile_fortran.py::Test_get_fortran_preprocessor::test_empty_env_cpp", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_hash_different_file_deps", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_hash_different_mo_commented_file_deps", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_add_file_dep", "tests/unit_tests/steps/test_compile_fortran.py::Test_get_fortran_preprocessor::test_from_env", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_2_part_version", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_eq", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_unknown_version_format", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_hash", "tests/unit_tests/steps/test_psyclone_unit_test.py::Test_gen_prebuild_hash::test_file_hash", "tests/unit_tests/test_util.py::TestCollectionConcat::test_vanilla", "tests/unit_tests/parse/fortran/test_iter_content.py::Test_iter_content::test_vanilla", "tests/unit_tests/test_util.py::TestSuffixFilter::test_constructor_suffix_scalar", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_gfortran_8", "tests/unit_tests/steps/test_cleanup_prebuilds.py::test_remove_all_unused", "tests/unit_tests/parse/fortran/test_fortran.py::TestAnalysedFortran::test_eq_different_psyclone_kernels", "tests/unit_tests/steps/test_steps.py::Test_check_for_errors::test_no_error", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_from_dict", "tests/unit_tests/parse/test_init.py::TestAnalysedFile::test_eq_different_file_hash", "tests/unit_tests/parse/test_x90.py::TestAnalysedX90::test_eq_different_kernel_deps", "tests/unit_tests/parse/test_x90.py::TestAnalysedX90::test_to_dict", "tests/unit_tests/parse/test_init.py::TestAnalysedDependent::test_hash_different_symbol_deps", "tests/unit_tests/test_artefacts.py::TestFilterBuildTrees::test_single_suffix", "tests/unit_tests/test_tools.py::Test_get_compiler_version::test_gfortran_6", "tests/unit_tests/steps/test_grab.py::TestGrabFcm::test_no_revision", "tests/unit_tests/test_dep_tree.py::Test_extract_sub_tree::test_vanilla", "tests/unit_tests/parse/test_init.py::TestAnalysedFile::test_to_dict", "tests/system_tests/svn_fcm/test_svn_fcm_system_test.py::TestMerge::test_conflict[svn_checkout-svn_merge]", "tests/unit_tests/steps/grab/test_svn_fcm_unit_test.py::TestRevision::test_both_matching", "tests/unit_tests/parse/test_x90.py::TestAnalysedX90::test_eq", "tests/unit_tests/steps/test_grab.py::TestGrabFolder::test_no_trailing_slash"], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/metomi_fab:4649173903997440b7546eb495732602d5e0a492", "patch": "[\"diff --git a/docs/source/advanced_config.rst b/docs/source/advanced_config.rst\\nindex 0e8a04d..0babf82 100644\\n--- a/docs/source/advanced_config.rst\\n+++ b/docs/source/advanced_config.rst\\n@@ -315,7 +315,7 @@ which most Fab steps accept. (See :ref:`Overriding default collections`)\\n \\n     @step\\n     def custom_step(state):\\n-            state._artefact_store['custom_artefacts'] = do_something(state._artefact_store['step 1 artefacts'])\\n+        state.artefact_store['custom_artefacts'] = do_something(state.artefact_store['step 1 artefacts'])\\n \\n \\n     with BuildConfig(project_label='<project label>') as state:\\n@@ -332,7 +332,7 @@ Steps have access to multiprocessing methods through the\\n \\n     @step\\n     def custom_step(state):\\n-        input_files = artefact_store['custom_artefacts']\\n+        input_files = state.artefact_store['custom_artefacts']\\n         results = run_mp(state, items=input_files, func=do_something)\\n \\n \\n\",\"diff --git a/source/fab/artefacts.py b/source/fab/artefacts.py\\nindex 7953f94..0749e78 100644\\n--- a/source/fab/artefacts.py\\n+++ b/source/fab/artefacts.py\\n@@ -15,7 +15,7 @@ from abc import ABC, abstractmethod\\n from pathlib import Path\\n from typing import Iterable, Union, Dict, List\\n \\n-from fab.constants import BUILD_TREES\\n+from fab.constants import BUILD_TREES, CURRENT_PREBUILDS\\n from fab.dep_tree import filter_source_tree, AnalysedDependent\\n from fab.util import suffix_filter\\n \\n@@ -32,7 +32,8 @@ class ArtefactsGetter(ABC):\\n             The artefact store from which to retrieve.\\n \\n         \\\"\\\"\\\"\\n-        pass\\n+        raise NotImplementedError(f\\\"__call__ must be implemented for \\\"\\n+                                  f\\\"'{type(self).__name__}'.\\\")\\n \\n \\n class CollectionGetter(ArtefactsGetter):\\n@@ -53,7 +54,6 @@ class CollectionGetter(ArtefactsGetter):\\n         self.collection_name = collection_name\\n \\n     def __call__(self, artefact_store):\\n-        super().__call__(artefact_store)\\n         return artefact_store.get(self.collection_name, [])\\n \\n \\n@@ -84,7 +84,6 @@ class CollectionConcat(ArtefactsGetter):\\n \\n     # todo: ensure the labelled values are iterables\\n     def __call__(self, artefact_store: Dict):\\n-        super().__call__(artefact_store)\\n         # todo: this should be a set, in case a file appears in multiple collections\\n         result = []\\n         for collection in self.collections:\\n@@ -118,7 +117,6 @@ class SuffixFilter(ArtefactsGetter):\\n         self.suffixes = [suffix] if isinstance(suffix, str) else suffix\\n \\n     def __call__(self, artefact_store):\\n-        super().__call__(artefact_store)\\n         # todo: returning an empty list is probably \\\"dishonest\\\" if the collection doesn't exist - return None instead?\\n         fpaths: Iterable[Path] = artefact_store.get(self.collection_name, [])\\n         return suffix_filter(fpaths, self.suffixes)\\n@@ -149,7 +147,6 @@ class FilterBuildTrees(ArtefactsGetter):\\n         self.suffixes = [suffix] if isinstance(suffix, str) else suffix\\n \\n     def __call__(self, artefact_store):\\n-        super().__call__(artefact_store)\\n \\n         build_trees = artefact_store[self.collection_name]\\n \\n@@ -158,3 +155,18 @@ class FilterBuildTrees(ArtefactsGetter):\\n             build_lists[root] = filter_source_tree(source_tree=tree, suffixes=self.suffixes)\\n \\n         return build_lists\\n+\\n+\\n+class ArtefactStore(dict):\\n+    '''This object stores artefacts (which can be of any type). Each artefact\\n+    is indexed by a string.\\n+    '''\\n+    def __init__(self):\\n+        super().__init__()\\n+        self.reset()\\n+\\n+    def reset(self):\\n+        '''Clears the artefact store (but does not delete any files).\\n+        '''\\n+        self.clear()\\n+        self[CURRENT_PREBUILDS] = set()\\n\",\"diff --git a/source/fab/build_config.py b/source/fab/build_config.py\\nindex ecaa660..bddb670 100644\\n--- a/source/fab/build_config.py\\n+++ b/source/fab/build_config.py\\n@@ -18,16 +18,18 @@ from logging.handlers import RotatingFileHandler\\n from multiprocessing import cpu_count\\n from pathlib import Path\\n from string import Template\\n-from typing import List, Optional, Dict, Any, Iterable\\n+from typing import List, Optional, Iterable\\n \\n+from fab.artefacts import ArtefactStore\\n from fab.constants import BUILD_OUTPUT, SOURCE_ROOT, PREBUILD, CURRENT_PREBUILDS\\n from fab.metrics import send_metric, init_metrics, stop_metrics, metrics_summary\\n+from fab.steps.cleanup_prebuilds import CLEANUP_COUNT, cleanup_prebuilds\\n from fab.util import TimerLogger, by_type, get_fab_workspace\\n \\n logger = logging.getLogger(__name__)\\n \\n \\n-class BuildConfig(object):\\n+class BuildConfig():\\n     \\\"\\\"\\\"\\n     Contains and runs a list of build steps.\\n \\n@@ -105,9 +107,10 @@ class BuildConfig(object):\\n \\n         # todo: should probably pull the artefact store out of the config\\n         # runtime\\n-        # todo: either make this public, add get/setters, or extract into a class.\\n-        self._artefact_store: Dict[str, Any] = {}\\n-        self.init_artefact_store()  # note: the artefact store is reset with every call to run()\\n+        self._artefact_store = ArtefactStore()\\n+\\n+        self._build_timer = None\\n+        self._start_time = None\\n \\n     def __enter__(self):\\n \\n@@ -130,8 +133,7 @@ class BuildConfig(object):\\n     def __exit__(self, exc_type, exc_val, exc_tb):\\n \\n         if not exc_type:  # None if there's no error.\\n-            from fab.steps.cleanup_prebuilds import CLEANUP_COUNT, cleanup_prebuilds\\n-            if CLEANUP_COUNT not in self._artefact_store:\\n+            if CLEANUP_COUNT not in self.artefact_store:\\n                 logger.info(\\\"no housekeeping step was run, using a default hard cleanup\\\")\\n                 cleanup_prebuilds(config=self, all_unused=True)\\n \\n@@ -142,19 +144,23 @@ class BuildConfig(object):\\n         self._finalise_logging()\\n \\n     @property\\n-    def build_output(self):\\n-        return self.project_workspace / BUILD_OUTPUT\\n+    def artefact_store(self) -> ArtefactStore:\\n+        ''':returns: the Artefact instance for this configuration.\\n+        '''\\n+        return self._artefact_store\\n \\n-    def init_artefact_store(self):\\n-        # there's no point writing to this from a child process of Step.run_mp() because you'll be modifying a copy.\\n-        self._artefact_store = {CURRENT_PREBUILDS: set()}\\n+    @property\\n+    def build_output(self) -> Path:\\n+        ''':returns: the build output path.\\n+        '''\\n+        return self.project_workspace / BUILD_OUTPUT\\n \\n     def add_current_prebuilds(self, artefacts: Iterable[Path]):\\n         \\\"\\\"\\\"\\n         Mark the given file paths as being current prebuilds, not to be cleaned during housekeeping.\\n \\n         \\\"\\\"\\\"\\n-        self._artefact_store[CURRENT_PREBUILDS].update(artefacts)\\n+        self.artefact_store[CURRENT_PREBUILDS].update(artefacts)\\n \\n     def _run_prep(self):\\n         self._init_logging()\\n@@ -168,7 +174,7 @@ class BuildConfig(object):\\n         init_metrics(metrics_folder=self.metrics_folder)\\n \\n         # note: initialising here gives a new set of artefacts each run\\n-        self.init_artefact_store()\\n+        self.artefact_store.reset()\\n \\n     def _prep_folders(self):\\n         self.source_root.mkdir(parents=True, exist_ok=True)\\n@@ -210,7 +216,7 @@ class BuildConfig(object):\\n \\n \\n # todo: better name? perhaps PathFlags?\\n-class AddFlags(object):\\n+class AddFlags():\\n     \\\"\\\"\\\"\\n     Add command-line flags when our path filter matches.\\n     Generally used inside a :class:`~fab.build_config.FlagsConfig`.\\n@@ -265,14 +271,13 @@ class AddFlags(object):\\n             input_flags += add_flags\\n \\n \\n-class FlagsConfig(object):\\n+class FlagsConfig():\\n     \\\"\\\"\\\"\\n     Return command-line flags for a given path.\\n \\n     Simply allows appending flags but may evolve to also replace and remove flags.\\n \\n     \\\"\\\"\\\"\\n-\\n     def __init__(self, common_flags: Optional[List[str]] = None, path_flags: Optional[List[AddFlags]] = None):\\n         \\\"\\\"\\\"\\n         :param common_flags:\\n\",\"diff --git a/source/fab/parse/fortran_common.py b/source/fab/parse/fortran_common.py\\nindex bc6aa97..f35c243 100644\\n--- a/source/fab/parse/fortran_common.py\\n+++ b/source/fab/parse/fortran_common.py\\n@@ -134,8 +134,6 @@ class FortranAnalyserBase(ABC):\\n \\n         # find things in the node tree\\n         analysed_file = self.walk_nodes(fpath=fpath, file_hash=file_hash, node_tree=node_tree)\\n-\\n-        analysis_fpath = self._get_analysis_fpath(fpath, file_hash)\\n         analysed_file.save(analysis_fpath)\\n \\n         return analysed_file, analysis_fpath\\n\",\"diff --git a/source/fab/steps/analyse.py b/source/fab/steps/analyse.py\\nindex 84dc39b..26c6cdc 100644\\n--- a/source/fab/steps/analyse.py\\n+++ b/source/fab/steps/analyse.py\\n@@ -167,7 +167,7 @@ def analyse(\\n     c_analyser._config = config\\n \\n     # parse\\n-    files: List[Path] = source_getter(config._artefact_store)\\n+    files: List[Path] = source_getter(config.artefact_store)\\n     analysed_files = _parse_files(config, files=files, fortran_analyser=fortran_analyser, c_analyser=c_analyser)\\n     _add_manual_results(special_measure_analysis_results, analysed_files)\\n \\n@@ -206,7 +206,7 @@ def analyse(\\n         _add_unreferenced_deps(unreferenced_deps, symbol_table, project_source_tree, build_tree)\\n         validate_dependencies(build_tree)\\n \\n-    config._artefact_store[BUILD_TREES] = build_trees\\n+    config.artefact_store[BUILD_TREES] = build_trees\\n \\n \\n def _analyse_dependencies(analysed_files: Iterable[AnalysedDependent]):\\n\",\"diff --git a/source/fab/steps/archive_objects.py b/source/fab/steps/archive_objects.py\\nindex d308ee2..c450af4 100644\\n--- a/source/fab/steps/archive_objects.py\\n+++ b/source/fab/steps/archive_objects.py\\n@@ -95,14 +95,14 @@ def archive_objects(config: BuildConfig, source: Optional[ArtefactsGetter] = Non\\n     output_fpath = str(output_fpath) if output_fpath else None\\n     output_collection = output_collection\\n \\n-    target_objects = source_getter(config._artefact_store)\\n+    target_objects = source_getter(config.artefact_store)\\n     assert target_objects.keys()\\n     if output_fpath and list(target_objects.keys()) != [None]:\\n         raise ValueError(\\\"You must not specify an output path (library) when there are root symbols (exes)\\\")\\n     if not output_fpath and list(target_objects.keys()) == [None]:\\n         raise ValueError(\\\"You must specify an output path when building a library.\\\")\\n \\n-    output_archives = config._artefact_store.setdefault(output_collection, {})\\n+    output_archives = config.artefact_store.setdefault(output_collection, {})\\n     for root, objects in target_objects.items():\\n \\n         if root:\\n\",\"diff --git a/source/fab/steps/c_pragma_injector.py b/source/fab/steps/c_pragma_injector.py\\nindex a79431c..d30321d 100644\\n--- a/source/fab/steps/c_pragma_injector.py\\n+++ b/source/fab/steps/c_pragma_injector.py\\n@@ -43,9 +43,9 @@ def c_pragma_injector(config, source: Optional[ArtefactsGetter] = None, output_n\\n     source_getter = source or DEFAULT_SOURCE_GETTER\\n     output_name = output_name or PRAGMAD_C\\n \\n-    files = source_getter(config._artefact_store)\\n+    files = source_getter(config.artefact_store)\\n     results = run_mp(config, items=files, func=_process_artefact)\\n-    config._artefact_store[output_name] = list(results)\\n+    config.artefact_store[output_name] = list(results)\\n \\n \\n def _process_artefact(fpath: Path):\\n\",\"diff --git a/source/fab/steps/cleanup_prebuilds.py b/source/fab/steps/cleanup_prebuilds.py\\nindex e62120d..8d1548b 100644\\n--- a/source/fab/steps/cleanup_prebuilds.py\\n+++ b/source/fab/steps/cleanup_prebuilds.py\\n@@ -63,7 +63,7 @@ def cleanup_prebuilds(\\n \\n     elif all_unused:\\n         num_removed = remove_all_unused(\\n-            found_files=prebuild_files, current_files=config._artefact_store[CURRENT_PREBUILDS])\\n+            found_files=prebuild_files, current_files=config.artefact_store[CURRENT_PREBUILDS])\\n \\n     else:\\n         # get the file access time for every artefact\\n@@ -71,15 +71,15 @@ def cleanup_prebuilds(\\n             dict(zip(prebuild_files, run_mp(config, prebuild_files, get_access_time)))  # type: ignore\\n \\n         # work out what to delete\\n-        to_delete = by_age(older_than, prebuilds_ts, current_files=config._artefact_store[CURRENT_PREBUILDS])\\n-        to_delete |= by_version_age(n_versions, prebuilds_ts, current_files=config._artefact_store[CURRENT_PREBUILDS])\\n+        to_delete = by_age(older_than, prebuilds_ts, current_files=config.artefact_store[CURRENT_PREBUILDS])\\n+        to_delete |= by_version_age(n_versions, prebuilds_ts, current_files=config.artefact_store[CURRENT_PREBUILDS])\\n \\n         # delete them all\\n         run_mp(config, to_delete, os.remove)\\n         num_removed = len(to_delete)\\n \\n     logger.info(f'removed {num_removed} prebuild files')\\n-    config._artefact_store[CLEANUP_COUNT] = num_removed\\n+    config.artefact_store[CLEANUP_COUNT] = num_removed\\n \\n \\n def by_age(older_than: Optional[timedelta],\\n\",\"diff --git a/source/fab/steps/compile_c.py b/source/fab/steps/compile_c.py\\nindex 09f1eee..ba2be4d 100644\\n--- a/source/fab/steps/compile_c.py\\n+++ b/source/fab/steps/compile_c.py\\n@@ -83,7 +83,7 @@ def compile_c(config, common_flags: Optional[List[str]] = None,\\n     source_getter = source or DEFAULT_SOURCE_GETTER\\n \\n     # gather all the source to compile, for all build trees, into one big lump\\n-    build_lists: Dict = source_getter(config._artefact_store)\\n+    build_lists: Dict = source_getter(config.artefact_store)\\n     to_compile: list = sum(build_lists.values(), [])\\n     logger.info(f\\\"compiling {len(to_compile)} c files\\\")\\n \\n@@ -101,7 +101,7 @@ def compile_c(config, common_flags: Optional[List[str]] = None,\\n     config.add_current_prebuilds(prebuild_files)\\n \\n     # record the compilation results for the next step\\n-    store_artefacts(compiled_c, build_lists, config._artefact_store)\\n+    store_artefacts(compiled_c, build_lists, config.artefact_store)\\n \\n \\n # todo: very similar code in fortran compiler\\n\",\"diff --git a/source/fab/steps/compile_fortran.py b/source/fab/steps/compile_fortran.py\\nindex f84e71f..706e598 100644\\n--- a/source/fab/steps/compile_fortran.py\\n+++ b/source/fab/steps/compile_fortran.py\\n@@ -84,7 +84,7 @@ def compile_fortran(config: BuildConfig, common_flags: Optional[List[str]] = Non\\n     mod_hashes: Dict[str, int] = {}\\n \\n     # get all the source to compile, for all build trees, into one big lump\\n-    build_lists: Dict[str, List] = source_getter(config._artefact_store)\\n+    build_lists: Dict[str, List] = source_getter(config.artefact_store)\\n \\n     # build the arguments passed to the multiprocessing function\\n     mp_common_args = MpCommonArgs(\\n@@ -119,7 +119,7 @@ def compile_fortran(config: BuildConfig, common_flags: Optional[List[str]] = Non\\n         logger.info(f\\\"stage 2 compiled {len(compiled_this_pass)} files\\\")\\n \\n     # record the compilation results for the next step\\n-    store_artefacts(compiled, build_lists, config._artefact_store)\\n+    store_artefacts(compiled, build_lists, config.artefact_store)\\n \\n \\n def handle_compiler_args(common_flags=None, path_flags=None):\\n\",\"diff --git a/source/fab/steps/find_source_files.py b/source/fab/steps/find_source_files.py\\nindex 0e417cc..25191d5 100644\\n--- a/source/fab/steps/find_source_files.py\\n+++ b/source/fab/steps/find_source_files.py\\n@@ -145,4 +145,4 @@ def find_source_files(config, source_root=None, output_collection=\\\"all_source\\\",\\n     if not filtered_fpaths:\\n         raise RuntimeError(\\\"no source files found after filtering\\\")\\n \\n-    config._artefact_store[output_collection] = filtered_fpaths\\n+    config.artefact_store[output_collection] = filtered_fpaths\\n\",\"diff --git a/source/fab/steps/link.py b/source/fab/steps/link.py\\nindex f44275a..571ff6b 100644\\n--- a/source/fab/steps/link.py\\n+++ b/source/fab/steps/link.py\\n@@ -78,11 +78,11 @@ def link_exe(config, linker: Optional[str] = None, flags=None, source: Optional[\\n     flags = flags or []\\n     source_getter = source or DefaultLinkerSource()\\n \\n-    target_objects = source_getter(config._artefact_store)\\n+    target_objects = source_getter(config.artefact_store)\\n     for root, objects in target_objects.items():\\n         exe_path = config.project_workspace / f'{root}'\\n         call_linker(linker=linker, flags=flags, filename=str(exe_path), objects=objects)\\n-        config._artefact_store.setdefault(EXECUTABLES, []).append(exe_path)\\n+        config.artefact_store.setdefault(EXECUTABLES, []).append(exe_path)\\n \\n \\n # todo: the bit about Dict[None, object_files] seems too obscure - try to rethink this.\\n@@ -123,7 +123,7 @@ def link_shared_object(config, output_fpath: str, linker: Optional[str] = None, \\n             flags.append(f)\\n \\n     # We expect a single build target containing the whole codebase, with no name (as it's not a root symbol).\\n-    target_objects = source_getter(config._artefact_store)\\n+    target_objects = source_getter(config.artefact_store)\\n     assert list(target_objects.keys()) == [None]\\n \\n     objects = target_objects[None]\\n\",\"diff --git a/source/fab/steps/preprocess.py b/source/fab/steps/preprocess.py\\nindex 08d6594..ffc3d40 100644\\n--- a/source/fab/steps/preprocess.py\\n+++ b/source/fab/steps/preprocess.py\\n@@ -88,7 +88,7 @@ def pre_processor(config: BuildConfig, preprocessor: str,\\n     check_for_errors(results, caller_label=name)\\n \\n     log_or_dot_finish(logger)\\n-    config._artefact_store[output_collection] = list(by_type(results, Path))\\n+    config.artefact_store[output_collection] = list(by_type(results, Path))\\n \\n \\n def process_artefact(arg: Tuple[Path, MpCommonArgs]):\\n@@ -192,7 +192,7 @@ def preprocess_fortran(config: BuildConfig, source: Optional[ArtefactsGetter] = \\n \\n     \\\"\\\"\\\"\\n     source_getter = source or SuffixFilter('all_source', ['.F90', '.f90'])\\n-    source_files = source_getter(config._artefact_store)\\n+    source_files = source_getter(config.artefact_store)\\n     F90s = suffix_filter(source_files, '.F90')\\n     f90s = suffix_filter(source_files, '.f90')\\n \\n@@ -257,7 +257,7 @@ def preprocess_c(config: BuildConfig, source=None, **kwargs):\\n \\n     \\\"\\\"\\\"\\n     source_getter = source or DefaultCPreprocessorSource()\\n-    source_files = source_getter(config._artefact_store)\\n+    source_files = source_getter(config.artefact_store)\\n \\n     pre_processor(\\n         config,\\n\",\"diff --git a/source/fab/steps/psyclone.py b/source/fab/steps/psyclone.py\\nindex eec88a0..d7b1cdb 100644\\n--- a/source/fab/steps/psyclone.py\\n+++ b/source/fab/steps/psyclone.py\\n@@ -50,7 +50,7 @@ def preprocess_x90(config, common_flags: Optional[List[str]] = None):\\n         if fpp_flag not in common_flags:\\n             common_flags.append(fpp_flag)\\n \\n-    source_files = SuffixFilter('all_source', '.X90')(config._artefact_store)\\n+    source_files = SuffixFilter('all_source', '.X90')(config.artefact_store)\\n \\n     pre_processor(\\n         config,\\n@@ -132,7 +132,7 @@ def psyclone(config, kernel_roots: Optional[List[Path]] = None,\\n     source_getter = source_getter or DEFAULT_SOURCE_GETTER\\n     overrides_folder = overrides_folder\\n \\n-    x90s = source_getter(config._artefact_store)\\n+    x90s = source_getter(config.artefact_store)\\n \\n     # get the data for child processes to calculate prebuild hashes\\n     prebuild_analyses = _analysis_for_prebuilds(config, x90s, transformation_script, kernel_roots)\\n@@ -153,7 +153,7 @@ def psyclone(config, kernel_roots: Optional[List[Path]] = None,\\n     prebuild_files: List[Path] = list(chain(*by_type(prebuilds, List)))\\n \\n     # record the output files in the artefact store for further processing\\n-    config._artefact_store['psyclone_output'] = output_files\\n+    config.artefact_store['psyclone_output'] = output_files\\n     outputs_str = \\\"\\\\n\\\".join(map(str, output_files))\\n     logger.debug(f'psyclone outputs:\\\\n{outputs_str}\\\\n')\\n \\n\",\"diff --git a/source/fab/steps/root_inc_files.py b/source/fab/steps/root_inc_files.py\\nindex 6dbbc64..2bc9999 100644\\n--- a/source/fab/steps/root_inc_files.py\\n+++ b/source/fab/steps/root_inc_files.py\\n@@ -47,7 +47,7 @@ def root_inc_files(config):\\n \\n     # inc files all go in the root - they're going to be removed altogether, soon\\n     inc_copied = set()\\n-    for fpath in suffix_filter(config._artefact_store[\\\"all_source\\\"], [\\\".inc\\\"]):\\n+    for fpath in suffix_filter(config.artefact_store[\\\"all_source\\\"], [\\\".inc\\\"]):\\n \\n         # don't copy from the output root to the output root!\\n         # this is currently unlikely to happen but did in the past, and caused problems.\\n\"]", "test_patch": "[\"diff --git a/tests/system_tests/CFortranInterop/test_CFortranInterop.py b/tests/system_tests/CFortranInterop/test_CFortranInterop.py\\nindex 483b696..ec708e6 100644\\n--- a/tests/system_tests/CFortranInterop/test_CFortranInterop.py\\n+++ b/tests/system_tests/CFortranInterop/test_CFortranInterop.py\\n@@ -46,10 +46,10 @@ def test_CFortranInterop(tmp_path):\\n         #     '/lib/x86_64-linux-gnu/libgfortran.so.5',\\n         # ]\\n \\n-    assert len(config._artefact_store[EXECUTABLES]) == 1\\n+    assert len(config.artefact_store[EXECUTABLES]) == 1\\n \\n     # run\\n-    command = [str(config._artefact_store[EXECUTABLES][0])]\\n+    command = [str(config.artefact_store[EXECUTABLES][0])]\\n     res = subprocess.run(command, capture_output=True)\\n     output = res.stdout.decode()\\n     assert output == ''.join(open(PROJECT_SOURCE / 'expected.exec.txt').readlines())\\n\",\"diff --git a/tests/system_tests/CUserHeader/test_CUserHeader.py b/tests/system_tests/CUserHeader/test_CUserHeader.py\\nindex d8ae677..04dac38 100644\\n--- a/tests/system_tests/CUserHeader/test_CUserHeader.py\\n+++ b/tests/system_tests/CUserHeader/test_CUserHeader.py\\n@@ -35,10 +35,10 @@ def test_CUseHeader(tmp_path):\\n \\n         link_exe(config, linker='gcc', flags=['-lgfortran']),\\n \\n-    assert len(config._artefact_store[EXECUTABLES]) == 1\\n+    assert len(config.artefact_store[EXECUTABLES]) == 1\\n \\n     # run\\n-    command = [str(config._artefact_store[EXECUTABLES][0])]\\n+    command = [str(config.artefact_store[EXECUTABLES][0])]\\n     res = subprocess.run(command, capture_output=True)\\n     output = res.stdout.decode()\\n     assert output == ''.join(open(PROJECT_SOURCE / 'expected.exec.txt').readlines())\\n\",\"diff --git a/tests/system_tests/FortranDependencies/test_FortranDependencies.py b/tests/system_tests/FortranDependencies/test_FortranDependencies.py\\nindex 6971bf8..e5d22f2 100644\\n--- a/tests/system_tests/FortranDependencies/test_FortranDependencies.py\\n+++ b/tests/system_tests/FortranDependencies/test_FortranDependencies.py\\n@@ -33,11 +33,11 @@ def test_FortranDependencies(tmp_path):\\n         compile_fortran(config, common_flags=['-c']),\\n         link_exe(config, linker='gcc', flags=['-lgfortran']),\\n \\n-    assert len(config._artefact_store[EXECUTABLES]) == 2\\n+    assert len(config.artefact_store[EXECUTABLES]) == 2\\n \\n     # run both exes\\n     output = set()\\n-    for exe in config._artefact_store[EXECUTABLES]:\\n+    for exe in config.artefact_store[EXECUTABLES]:\\n         res = subprocess.run(str(exe), capture_output=True)\\n         output.add(res.stdout.decode())\\n \\n\",\"diff --git a/tests/system_tests/FortranPreProcess/test_FortranPreProcess.py b/tests/system_tests/FortranPreProcess/test_FortranPreProcess.py\\nindex f45ea74..0888f53 100644\\n--- a/tests/system_tests/FortranPreProcess/test_FortranPreProcess.py\\n+++ b/tests/system_tests/FortranPreProcess/test_FortranPreProcess.py\\n@@ -36,13 +36,13 @@ def test_FortranPreProcess(tmp_path):\\n     # stay\\n     stay_config = build(fab_workspace=tmp_path, fpp_flags=['-P', '-DSHOULD_I_STAY=yes'])\\n \\n-    stay_exe = stay_config._artefact_store[EXECUTABLES][0]\\n+    stay_exe = stay_config.artefact_store[EXECUTABLES][0]\\n     stay_res = subprocess.run(str(stay_exe), capture_output=True)\\n     assert stay_res.stdout.decode().strip() == 'I should stay'\\n \\n     # go\\n     go_config = build(fab_workspace=tmp_path, fpp_flags=['-P'])\\n \\n-    go_exe = go_config._artefact_store[EXECUTABLES][0]\\n+    go_exe = go_config.artefact_store[EXECUTABLES][0]\\n     go_res = subprocess.run(str(go_exe), capture_output=True)\\n     assert go_res.stdout.decode().strip() == 'I should go now'\\n\",\"diff --git a/tests/system_tests/MinimalC/test_MinimalC.py b/tests/system_tests/MinimalC/test_MinimalC.py\\nindex aa99bb1..36a32b0 100644\\n--- a/tests/system_tests/MinimalC/test_MinimalC.py\\n+++ b/tests/system_tests/MinimalC/test_MinimalC.py\\n@@ -34,10 +34,10 @@ def test_MinimalC(tmp_path):\\n \\n         link_exe(config, linker='gcc'),\\n \\n-    assert len(config._artefact_store[EXECUTABLES]) == 1\\n+    assert len(config.artefact_store[EXECUTABLES]) == 1\\n \\n     # run\\n-    command = [str(config._artefact_store[EXECUTABLES][0])]\\n+    command = [str(config.artefact_store[EXECUTABLES][0])]\\n     res = subprocess.run(command, capture_output=True)\\n     output = res.stdout.decode()\\n     assert output == 'Hello world!'\\n\",\"diff --git a/tests/system_tests/MinimalFortran/test_MinimalFortran.py b/tests/system_tests/MinimalFortran/test_MinimalFortran.py\\nindex 6dd7615..455755c 100644\\n--- a/tests/system_tests/MinimalFortran/test_MinimalFortran.py\\n+++ b/tests/system_tests/MinimalFortran/test_MinimalFortran.py\\n@@ -32,10 +32,10 @@ def test_MinimalFortran(tmp_path):\\n         compile_fortran(config, common_flags=['-c']),\\n         link_exe(config, linker='gcc', flags=['-lgfortran']),\\n \\n-    assert len(config._artefact_store[EXECUTABLES]) == 1\\n+    assert len(config.artefact_store[EXECUTABLES]) == 1\\n \\n     # run\\n-    command = [str(config._artefact_store[EXECUTABLES][0])]\\n+    command = [str(config.artefact_store[EXECUTABLES][0])]\\n     res = subprocess.run(command, capture_output=True)\\n     output = res.stdout.decode()\\n     assert output.strip() == 'Hello world!'\\n\",\"diff --git a/tests/unit_tests/steps/test_archive_objects.py b/tests/unit_tests/steps/test_archive_objects.py\\nindex 0600d85..583e497 100644\\n--- a/tests/unit_tests/steps/test_archive_objects.py\\n+++ b/tests/unit_tests/steps/test_archive_objects.py\\n@@ -29,7 +29,7 @@ class Test_archive_objects(object):\\n         mock_run_command.assert_has_calls(expected_calls)\\n \\n         # ensure the correct artefacts were created\\n-        assert config._artefact_store[OBJECT_ARCHIVES] == {\\n+        assert config.artefact_store[OBJECT_ARCHIVES] == {\\n             target: [str(config.build_output / f'{target}.a')] for target in targets}\\n \\n     def test_for_library(self):\\n@@ -48,5 +48,5 @@ class Test_archive_objects(object):\\n             'ar', 'cr', str(config.build_output / 'mylib.a'), 'util1.o', 'util2.o'])\\n \\n         # ensure the correct artefacts were created\\n-        assert config._artefact_store[OBJECT_ARCHIVES] == {\\n+        assert config.artefact_store[OBJECT_ARCHIVES] == {\\n             None: [str(config.build_output / 'mylib.a')]}\\n\",\"diff --git a/tests/unit_tests/steps/test_cleanup_prebuilds.py b/tests/unit_tests/steps/test_cleanup_prebuilds.py\\nindex ec15acc..99a2695 100644\\n--- a/tests/unit_tests/steps/test_cleanup_prebuilds.py\\n+++ b/tests/unit_tests/steps/test_cleanup_prebuilds.py\\n@@ -21,7 +21,7 @@ class TestCleanupPrebuilds(object):\\n         with mock.patch('fab.steps.cleanup_prebuilds.file_walk', return_value=[Path('foo.o')]), \\\\\\n              pytest.warns(UserWarning, match=\\\"_metric_send_conn not set, cannot send metrics\\\"):\\n             with mock.patch('fab.steps.cleanup_prebuilds.remove_all_unused') as mock_remove_all_unused:\\n-                cleanup_prebuilds(config=mock.Mock(_artefact_store={CURRENT_PREBUILDS: [Path('bar.o')]}))\\n+                cleanup_prebuilds(config=mock.Mock(artefact_store={CURRENT_PREBUILDS: [Path('bar.o')]}))\\n         mock_remove_all_unused.assert_called_once_with(found_files=[Path('foo.o')], current_files=[Path('bar.o')])\\n \\n     def test_init_bad_args(self):\\n\",\"diff --git a/tests/unit_tests/steps/test_compile_c.py b/tests/unit_tests/steps/test_compile_c.py\\nindex 13f2022..9a58d99 100644\\n--- a/tests/unit_tests/steps/test_compile_c.py\\n+++ b/tests/unit_tests/steps/test_compile_c.py\\n@@ -14,10 +14,9 @@ from fab.steps.compile_c import _get_obj_combo_hash, compile_c\\n @pytest.fixture\\n def content(tmp_path):\\n     config = BuildConfig('proj', multiprocessing=False, fab_workspace=tmp_path)\\n-    config.init_artefact_store()\\n \\n     analysed_file = AnalysedC(fpath=Path(f'{config.source_root}/foo.c'), file_hash=0)\\n-    config._artefact_store[BUILD_TREES] = {None: {analysed_file.fpath: analysed_file}}\\n+    config.artefact_store[BUILD_TREES] = {None: {analysed_file.fpath: analysed_file}}\\n     expect_hash = 9120682468\\n     return config, analysed_file, expect_hash\\n \\n@@ -51,7 +50,7 @@ class Test_CompileC(object):\\n         values['send_metric'].assert_called_once()\\n \\n         # ensure it created the correct artefact collection\\n-        assert config._artefact_store[OBJECT_FILES] == {\\n+        assert config.artefact_store[OBJECT_FILES] == {\\n             None: {config.prebuild_folder / f'foo.{expect_hash:x}.o', }\\n         }\\n \\n\",\"diff --git a/tests/unit_tests/steps/test_link.py b/tests/unit_tests/steps/test_link.py\\nindex cfee8f9..57af5df 100644\\n--- a/tests/unit_tests/steps/test_link.py\\n+++ b/tests/unit_tests/steps/test_link.py\\n@@ -19,7 +19,7 @@ class TestLinkExe(object):\\n \\n         config = SimpleNamespace(\\n             project_workspace=Path('workspace'),\\n-            _artefact_store={OBJECT_FILES: {'foo': {'foo.o', 'bar.o'}}},\\n+            artefact_store={OBJECT_FILES: {'foo': {'foo.o', 'bar.o'}}},\\n         )\\n \\n         with mock.patch('os.getenv', return_value='-L/foo1/lib -L/foo2/lib'):\\n\",\"diff --git a/tests/unit_tests/steps/test_root_inc_files.py b/tests/unit_tests/steps/test_root_inc_files.py\\nindex 3bb55ce..9c61cb9 100644\\n--- a/tests/unit_tests/steps/test_root_inc_files.py\\n+++ b/tests/unit_tests/steps/test_root_inc_files.py\\n@@ -14,7 +14,7 @@ class TestRootIncFiles(object):\\n         inc_files = [Path('/foo/source/bar.inc')]\\n \\n         config = BuildConfig('proj')\\n-        config._artefact_store['all_source'] = inc_files\\n+        config.artefact_store['all_source'] = inc_files\\n \\n         with mock.patch('fab.steps.root_inc_files.shutil') as mock_shutil:\\n             with mock.patch('fab.steps.root_inc_files.Path.mkdir'), \\\\\\n@@ -27,7 +27,7 @@ class TestRootIncFiles(object):\\n         # ensure it doesn't try to copy a file in the build output\\n         config = BuildConfig('proj')\\n         inc_files = [Path('/foo/source/bar.inc'), config.build_output / 'fab.inc']\\n-        config._artefact_store['all_source'] = inc_files\\n+        config.artefact_store['all_source'] = inc_files\\n \\n         with mock.patch('fab.steps.root_inc_files.shutil') as mock_shutil:\\n             with mock.patch('fab.steps.root_inc_files.Path.mkdir'), \\\\\\n@@ -41,7 +41,7 @@ class TestRootIncFiles(object):\\n         inc_files = [Path('/foo/source/bar.inc'), Path('/foo/sauce/bar.inc')]\\n \\n         config = BuildConfig('proj')\\n-        config._artefact_store['all_source'] = inc_files\\n+        config.artefact_store['all_source'] = inc_files\\n \\n         with pytest.raises(FileExistsError):\\n             with mock.patch('fab.steps.root_inc_files.shutil'):\\n\",\"diff --git a/tests/unit_tests/test_artefacts.py b/tests/unit_tests/test_artefacts.py\\nindex bdd0dce..cd01114 100644\\n--- a/tests/unit_tests/test_artefacts.py\\n+++ b/tests/unit_tests/test_artefacts.py\\n@@ -3,28 +3,60 @@ from unittest.mock import call\\n \\n import pytest\\n \\n-from fab.artefacts import FilterBuildTrees\\n-from fab.constants import BUILD_TREES\\n+from fab.artefacts import ArtefactStore, ArtefactsGetter, FilterBuildTrees\\n+from fab.constants import BUILD_TREES, CURRENT_PREBUILDS\\n \\n \\n-class TestFilterBuildTrees(object):\\n+def test_artefacts_getter():\\n+    '''Test that ArtefactsGetter is a proper AbstractClass\\n+    and that a NotImplemented error is raised if a derived\\n+    class is trying to call the base class.\\n+    '''\\n+\\n+    # First check that we can't instantiate\\n+    # a class that doesn't implement __call__:\\n+    # ----------------------------------------\\n+    class MyClass(ArtefactsGetter):\\n+        pass\\n+\\n+    with pytest.raises(TypeError) as err:\\n+        _ = MyClass()\\n+    # The actual error messages changes slightly from python\\n+    # version to version:\\n+    # 3.7: ... with abstract methods\\n+    # 3.8: ... with abstract method\\n+    # 3.12: ... without an implementation for abstract\\n+    # so we only test for the begin which is identical:\\n+    assert \\\"Can't instantiate abstract class MyClass with\\\" in str(err.value)\\n+\\n+    # Now test that we can raise the NotImplementedError\\n+    # --------------------------------------------------\\n+    class MyClassWithCall(ArtefactsGetter):\\n+        def __call__(self, artefact_store):\\n+            super().__call__(artefact_store)\\n+\\n+    my_class_with_call = MyClassWithCall()\\n+    with pytest.raises(NotImplementedError) as err:\\n+        my_class_with_call(\\\"not-used\\\")\\n+    assert (\\\"__call__ must be implemented for 'MyClassWithCall'\\\"\\n+            in str(err.value))\\n+\\n+\\n+class TestFilterBuildTrees():\\n \\n     @pytest.fixture\\n     def artefact_store(self):\\n-        return {\\n-            BUILD_TREES: {\\n-                'tree1': {\\n-                    'a.foo': None,\\n-                    'b.foo': None,\\n-                    'c.bar': None,\\n-                },\\n-                'tree2': {\\n-                    'd.foo': None,\\n-                    'e.foo': None,\\n-                    'f.bar': None,\\n-                },\\n-            }\\n-        }\\n+        '''A fixture that returns an ArtefactStore with\\n+        some elements.'''\\n+        artefact_store = ArtefactStore()\\n+        artefact_store[BUILD_TREES] = {'tree1': {'a.foo': None,\\n+                                                 'b.foo': None,\\n+                                                 'c.bar': None, },\\n+                                       'tree2': {'d.foo': None,\\n+                                                 'e.foo': None,\\n+                                                 'f.bar': None, },\\n+                                       }\\n+        return artefact_store\\n \\n     def test_single_suffix(self, artefact_store):\\n         # ensure the artefact getter passes through the trees properly to the filter func\\n@@ -49,3 +81,11 @@ class TestFilterBuildTrees(object):\\n             call(source_tree=artefact_store[BUILD_TREES]['tree1'], suffixes=['.foo', '.bar']),\\n             call(source_tree=artefact_store[BUILD_TREES]['tree2'], suffixes=['.foo', '.bar']),\\n         ])\\n+\\n+\\n+def test_artefact_store():\\n+    '''Tests the ArtefactStore class.'''\\n+    artefact_store = ArtefactStore()\\n+    assert len(artefact_store) == 1\\n+    assert isinstance(artefact_store, dict)\\n+    assert CURRENT_PREBUILDS in artefact_store\\n\",\"diff --git a/tests/unit_tests/test_build_config.py b/tests/unit_tests/test_build_config.py\\nindex cb4f3e1..54a49ab 100644\\n--- a/tests/unit_tests/test_build_config.py\\n+++ b/tests/unit_tests/test_build_config.py\\n@@ -25,6 +25,6 @@ class TestBuildConfig(object):\\n     def test_add_cleanup(self):\\n         # ensure the cleanup step is added\\n         with BuildConfig('proj') as config:\\n-            assert CLEANUP_COUNT not in config._artefact_store\\n+            assert CLEANUP_COUNT not in config.artefact_store\\n             pass\\n-        assert CLEANUP_COUNT in config._artefact_store\\n+        assert CLEANUP_COUNT in config.artefact_store\"]", "hints_text": ""}
