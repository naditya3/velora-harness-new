{"instance_id": "1893439028117125", "repo": "xenonnt/alea", "base_commit": "3452e90199d48d3bf1358f7064ae7384073041a5", "problem_statement": "Access to templates:\\nIn binference we had a method `get_pdfs()`, which would return a list of templates for given generate values. I think it would be nice to add this functionality to alea. It should be possible to access the templates in the blueice likelihood objects, I think, which would ensure that it has all the slicing, etc. already applied to it.", "FAIL_TO_PASS": ["test_blueice_extended_model.TestBlueiceExtendedModel.test_all_source_names"], "PASS_TO_PASS": ["test_submitter.TestSubmitter.test_all_runner_kwargs", "test_blueice_extended_model.TestBlueiceExtendedModel.test_get_expectation_values_per_likelihood_term", "test_blueice_extended_model.TestBlueiceExtendedModel.test_likelihood", "test_blueice_extended_model.TestBlueiceExtendedModel.test_deep_copyable", "test_parameters.TestParameters.test___repr__", "test_blueice_extended_model.TestBlueiceExtendedModel.test_store_real_data", "test_utils.TestUtils.test_expand_grid_dict", "test_utils.TestUtils.test_get_analysis_space", "test_blueice_extended_model.TestBlueiceExtendedModel.test_fit", "test_parameters.TestParameters.test_deep_copyable", "test_blueice_extended_model.TestBlueiceExtendedModel.test_expectation_values", "test_blueice_extended_model.TestBlueiceExtendedModel.test_generate_data", "test_blueice_extended_model.TestBlueiceExtendedModel.test_needs_reinit", "test_model.TestStatisticalModel.test_statistical_model", "test_utils.TestUtils.test_convert_to_vary", "test_utils.TestUtils.test_deterministic_hash", "test_gaussian_model.TestGaussianModel.test_fit_result", "test_utils.TestUtils.test_within_limits", "test_utils.TestUtils.test_asymptotic_critical_value", "test_utils.TestUtils.test_can_expand_grid", "test_submitter.TestSubmitter.test_init", "test_parameters.TestParameters.test_from_list", "test_submitter.TestSubmitter.test_submit", "test_utils.TestUtils.test_formatted_to_asterisked", "test_gaussian_model.TestGaussianModel.test_data_generation", "test_gaussian_model.TestGaussianModel.test_data_storage", "test_template_source.TestTemplateSource.test_init_templates"], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && /opt/hostedtoolcache/Python/3.8.18/x64/bin/python3 /app/repo/unittest_loader_no_traceback.py ./tests ;", "test_output_parser": "python/parse_log_unittest", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_python_unittest/xenonnt_alea:3452e90199d48d3bf1358f7064ae7384073041a5", "patch": "[\"diff --git a/alea/models/blueice_extended_model.py b/alea/models/blueice_extended_model.py\\nindex c99c6cdc..a0deb1d7 100644\\n--- a/alea/models/blueice_extended_model.py\\n+++ b/alea/models/blueice_extended_model.py\\n@@ -9,6 +9,7 @@\\n from blueice.likelihood import LogAncillaryLikelihood, LogLikelihoodSum\\n from inference_interface import dict_to_structured_array, structured_array_to_dict\\n \\n+import multihist\\n from alea.model import StatisticalModel\\n from alea.parameters import Parameters\\n from alea.simulators import BlueiceDataGenerator\\n@@ -224,6 +225,63 @@ def get_expectation_values(self, per_likelihood_term=False, **kwargs) -> dict:\\n \\n         return ret\\n \\n+    def get_pdf(\\n+        self, source_name: str, likelihood_name: str, multiply_mu=False, **kwargs\\n+    ) -> multihist.Histdd:\\n+        \\\"\\\"\\\"Return the pdf for a given source and likelihood term.\\n+\\n+        Args:\\n+            source_name (str): Name of the source.\\n+            likelihood_name (str): Name of the likelihood.\\n+            kwargs: Named parameters.\\n+\\n+        Returns:\\n+            multihist.Histdd: A histogram of the pdf.\\n+\\n+        \\\"\\\"\\\"\\n+        if likelihood_name not in self.likelihood_names:\\n+            raise ValueError(f\\\"Likelihood {likelihood_name} not found.\\\")\\n+        if source_name not in self.get_source_name_list(likelihood_name):\\n+            raise ValueError(f\\\"Source {source_name} not found in likelihood {likelihood_name}.\\\")\\n+        likelihood_index = self.likelihood_names.index(likelihood_name)\\n+\\n+        # prepare the generate_values, WARNING: This silently drops parameters it can't handle!\\n+        generate_values = self.parameters(**kwargs)  # kwarg or nominal value\\n+        parameter_names = self.likelihood_parameters[likelihood_index]\\n+        livetime_parameter = self.livetime_parameter_names[likelihood_index]\\n+        call_args = {k: i for k, i in generate_values.items() if k in parameter_names}\\n+        if livetime_parameter is not None:\\n+            call_args[\\\"livetime_days\\\"] = generate_values[livetime_parameter]\\n+\\n+        # we will set fake data to the likelihood term so we need to copy it\\n+        ll_term = deepcopy(self.likelihood_list[likelihood_index])\\n+\\n+        # set fake data as the center of each bin\\n+        h = multihist.Histdd(dimensions=ll_term.base_model.config[\\\"analysis_space\\\"])\\n+        bin_centers = []\\n+        dtype = []\\n+\\n+        for dim in ll_term.base_model.config[\\\"analysis_space\\\"]:\\n+            dtype.append((dim[0], float))\\n+            bin_centers.append(0.5 * (dim[1][:-1] + dim[1][1:]))\\n+\\n+        data_binc = np.zeros(np.product(h.histogram.shape), dtype=dtype)\\n+        for i, l in enumerate(itertools.product(*bin_centers)):\\n+            for n, v in zip([dt[0] for dt in dtype], l):\\n+                data_binc[n][i] = v\\n+\\n+        ll_term.set_data(data_binc)\\n+\\n+        # Evaluate the pdf and cast it to a multihist\\n+        _, mus, ps = ll_term(full_output=True, **call_args)\\n+        source_names = [s.name for s in ll_term.base_model.sources]\\n+        ps = {s: p for s, p in zip(source_names, ps)}\\n+        h.histogram = ps[source_name].reshape(h.histogram.shape)\\n+\\n+        if multiply_mu:\\n+            h.histogram *= mus[source_names.index(source_name)]\\n+        return h\\n+\\n     def _process_blueice_config(self, config, template_folder_list):\\n         \\\"\\\"\\\"Process the blueice config from config.\\\"\\\"\\\"\\n         blueice_config = adapt_likelihood_config_for_blueice(config, template_folder_list)\\n\",\"diff --git a/alea/models/blueice_extended_model.py b/alea/models/blueice_extended_model.py\\nindex a0deb1d7..89e17d65 100644\\n--- a/alea/models/blueice_extended_model.py\\n+++ b/alea/models/blueice_extended_model.py\\n@@ -225,24 +225,20 @@ def get_expectation_values(self, per_likelihood_term=False, **kwargs) -> dict:\\n \\n         return ret\\n \\n-    def get_pdf(\\n-        self, source_name: str, likelihood_name: str, multiply_mu=False, **kwargs\\n-    ) -> multihist.Histdd:\\n+    def get_pdfs(self, likelihood_name: str, multiply_mus=False, **kwargs) -> dict:\\n         \\\"\\\"\\\"Return the pdf for a given source and likelihood term.\\n \\n         Args:\\n-            source_name (str): Name of the source.\\n-            likelihood_name (str): Name of the likelihood.\\n+            likelihood_name (str): Name of the likelihood term.\\n+            multiply_mus (bool): If True, multiply the pdf with the mus.\\n             kwargs: Named parameters.\\n \\n         Returns:\\n-            multihist.Histdd: A histogram of the pdf.\\n+            dict: Dictionary of multihist objects for each source.\\n \\n         \\\"\\\"\\\"\\n         if likelihood_name not in self.likelihood_names:\\n             raise ValueError(f\\\"Likelihood {likelihood_name} not found.\\\")\\n-        if source_name not in self.get_source_name_list(likelihood_name):\\n-            raise ValueError(f\\\"Source {source_name} not found in likelihood {likelihood_name}.\\\")\\n         likelihood_index = self.likelihood_names.index(likelihood_name)\\n \\n         # prepare the generate_values, WARNING: This silently drops parameters it can't handle!\\n@@ -275,12 +271,16 @@ def get_pdf(\\n         # Evaluate the pdf and cast it to a multihist\\n         _, mus, ps = ll_term(full_output=True, **call_args)\\n         source_names = [s.name for s in ll_term.base_model.sources]\\n-        ps = {s: p for s, p in zip(source_names, ps)}\\n-        h.histogram = ps[source_name].reshape(h.histogram.shape)\\n \\n-        if multiply_mu:\\n-            h.histogram *= mus[source_names.index(source_name)]\\n-        return h\\n+        hs = {}\\n+        for source_name, p in zip(source_names, ps):\\n+            this_h = deepcopy(h)\\n+            this_h.histogram = p.reshape(h.histogram.shape)\\n+            if multiply_mus:\\n+                this_h.histogram *= mus[source_names.index(source_name)]\\n+            hs[source_name] = this_h\\n+\\n+        return hs\\n \\n     def _process_blueice_config(self, config, template_folder_list):\\n         \\\"\\\"\\\"Process the blueice config from config.\\\"\\\"\\\"\\n\",\"diff --git a/alea/models/blueice_extended_model.py b/alea/models/blueice_extended_model.py\\nindex 89e17d65..dc27d305 100644\\n--- a/alea/models/blueice_extended_model.py\\n+++ b/alea/models/blueice_extended_model.py\\n@@ -9,7 +9,7 @@\\n from blueice.likelihood import LogAncillaryLikelihood, LogLikelihoodSum\\n from inference_interface import dict_to_structured_array, structured_array_to_dict\\n \\n-import multihist\\n+# import multihist\\n from alea.model import StatisticalModel\\n from alea.parameters import Parameters\\n from alea.simulators import BlueiceDataGenerator\\n@@ -241,6 +241,15 @@ def get_pdfs(self, likelihood_name: str, multiply_mus=False, **kwargs) -> dict:\\n             raise ValueError(f\\\"Likelihood {likelihood_name} not found.\\\")\\n         likelihood_index = self.likelihood_names.index(likelihood_name)\\n \\n+        if not self.parameters.values_in_fit_limits(**kwargs):\\n+            raise ValueError(\\\"Values are not within fit limits\\\")\\n+        generate_values = self.parameters(**kwargs)\\n+        lt_name = self.livetime_parameter_names[likelihood_index]\\n+        lt = generate_values.get(lt_name, None)\\n+\\n+        # compute the pdfs\\n+        self.data_generators[likelihood_index].compute_pdfs(livetime_days=lt, **generate_values)\\n+\\n         # prepare the generate_values, WARNING: This silently drops parameters it can't handle!\\n         generate_values = self.parameters(**kwargs)  # kwarg or nominal value\\n         parameter_names = self.likelihood_parameters[likelihood_index]\\n@@ -250,37 +259,40 @@ def get_pdfs(self, likelihood_name: str, multiply_mus=False, **kwargs) -> dict:\\n             call_args[\\\"livetime_days\\\"] = generate_values[livetime_parameter]\\n \\n         # we will set fake data to the likelihood term so we need to copy it\\n-        ll_term = deepcopy(self.likelihood_list[likelihood_index])\\n+        # ll_term = deepcopy(self.likelihood_list[likelihood_index])\\n \\n         # set fake data as the center of each bin\\n-        h = multihist.Histdd(dimensions=ll_term.base_model.config[\\\"analysis_space\\\"])\\n-        bin_centers = []\\n-        dtype = []\\n-\\n-        for dim in ll_term.base_model.config[\\\"analysis_space\\\"]:\\n-            dtype.append((dim[0], float))\\n-            bin_centers.append(0.5 * (dim[1][:-1] + dim[1][1:]))\\n-\\n-        data_binc = np.zeros(np.product(h.histogram.shape), dtype=dtype)\\n-        for i, l in enumerate(itertools.product(*bin_centers)):\\n-            for n, v in zip([dt[0] for dt in dtype], l):\\n-                data_binc[n][i] = v\\n-\\n-        ll_term.set_data(data_binc)\\n-\\n-        # Evaluate the pdf and cast it to a multihist\\n-        _, mus, ps = ll_term(full_output=True, **call_args)\\n-        source_names = [s.name for s in ll_term.base_model.sources]\\n-\\n-        hs = {}\\n-        for source_name, p in zip(source_names, ps):\\n-            this_h = deepcopy(h)\\n-            this_h.histogram = p.reshape(h.histogram.shape)\\n-            if multiply_mus:\\n-                this_h.histogram *= mus[source_names.index(source_name)]\\n-            hs[source_name] = this_h\\n-\\n-        return hs\\n+        # analysis_space = ll_term.base_model.config[\\\"analysis_space\\\"]\\n+        # h_template = multihist.Histdd(dimensions=analysis_space)\\n+        # bin_centers = []\\n+        # dtype = []\\n+        # for (name, bin_edges) in analysis_space:\\n+        #     dtype.append((name, float))\\n+        #     bin_centers.append(0.5 * (bin_edges[:-1] + bin_edges[1:]))\\n+\\n+        # data_binc = np.zeros(np.product(h_template.histogram.shape), dtype=dtype)\\n+        # for i, l in enumerate(itertools.product(*bin_centers)):\\n+        #     for n, v in zip([dt[0] for dt in dtype], l):\\n+        #         data_binc[n][i] = v\\n+\\n+        # ll_term.set_data(data_binc)\\n+\\n+        # # Evaluate the pdf and cast it to a multihist\\n+        # _, mus, ps = ll_term(full_output=True, **call_args)\\n+        # source_names = [s.name for s in ll_term.base_model.sources]\\n+\\n+        # hs = {}\\n+        # for source_name, p in zip(source_names, ps):\\n+        #     h = deepcopy(h_template)\\n+        #     h.histogram = p.reshape(h_template.histogram.shape)\\n+\\n+        #     h.histogram *= h.bin_volumes()\\n+        #     if multiply_mus:\\n+        #         h.histogram *= mus[source_names.index(source_name)]\\n+        #     hs[source_name] = h\\n+\\n+        # return hs\\n+        return {}\\n \\n     def _process_blueice_config(self, config, template_folder_list):\\n         \\\"\\\"\\\"Process the blueice config from config.\\\"\\\"\\\"\\n\",\"diff --git a/alea/simulators.py b/alea/simulators.py\\nindex 6232f86d..edba9d4b 100644\\n--- a/alea/simulators.py\\n+++ b/alea/simulators.py\\n@@ -39,22 +39,20 @@ def __init__(self, ll_term):\\n         logging.debug(\\\"initing simulator, binned: \\\" + str(self.binned))\\n \\n         ll = deepcopy(ll_term)\\n-        bins = []  # bin edges\\n         bincs = []  # bin centers of each component\\n         direction_names = []\\n         dtype = []\\n         data_length = 1  # number of bins in nD histogram\\n         data_lengths = []  # list of number of bins of each component\\n-        for direction in ll.base_model.config[\\\"analysis_space\\\"]:\\n-            bins.append(direction[1])\\n-            binc = 0.5 * (direction[1][1::] + direction[1][0:-1])\\n+        analysis_space = ll_term.base_model.config[\\\"analysis_space\\\"]\\n+        for name, bin_edges in analysis_space:\\n+            binc = 0.5 * (bin_edges[1:] + bin_edges[:-1])\\n             bincs.append(binc)\\n-            dtype.append((direction[0], float))\\n-            data_length *= len(direction[1]) - 1\\n-            data_lengths.append(len(direction[1]) - 1)\\n-            direction_names.append(direction[0])\\n+            dtype.append((name, float))\\n+            data_length *= len(bin_edges) - 1\\n+            data_lengths.append(len(bin_edges) - 1)\\n+            direction_names.append(name)\\n         dtype.append((\\\"source\\\", int))\\n-        logging.debug(\\\"init simulate_interpolated with bins: \\\" + str(bins))\\n \\n         data_binc = np.zeros(data_length, dtype=dtype)\\n         for i, l in enumerate(product(*bincs)):\\n@@ -64,7 +62,7 @@ def __init__(self, ll_term):\\n         ll.set_data(data_binc)\\n         source_histograms = []\\n         for i in range(len(ll.base_model.sources)):\\n-            source_histograms.append(mh.Histdd(bins=bins))\\n+            source_histograms.append(mh.Histdd(dimensions=analysis_space))\\n \\n         self.ll = ll\\n         self.bincs = bincs\\n@@ -72,7 +70,8 @@ def __init__(self, ll_term):\\n         self.source_histograms = source_histograms\\n         self.data_lengths = data_lengths\\n         self.dtype = dtype\\n-        self.last_kwargs = {\\\"FAKE_PARAMETER\\\": None}\\n+        self.last_kwargs = {}\\n+        self.first_call = True\\n         self.mus = ll.base_model.expected_events()\\n         self.parameters = list(ll.shape_parameters.keys())\\n         self.parameters += [n + \\\"_rate_multiplier\\\" for n in ll.rate_parameters.keys()]\\n@@ -99,31 +98,7 @@ def simulate(self, filter_kwargs=True, n_toys=None, sample_n_toys=False, **kwarg\\n             The dtype follows self.dtype.\\n \\n         \\\"\\\"\\\"\\n-        if filter_kwargs:\\n-            kwargs = {k: v for k, v in kwargs.items() if k in self.parameters + [\\\"livetime_days\\\"]}\\n-\\n-        unmatched_item = set(self.last_kwargs.items()) ^ set(kwargs.items())\\n-        logging.debug(\\\"filtered kwargs in simulate: \\\" + str(kwargs))\\n-        logging.debug(\\\"unmatched_item in simulate: \\\" + str(unmatched_item))\\n-        # check if the cached generator may be used:\\n-        if (\\\"FAKE_PARAMETER\\\" in self.last_kwargs.keys()) or (len(unmatched_item) != 0):\\n-            ret = self.ll(full_output=True, **kwargs)  # result, mus, ps\\n-            if isinstance(ret, float):\\n-                logging.warning(\\\"ERROR, generator kwarg outside range?\\\")\\n-                logging.warning(kwargs)\\n-            _, mus, ps_array = ret\\n-            for i in range(len(self.ll.base_model.sources)):\\n-                self.source_histograms[i].histogram = ps_array[i].reshape(self.data_lengths)\\n-                if not self.binned:\\n-                    logging.debug(\\n-                        f\\\"Source {str(self.ll.base_model.sources[i].name)} is not binned. \\\"\\n-                        \\\"Multiplying histogram with bin volumes.\\\"\\n-                    )\\n-                    self.source_histograms[i] *= self.source_histograms[i].bin_volumes()\\n-                    logging.debug(\\\"n after multiplying: \\\" + str(self.source_histograms[i].n))\\n-            self.mus = mus\\n-            self.last_kwargs = kwargs\\n-            logging.debug(f\\\"mus of simulate: {mus}\\\")\\n+        self.compute_pdfs(filter_kwargs=filter_kwargs, **kwargs)\\n \\n         if n_toys is not None:\\n             if sample_n_toys:\\n@@ -135,7 +110,6 @@ def simulate(self, filter_kwargs=True, n_toys=None, sample_n_toys=False, **kwarg\\n             # Generate a number n_source (according to the expectation value)\\n             # of toys for each source component:\\n             n_sources = sps.poisson(self.mus).rvs()\\n-            logging.debug(\\\"number of events drawn from Poisson: \\\" + str(n_sources))\\n             if len(self.ll.base_model.sources) == 1:\\n                 n_sources = np.array([n_sources])\\n \\n@@ -148,5 +122,33 @@ def simulate(self, filter_kwargs=True, n_toys=None, sample_n_toys=False, **kwarg\\n                     r_data[n][i_write : i_write + n_source] = rvs[:, j]\\n                 r_data[\\\"source\\\"][i_write : i_write + n_source] = i\\n                 i_write += n_source\\n-        logging.debug(\\\"return simulated data with length: \\\" + str(len(r_data)))\\n         return r_data\\n+\\n+    def compute_pdfs(self, filter_kwargs=True, **kwargs) -> None:\\n+        \\\"\\\"\\\"Compute PDFs of the sources for the given parameters.\\n+\\n+        Args:\\n+            filter_kwargs (bool, optional (default=True)): If True,\\n+                only parameters of the ll object are accepted as kwargs. Defaults to True.\\n+            kwargs: The parameters pasted to the likelihood function.\\n+\\n+        \\\"\\\"\\\"\\n+        if filter_kwargs:\\n+            kwargs = {k: v for k, v in kwargs.items() if k in self.parameters + [\\\"livetime_days\\\"]}\\n+\\n+        # check if the cached generator may be used:\\n+        unmatched_item = set(self.last_kwargs.items()) ^ set(kwargs.items())\\n+        kwargs_changed = len(unmatched_item) != 0\\n+        if self.first_call or kwargs_changed:\\n+            ret = self.ll(full_output=True, **kwargs)\\n+            if isinstance(ret, float):\\n+                logging.warning(\\\"ERROR, generator kwarg outside range?\\\")\\n+                logging.warning(kwargs)\\n+            _, mus, ps_array = ret\\n+            for i in range(len(self.ll.base_model.sources)):\\n+                self.source_histograms[i].histogram = ps_array[i].reshape(self.data_lengths)\\n+                if not self.binned:\\n+                    self.source_histograms[i] *= self.source_histograms[i].bin_volumes()\\n+            self.mus = mus\\n+            self.last_kwargs = kwargs\\n+            self.first_call = False\\n\",\"diff --git a/alea/models/blueice_extended_model.py b/alea/models/blueice_extended_model.py\\nindex dc27d305..1a147c50 100644\\n--- a/alea/models/blueice_extended_model.py\\n+++ b/alea/models/blueice_extended_model.py\\n@@ -225,7 +225,7 @@ def get_expectation_values(self, per_likelihood_term=False, **kwargs) -> dict:\\n \\n         return ret\\n \\n-    def get_pdfs(self, likelihood_name: str, multiply_mus=False, **kwargs) -> dict:\\n+    def get_source_histograms(self, likelihood_name: str, multiply_mus=False, **kwargs) -> dict:\\n         \\\"\\\"\\\"Return the pdf for a given source and likelihood term.\\n \\n         Args:\\n@@ -239,24 +239,32 @@ def get_pdfs(self, likelihood_name: str, multiply_mus=False, **kwargs) -> dict:\\n         \\\"\\\"\\\"\\n         if likelihood_name not in self.likelihood_names:\\n             raise ValueError(f\\\"Likelihood {likelihood_name} not found.\\\")\\n-        likelihood_index = self.likelihood_names.index(likelihood_name)\\n+        ll_index = self.likelihood_names.index(likelihood_name)\\n \\n         if not self.parameters.values_in_fit_limits(**kwargs):\\n             raise ValueError(\\\"Values are not within fit limits\\\")\\n         generate_values = self.parameters(**kwargs)\\n-        lt_name = self.livetime_parameter_names[likelihood_index]\\n-        lt = generate_values.get(lt_name, None)\\n+        lt_name = self.livetime_parameter_names[ll_index]\\n+        # change keyof lt_name to \\\"livetime_days\\\" if it is in the generate_values\\n+        if lt_name in generate_values:\\n+            generate_values[\\\"livetime_days\\\"] = generate_values.pop(lt_name)\\n \\n         # compute the pdfs\\n-        self.data_generators[likelihood_index].compute_pdfs(livetime_days=lt, **generate_values)\\n+        self.data_generators[ll_index].compute_pdfs_and_mus(**generate_values)\\n \\n-        # prepare the generate_values, WARNING: This silently drops parameters it can't handle!\\n-        generate_values = self.parameters(**kwargs)  # kwarg or nominal value\\n-        parameter_names = self.likelihood_parameters[likelihood_index]\\n-        livetime_parameter = self.livetime_parameter_names[likelihood_index]\\n-        call_args = {k: i for k, i in generate_values.items() if k in parameter_names}\\n-        if livetime_parameter is not None:\\n-            call_args[\\\"livetime_days\\\"] = generate_values[livetime_parameter]\\n+        if multiply_mus:\\n+            # FIXME\\n+            raise NotImplementedError\\n+\\n+        return self.data_generators[ll_index].source_histograms\\n+\\n+        # # prepare the generate_values, WARNING: This silently drops parameters it can't handle!\\n+        # generate_values = self.parameters(**kwargs)  # kwarg or nominal value\\n+        # parameter_names = self.likelihood_parameters[likelihood_index]\\n+        # livetime_parameter = self.livetime_parameter_names[likelihood_index]\\n+        # call_args = {k: i for k, i in generate_values.items() if k in parameter_names}\\n+        # if livetime_parameter is not None:\\n+        #     call_args[\\\"livetime_days\\\"] = generate_values[livetime_parameter]\\n \\n         # we will set fake data to the likelihood term so we need to copy it\\n         # ll_term = deepcopy(self.likelihood_list[likelihood_index])\\n@@ -292,7 +300,7 @@ def get_pdfs(self, likelihood_name: str, multiply_mus=False, **kwargs) -> dict:\\n         #     hs[source_name] = h\\n \\n         # return hs\\n-        return {}\\n+        # return {}\\n \\n     def _process_blueice_config(self, config, template_folder_list):\\n         \\\"\\\"\\\"Process the blueice config from config.\\\"\\\"\\\"\\n\",\"diff --git a/alea/simulators.py b/alea/simulators.py\\nindex edba9d4b..7747b541 100644\\n--- a/alea/simulators.py\\n+++ b/alea/simulators.py\\n@@ -60,9 +60,9 @@ def __init__(self, ll_term):\\n                 data_binc[n][i] = v\\n \\n         ll.set_data(data_binc)\\n-        source_histograms = []\\n-        for i in range(len(ll.base_model.sources)):\\n-            source_histograms.append(mh.Histdd(dimensions=analysis_space))\\n+        source_histograms = {}\\n+        for s in ll.base_model.sources:\\n+            source_histograms[s.name] = mh.Histdd(dimensions=analysis_space)\\n \\n         self.ll = ll\\n         self.bincs = bincs\\n@@ -98,6 +98,7 @@ def simulate(self, filter_kwargs=True, n_toys=None, sample_n_toys=False, **kwarg\\n             The dtype follows self.dtype.\\n \\n         \\\"\\\"\\\"\\n+        # TODO: I changed source_histograms to be a dict, so this needs to be updated\\n         self.compute_pdfs(filter_kwargs=filter_kwargs, **kwargs)\\n \\n         if n_toys is not None:\\n@@ -124,7 +125,7 @@ def simulate(self, filter_kwargs=True, n_toys=None, sample_n_toys=False, **kwarg\\n                 i_write += n_source\\n         return r_data\\n \\n-    def compute_pdfs(self, filter_kwargs=True, **kwargs) -> None:\\n+    def compute_pdfs_and_mus(self, filter_kwargs=True, **kwargs) -> None:\\n         \\\"\\\"\\\"Compute PDFs of the sources for the given parameters.\\n \\n         Args:\\n\",\"diff --git a/alea/simulators.py b/alea/simulators.py\\nindex 7747b541..67059925 100644\\n--- a/alea/simulators.py\\n+++ b/alea/simulators.py\\n@@ -52,6 +52,7 @@ def __init__(self, ll_term):\\n             data_length *= len(bin_edges) - 1\\n             data_lengths.append(len(bin_edges) - 1)\\n             direction_names.append(name)\\n+        # IDEA: make source a string, not an int\\n         dtype.append((\\\"source\\\", int))\\n \\n         data_binc = np.zeros(data_length, dtype=dtype)\\n@@ -98,8 +99,7 @@ def simulate(self, filter_kwargs=True, n_toys=None, sample_n_toys=False, **kwarg\\n             The dtype follows self.dtype.\\n \\n         \\\"\\\"\\\"\\n-        # TODO: I changed source_histograms to be a dict, so this needs to be updated\\n-        self.compute_pdfs(filter_kwargs=filter_kwargs, **kwargs)\\n+        self.compute_pdfs_and_mus(filter_kwargs=filter_kwargs, **kwargs)\\n \\n         if n_toys is not None:\\n             if sample_n_toys:\\n@@ -118,7 +118,8 @@ def simulate(self, filter_kwargs=True, n_toys=None, sample_n_toys=False, **kwarg\\n         i_write = 0\\n         for i, n_source in enumerate(n_sources):\\n             if n_source > 0:  # dont generate if 0\\n-                rvs = self.source_histograms[i].get_random(n_source)\\n+                source_name = self.ll.base_model.sources[i].name\\n+                rvs = self.source_histograms[source_name].get_random(n_source)\\n                 for j, n in enumerate(self.direction_names):\\n                     r_data[n][i_write : i_write + n_source] = rvs[:, j]\\n                 r_data[\\\"source\\\"][i_write : i_write + n_source] = i\\n@@ -146,10 +147,10 @@ def compute_pdfs_and_mus(self, filter_kwargs=True, **kwargs) -> None:\\n                 logging.warning(\\\"ERROR, generator kwarg outside range?\\\")\\n                 logging.warning(kwargs)\\n             _, mus, ps_array = ret\\n-            for i in range(len(self.ll.base_model.sources)):\\n-                self.source_histograms[i].histogram = ps_array[i].reshape(self.data_lengths)\\n+            for i, s in enumerate(self.ll.base_model.sources):\\n+                self.source_histograms[s.name].histogram = ps_array[i].reshape(self.data_lengths)\\n                 if not self.binned:\\n-                    self.source_histograms[i] *= self.source_histograms[i].bin_volumes()\\n+                    self.source_histograms[s.name] *= self.source_histograms[s.name].bin_volumes()\\n             self.mus = mus\\n             self.last_kwargs = kwargs\\n             self.first_call = False\\n\",\"diff --git a/alea/models/blueice_extended_model.py b/alea/models/blueice_extended_model.py\\nindex 1a147c50..9b669d00 100644\\n--- a/alea/models/blueice_extended_model.py\\n+++ b/alea/models/blueice_extended_model.py\\n@@ -258,50 +258,6 @@ def get_source_histograms(self, likelihood_name: str, multiply_mus=False, **kwar\\n \\n         return self.data_generators[ll_index].source_histograms\\n \\n-        # # prepare the generate_values, WARNING: This silently drops parameters it can't handle!\\n-        # generate_values = self.parameters(**kwargs)  # kwarg or nominal value\\n-        # parameter_names = self.likelihood_parameters[likelihood_index]\\n-        # livetime_parameter = self.livetime_parameter_names[likelihood_index]\\n-        # call_args = {k: i for k, i in generate_values.items() if k in parameter_names}\\n-        # if livetime_parameter is not None:\\n-        #     call_args[\\\"livetime_days\\\"] = generate_values[livetime_parameter]\\n-\\n-        # we will set fake data to the likelihood term so we need to copy it\\n-        # ll_term = deepcopy(self.likelihood_list[likelihood_index])\\n-\\n-        # set fake data as the center of each bin\\n-        # analysis_space = ll_term.base_model.config[\\\"analysis_space\\\"]\\n-        # h_template = multihist.Histdd(dimensions=analysis_space)\\n-        # bin_centers = []\\n-        # dtype = []\\n-        # for (name, bin_edges) in analysis_space:\\n-        #     dtype.append((name, float))\\n-        #     bin_centers.append(0.5 * (bin_edges[:-1] + bin_edges[1:]))\\n-\\n-        # data_binc = np.zeros(np.product(h_template.histogram.shape), dtype=dtype)\\n-        # for i, l in enumerate(itertools.product(*bin_centers)):\\n-        #     for n, v in zip([dt[0] for dt in dtype], l):\\n-        #         data_binc[n][i] = v\\n-\\n-        # ll_term.set_data(data_binc)\\n-\\n-        # # Evaluate the pdf and cast it to a multihist\\n-        # _, mus, ps = ll_term(full_output=True, **call_args)\\n-        # source_names = [s.name for s in ll_term.base_model.sources]\\n-\\n-        # hs = {}\\n-        # for source_name, p in zip(source_names, ps):\\n-        #     h = deepcopy(h_template)\\n-        #     h.histogram = p.reshape(h_template.histogram.shape)\\n-\\n-        #     h.histogram *= h.bin_volumes()\\n-        #     if multiply_mus:\\n-        #         h.histogram *= mus[source_names.index(source_name)]\\n-        #     hs[source_name] = h\\n-\\n-        # return hs\\n-        # return {}\\n-\\n     def _process_blueice_config(self, config, template_folder_list):\\n         \\\"\\\"\\\"Process the blueice config from config.\\\"\\\"\\\"\\n         blueice_config = adapt_likelihood_config_for_blueice(config, template_folder_list)\\n\",\"diff --git a/alea/simulators.py b/alea/simulators.py\\nindex 67059925..936c0236 100644\\n--- a/alea/simulators.py\\n+++ b/alea/simulators.py\\n@@ -36,37 +36,34 @@ def __init__(self, ll_term):\\n             self.binned = False\\n         else:\\n             raise NotImplementedError\\n-        logging.debug(\\\"initing simulator, binned: \\\" + str(self.binned))\\n \\n         ll = deepcopy(ll_term)\\n         bincs = []  # bin centers of each component\\n         direction_names = []\\n         dtype = []\\n-        data_length = 1  # number of bins in nD histogram\\n         data_lengths = []  # list of number of bins of each component\\n         analysis_space = ll_term.base_model.config[\\\"analysis_space\\\"]\\n+\\n+        source_histograms = {}\\n+        for n in ll.source_name_list:\\n+            source_histograms[n] = mh.Histdd(dimensions=analysis_space)\\n+\\n         for name, bin_edges in analysis_space:\\n-            binc = 0.5 * (bin_edges[1:] + bin_edges[:-1])\\n-            bincs.append(binc)\\n+            bincs.append(0.5 * (bin_edges[1:] + bin_edges[:-1]))\\n             dtype.append((name, float))\\n-            data_length *= len(bin_edges) - 1\\n             data_lengths.append(len(bin_edges) - 1)\\n             direction_names.append(name)\\n         # IDEA: make source a string, not an int\\n         dtype.append((\\\"source\\\", int))\\n \\n-        data_binc = np.zeros(data_length, dtype=dtype)\\n+        data_binc = np.zeros(np.prod(data_lengths), dtype=dtype)\\n         for i, l in enumerate(product(*bincs)):\\n             for n, v in zip(direction_names, l):\\n                 data_binc[n][i] = v\\n \\n         ll.set_data(data_binc)\\n-        source_histograms = {}\\n-        for s in ll.base_model.sources:\\n-            source_histograms[s.name] = mh.Histdd(dimensions=analysis_space)\\n \\n         self.ll = ll\\n-        self.bincs = bincs\\n         self.direction_names = direction_names\\n         self.source_histograms = source_histograms\\n         self.data_lengths = data_lengths\\n@@ -118,7 +115,7 @@ def simulate(self, filter_kwargs=True, n_toys=None, sample_n_toys=False, **kwarg\\n         i_write = 0\\n         for i, n_source in enumerate(n_sources):\\n             if n_source > 0:  # dont generate if 0\\n-                source_name = self.ll.base_model.sources[i].name\\n+                source_name = self.ll.source_name_list[i]\\n                 rvs = self.source_histograms[source_name].get_random(n_source)\\n                 for j, n in enumerate(self.direction_names):\\n                     r_data[n][i_write : i_write + n_source] = rvs[:, j]\\n@@ -147,10 +144,10 @@ def compute_pdfs_and_mus(self, filter_kwargs=True, **kwargs) -> None:\\n                 logging.warning(\\\"ERROR, generator kwarg outside range?\\\")\\n                 logging.warning(kwargs)\\n             _, mus, ps_array = ret\\n-            for i, s in enumerate(self.ll.base_model.sources):\\n-                self.source_histograms[s.name].histogram = ps_array[i].reshape(self.data_lengths)\\n+            for n, p in zip(self.ll.source_name_list, ps_array):\\n+                self.source_histograms[n].histogram = p.reshape(self.data_lengths)\\n                 if not self.binned:\\n-                    self.source_histograms[s.name] *= self.source_histograms[s.name].bin_volumes()\\n+                    self.source_histograms[n] *= self.source_histograms[n].bin_volumes()\\n             self.mus = mus\\n             self.last_kwargs = kwargs\\n             self.first_call = False\\n\",\"diff --git a/alea/models/blueice_extended_model.py b/alea/models/blueice_extended_model.py\\nindex 9b669d00..6726ef2c 100644\\n--- a/alea/models/blueice_extended_model.py\\n+++ b/alea/models/blueice_extended_model.py\\n@@ -251,12 +251,15 @@ def get_source_histograms(self, likelihood_name: str, multiply_mus=False, **kwar\\n \\n         # compute the pdfs\\n         self.data_generators[ll_index].compute_pdfs_and_mus(**generate_values)\\n+        source_histograms = self.data_generators[ll_index].source_histograms\\n \\n         if multiply_mus:\\n-            # FIXME\\n-            raise NotImplementedError\\n+            mus = self.data_generators[ll_index].mus\\n+            for source_name, hist in source_histograms.items():\\n+                source_index = self.get_source_name_list(likelihood_name).index(source_name)\\n+                hist.histogram *= mus[source_index]\\n \\n-        return self.data_generators[ll_index].source_histograms\\n+        return source_histograms\\n \\n     def _process_blueice_config(self, config, template_folder_list):\\n         \\\"\\\"\\\"Process the blueice config from config.\\\"\\\"\\\"\\n\",\"diff --git a/alea/models/blueice_extended_model.py b/alea/models/blueice_extended_model.py\\nindex 6726ef2c..441a52ae 100644\\n--- a/alea/models/blueice_extended_model.py\\n+++ b/alea/models/blueice_extended_model.py\\n@@ -1,6 +1,5 @@\\n import warnings\\n from typing import List, Dict, Callable, Optional, Union, cast\\n-from copy import deepcopy\\n from pydoc import locate\\n import itertools\\n \\n@@ -142,7 +141,7 @@ def get_source_name_list(self, likelihood_name: str) -> list:\\n         return self.likelihood_list[ll_index].source_name_list\\n \\n     @property\\n-    def all_source_names(self) -> set:\\n+    def all_source_names(self) -> list:\\n         \\\"\\\"\\\"Return a set of possible source names from all likelihood terms.\\n \\n         Args:\\n@@ -154,7 +153,7 @@ def all_source_names(self) -> set:\\n         source_names = set(\\n             itertools.chain.from_iterable([ll.source_name_list for ll in self.likelihood_list[:-1]])\\n         )\\n-        return source_names\\n+        return sorted(source_names)\\n \\n     @property\\n     def likelihood_list(self) -> List:\\n@@ -179,42 +178,29 @@ def get_expectation_values(self, per_likelihood_term=False, **kwargs) -> dict:\\n             dict: Dictionary of expectation values. If per_likelihood_term is True, the dictionary\\n                 has the form {likelihood_name: {source_name: expectation_value, ...}, ...}.\\n \\n-        Caution:\\n-            The function silently drops parameters it can't handle!\\n-\\n         Todo:\\n-            Current implementation is not elegant.\\n-            It copied the llh and sets the data to the copied llh,\\n-            because the call of llh needs data to be set.\\n-            But data is not needed for the expectation values.\\n-            We should update this function in the future after we stop using blueice.\\n-\\n             Make a self.likelihood_temrs dict with the likelihood names as keys and\\n             the corresponding likelihood terms as values.\\n \\n         \\\"\\\"\\\"\\n-        generate_values = self.parameters(**kwargs)  # kwarg or nominal value\\n         ret = cast(Dict[str, Dict[str, float]], {})\\n-\\n-        # calling ll need data to be set\\n-        self_copy = deepcopy(self)\\n-        self_copy.data = self_copy.generate_data()\\n+        # prepare generate_values\\n+        if not self.parameters.values_in_fit_limits(**kwargs):\\n+            raise ValueError(\\\"Values are not within fit limits\\\")\\n+        generate_values = self.parameters(**kwargs)\\n \\n         # ancillary likelihood does not contribute\\n-        for ll_term, ll_name, parameter_names, livetime_parameter in zip(\\n-            self_copy.likelihood_list[:-1],\\n-            self_copy.likelihood_names[:-1],\\n-            self_copy.likelihood_parameters,\\n-            self_copy.livetime_parameter_names,\\n+        for ll_name, lt_name in zip(\\n+            self.likelihood_names[:-1],\\n+            self.livetime_parameter_names,\\n         ):\\n             ret[ll_name] = {}\\n-            # WARNING: This silently drops parameters it can't handle!\\n-            call_args = {k: i for k, i in generate_values.items() if k in parameter_names}\\n-            if livetime_parameter is not None:\\n-                call_args[\\\"livetime_days\\\"] = generate_values[livetime_parameter]\\n-\\n-            mus = ll_term(full_output=True, **call_args)[1]\\n-            for n, mu in zip(ll_term.source_name_list, mus):\\n+            ll_index = self.likelihood_names.index(ll_name)\\n+            lt = generate_values.pop(lt_name, None)\\n+            # compute the mus\\n+            self.data_generators[ll_index].compute_pdfs_and_mus(**generate_values, livetime_days=lt)\\n+            mus = self.data_generators[ll_index].mus\\n+            for n, mu in zip(self.likelihood_list[ll_index].source_name_list, mus):\\n                 ret[ll_name][n] = mu\\n         if not per_likelihood_term:\\n             # sum over sources with same names of all likelihood terms\\n@@ -241,6 +227,7 @@ def get_source_histograms(self, likelihood_name: str, multiply_mus=False, **kwar\\n             raise ValueError(f\\\"Likelihood {likelihood_name} not found.\\\")\\n         ll_index = self.likelihood_names.index(likelihood_name)\\n \\n+        # prepare generate_values\\n         if not self.parameters.values_in_fit_limits(**kwargs):\\n             raise ValueError(\\\"Values are not within fit limits\\\")\\n         generate_values = self.parameters(**kwargs)\\n\",\"diff --git a/alea/models/blueice_extended_model.py b/alea/models/blueice_extended_model.py\\nindex 441a52ae..eb0e2c26 100644\\n--- a/alea/models/blueice_extended_model.py\\n+++ b/alea/models/blueice_extended_model.py\\n@@ -212,15 +212,15 @@ def get_expectation_values(self, per_likelihood_term=False, **kwargs) -> dict:\\n         return ret\\n \\n     def get_source_histograms(self, likelihood_name: str, multiply_mus=False, **kwargs) -> dict:\\n-        \\\"\\\"\\\"Return the pdf for a given source and likelihood term.\\n+        \\\"\\\"\\\"Return the pdfs or histograms of all sources for a given likelihood term.\\n \\n         Args:\\n             likelihood_name (str): Name of the likelihood term.\\n-            multiply_mus (bool): If True, multiply the pdf with the mus.\\n+            multiply_mus (bool): If True, multiply the pdfs/histograms with the expecftation values.\\n             kwargs: Named parameters.\\n \\n         Returns:\\n-            dict: Dictionary of multihist objects for each source.\\n+            dict: Dictionary containing a multihist object for each source.\\n \\n         \\\"\\\"\\\"\\n         if likelihood_name not in self.likelihood_names:\\n\",\"diff --git a/alea/models/blueice_extended_model.py b/alea/models/blueice_extended_model.py\\nindex eb0e2c26..af3835c8 100644\\n--- a/alea/models/blueice_extended_model.py\\n+++ b/alea/models/blueice_extended_model.py\\n@@ -8,7 +8,6 @@\\n from blueice.likelihood import LogAncillaryLikelihood, LogLikelihoodSum\\n from inference_interface import dict_to_structured_array, structured_array_to_dict\\n \\n-# import multihist\\n from alea.model import StatisticalModel\\n from alea.parameters import Parameters\\n from alea.simulators import BlueiceDataGenerator\\n\",\"diff --git a/alea/models/blueice_extended_model.py b/alea/models/blueice_extended_model.py\\nindex af3835c8..0bbba818 100644\\n--- a/alea/models/blueice_extended_model.py\\n+++ b/alea/models/blueice_extended_model.py\\n@@ -2,6 +2,7 @@\\n from typing import List, Dict, Callable, Optional, Union, cast\\n from pydoc import locate\\n import itertools\\n+from copy import deepcopy\\n \\n import numpy as np\\n import scipy.stats as stats\\n@@ -210,12 +211,13 @@ def get_expectation_values(self, per_likelihood_term=False, **kwargs) -> dict:\\n \\n         return ret\\n \\n-    def get_source_histograms(self, likelihood_name: str, multiply_mus=False, **kwargs) -> dict:\\n+    def get_source_histograms(self, likelihood_name: str, expected_events=False, **kwargs) -> dict:\\n         \\\"\\\"\\\"Return the pdfs or histograms of all sources for a given likelihood term.\\n \\n         Args:\\n             likelihood_name (str): Name of the likelihood term.\\n-            multiply_mus (bool): If True, multiply the pdfs/histograms with the expecftation values.\\n+            expected_events (bool): If True, return the histograms containing\\n+                the number of expected events.\\n             kwargs: Named parameters.\\n \\n         Returns:\\n@@ -224,6 +226,9 @@ def get_source_histograms(self, likelihood_name: str, multiply_mus=False, **kwar\\n         \\\"\\\"\\\"\\n         if likelihood_name not in self.likelihood_names:\\n             raise ValueError(f\\\"Likelihood {likelihood_name} not found.\\\")\\n+        elif likelihood_name == \\\"ancillary\\\":\\n+            raise ValueError(\\\"No source histograms for ancillary likelihood.\\\")\\n+        \\n         ll_index = self.likelihood_names.index(likelihood_name)\\n \\n         # prepare generate_values\\n@@ -237,13 +242,17 @@ def get_source_histograms(self, likelihood_name: str, multiply_mus=False, **kwar\\n \\n         # compute the pdfs\\n         self.data_generators[ll_index].compute_pdfs_and_mus(**generate_values)\\n-        source_histograms = self.data_generators[ll_index].source_histograms\\n+        source_histograms = deepcopy(self.data_generators[ll_index].source_histograms)\\n \\n-        if multiply_mus:\\n+        if expected_events:\\n             mus = self.data_generators[ll_index].mus\\n             for source_name, hist in source_histograms.items():\\n                 source_index = self.get_source_name_list(likelihood_name).index(source_name)\\n                 hist.histogram *= mus[source_index]\\n+        # for unbinned likelihoods we need to divide by the bin volumes\\n+        elif not expected_events and not self.data_generators[ll_index].binned:\\n+            for hist in source_histograms.values():\\n+                hist.histogram /= hist.bin_volumes()\\n \\n         return source_histograms\\n \\n\",\"diff --git a/alea/models/blueice_extended_model.py b/alea/models/blueice_extended_model.py\\nindex 0bbba818..08550a35 100644\\n--- a/alea/models/blueice_extended_model.py\\n+++ b/alea/models/blueice_extended_model.py\\n@@ -228,7 +228,7 @@ def get_source_histograms(self, likelihood_name: str, expected_events=False, **k\\n             raise ValueError(f\\\"Likelihood {likelihood_name} not found.\\\")\\n         elif likelihood_name == \\\"ancillary\\\":\\n             raise ValueError(\\\"No source histograms for ancillary likelihood.\\\")\\n-        \\n+\\n         ll_index = self.likelihood_names.index(likelihood_name)\\n \\n         # prepare generate_values\\n\"]", "test_patch": "[\"diff --git a/tests/test_blueice_extended_model.py b/tests/test_blueice_extended_model.py\\nindex 2fb03635..6d6606f4 100644\\n--- a/tests/test_blueice_extended_model.py\\n+++ b/tests/test_blueice_extended_model.py\\n@@ -77,7 +77,7 @@ def test_all_source_names(self):\\n             for ll_t in config[\\\"likelihood_config\\\"][\\\"likelihood_terms\\\"]:\\n                 _source_names.update([s[\\\"name\\\"] for s in ll_t[\\\"sources\\\"]])\\n             source_names = model.all_source_names\\n-            self.assertEqual(source_names, _source_names)\\n+            self.assertEqual(source_names, sorted(_source_names))\\n \\n     def test_expectation_values(self):\\n         \\\"\\\"\\\"Test of the expectation_values method.\\\"\\\"\\\"\\n\",\"diff --git a/tests/test_blueice_extended_model.py b/tests/test_blueice_extended_model.py\\nindex 6d6606f4..141bae30 100644\\n--- a/tests/test_blueice_extended_model.py\\n+++ b/tests/test_blueice_extended_model.py\\n@@ -2,6 +2,7 @@\\n import pytest\\n from unittest import TestCase\\n from copy import deepcopy\\n+import numpy as np\\n \\n from inference_interface import toydata_from_file\\n \\n@@ -208,3 +209,38 @@ def test_needs_reinit(self):\\n             model.data = model.generate_data()\\n             with self.assertRaises(ValueError):\\n                 model.fit(wimp_mass=1)\\n+\\n+    def test_get_source_histograms(self):\\n+        \\\"\\\"\\\"Test of the get_source_histograms method.\\\"\\\"\\\"\\n+        for model in self.models:\\n+            mus = model.get_expectation_values(per_likelihood_term=True)\\n+            for ll_name, ll_term in zip(model.likelihood_names[:-1], model.likelihood_list[:-1]):\\n+                source_histograms = model.get_source_histograms(ll_name)\\n+                self.assertEqual(sorted(source_histograms.keys()), sorted(ll_term.source_name_list))\\n+\\n+                # check whether the correct source histograms are returned\\n+                for s_name, histogram in source_histograms.items():\\n+                    source_index = ll_term.source_name_list.index(s_name)\\n+                    blueice_source = ll_term.base_model.sources[source_index]\\n+                    blueice_hist = blueice_source._pdf_histogram.histogram\\n+                    np.testing.assert_almost_equal(blueice_hist, histogram,\\n+                                                   decimal=10)\\n+\\n+                # check that expected_events boolean works\\n+                source_histograms = model.get_source_histograms(\\n+                    ll_name,\\n+                    expected_events=True\\n+                )\\n+                for s_name, histogram in source_histograms.items():\\n+                    mu = mus[ll_name][s_name]\\n+                    sum_hist = histogram.n\\n+                    np.testing.assert_almost_equal(mu, sum_hist,\\n+                                                   decimal=4)\\n+\\n+            # check that model.likelihood_names[-1] fails\\n+            with self.assertRaises(ValueError):\\n+                model.get_source_histograms(model.likelihood_names[-1])\\n+\\n+            # check that invalid likelihood names fail\\n+            with self.assertRaises(ValueError):\\n+                model.get_source_histograms(\\\"alea_iacta_est\\\")\\n\",\"diff --git a/tests/test_blueice_extended_model.py b/tests/test_blueice_extended_model.py\\nindex 141bae30..2b47c00b 100644\\n--- a/tests/test_blueice_extended_model.py\\n+++ b/tests/test_blueice_extended_model.py\\n@@ -223,19 +223,14 @@ def test_get_source_histograms(self):\\n                     source_index = ll_term.source_name_list.index(s_name)\\n                     blueice_source = ll_term.base_model.sources[source_index]\\n                     blueice_hist = blueice_source._pdf_histogram.histogram\\n-                    np.testing.assert_almost_equal(blueice_hist, histogram,\\n-                                                   decimal=10)\\n+                    np.testing.assert_almost_equal(blueice_hist, histogram, decimal=10)\\n \\n                 # check that expected_events boolean works\\n-                source_histograms = model.get_source_histograms(\\n-                    ll_name,\\n-                    expected_events=True\\n-                )\\n+                source_histograms = model.get_source_histograms(ll_name, expected_events=True)\\n                 for s_name, histogram in source_histograms.items():\\n                     mu = mus[ll_name][s_name]\\n                     sum_hist = histogram.n\\n-                    np.testing.assert_almost_equal(mu, sum_hist,\\n-                                                   decimal=4)\\n+                    np.testing.assert_almost_equal(mu, sum_hist, decimal=4)\\n \\n             # check that model.likelihood_names[-1] fails\\n             with self.assertRaises(ValueError):\\n\",\"diff --git a/tests/test_template_source.py b/tests/test_template_source.py\\nindex 47e70393..151f0c71 100644\\n--- a/tests/test_template_source.py\\n+++ b/tests/test_template_source.py\\n@@ -14,3 +14,28 @@ def test_init_templates(self):\\n         likelihood_config = model_configs[\\\"likelihood_config\\\"]\\n         model = BlueiceExtendedModel(parameter_definition, likelihood_config)\\n         model.nominal_expectation_values\\n+\\n+    def test_wrong_analysis_space(self):\\n+        \\\"\\\"\\\"Test whether initializing with a wrong analysis_space raises error.\\\"\\\"\\\"\\n+        model_configs = load_yaml(\\\"unbinned_wimp_statistical_model_template_source_test.yaml\\\")\\n+        parameter_definition = model_configs[\\\"parameter_definition\\\"]\\n+        likelihood_config = model_configs[\\\"likelihood_config\\\"]\\n+        # Change the analysis space to a wrong one\\n+        space = likelihood_config[\\\"likelihood_terms\\\"][0][\\\"analysis_space\\\"]\\n+        # additive mismatch in cs1\\n+        space[0][\\\"cs1\\\"] = \\\"np.linspace(1, 101, 51)\\\"\\n+        space[1][\\\"cs2\\\"] = \\\"np.geomspace(100, 100000, 51)\\\"\\n+        with self.assertRaises(AssertionError):\\n+            _ = BlueiceExtendedModel(parameter_definition, likelihood_config)\\n+\\n+        # multiplicative mismatch in cs2\\n+        space[0][\\\"cs1\\\"] = \\\"np.linspace(0, 100, 51)\\\"\\n+        space[1][\\\"cs2\\\"] = \\\"np.geomspace(101, 101000, 51)\\\"\\n+        with self.assertRaises(AssertionError):\\n+            _ = BlueiceExtendedModel(parameter_definition, likelihood_config)\\n+\\n+        # If the dimensions are wrong we should get ValueError\\n+        space[0][\\\"cs1\\\"] = \\\"np.linspace(0, 100, 50)\\\"\\n+        space[1][\\\"cs2\\\"] = \\\"np.geomspace(100, 100000, 51)\\\"\\n+        with self.assertRaises(ValueError):\\n+            _ = BlueiceExtendedModel(parameter_definition, likelihood_config)\"]", "hints_text": ""}
