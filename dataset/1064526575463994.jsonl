{"instance_id": "1064526575463994", "repo": "akikuno/dajin2", "base_commit": "cee45aef748e23dcc95d41b724b792532dcf1e4b", "problem_statement": "two more errors in execution (one fixed):\\nAnother errors were occurred when I tried another PC.\\r\\n\\r\\nI conducted same commands after successful install in another PC:\\r\\n`DAJIN2 --control barcode01/ --sample barcode02/ --allele actc1L_cont_knockin.fa  --name act1c --genome xenLae2 --threads 8`\\r\\n\\r\\nBut another error was occurred:\\r\\n```\\r\\n2024-03-26 18:29:11, INFO, barcode01/ is now processing...\\r\\n2024-03-26 18:29:14, INFO, Preprocess barcode01/...\\r\\n2024-03-26 18:30:27, INFO, Output BAM files of barcode01/...\\r\\n2024-03-26 18:30:28, INFO, üçµ barcode01/ is finished!\\r\\n2024-03-26 18:30:28, INFO, barcode02/ is now processing...\\r\\n2024-03-26 18:30:31, INFO, Preprocess barcode02/...\\r\\n2024-03-26 18:30:38, ERROR, Catch an Exception. Traceback:\\r\\nTraceback (most recent call last):\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/bin/DAJIN2\", line 10, in <module>\\r\\n    sys.exit(execute())\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/main.py\", line 236, in execute\\r\\n    execute_single_mode(arguments)\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/main.py\", line 48, in execute_single_mode\\r\\n    core.execute_sample(arguments)\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/core/core.py\", line 120, in execute_sample\\r\\n    preprocess.cache_mutation_loci(ARGS, is_control=False)\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/core/preprocess/mutation_extractor.py\", line 322, in cache_mutation_loci\\r\\n    mutation_loci = extract_mutation_loci(\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/core/preprocess/mutation_extractor.py\", line 280, in extract_mutation_loci\\r\\n    anomal_loci = extract_anomal_loci(\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/core/preprocess/mutation_extractor.py\", line 128, in extract_anomal_loci\\r\\n    idx_outliers = detect_anomalies(values_sample, values_control, thresholds[mut], is_consensus)\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/core/preprocess/mutation_extractor.py\", line 111, in detect_anomalies\\r\\n    kmeans = MiniBatchKMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(values_subtract_reshaped)\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py\", line 1960, in fit\\r\\n    self._check_params(X)\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py\", line 1792, in _check_params\\r\\n    super()._check_params(X)\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py\", line 818, in _check_params\\r\\n    if self.n_init <= 0:\\r\\nTypeError: '<=' not supported between instances of 'str' and 'int'\\r\\n```\\r\\n\\r\\nI could fix this by updating scikit-learn by pip:\\r\\n`pip install -U scikit-learn`\\r\\n\\r\\nHowever, an another error was occurred after fixing scikit-learn:\\r\\n```\\r\\n2024-03-26 18:46:37, INFO, barcode01/ is now processing...\\r\\n2024-03-26 18:46:39, INFO, Preprocess barcode01/...\\r\\n2024-03-26 18:47:52, INFO, Output BAM files of barcode01/...\\r\\n2024-03-26 18:47:53, INFO, üçµ barcode01/ is finished!\\r\\n2024-03-26 18:47:53, INFO, barcode02/ is now processing...\\r\\n2024-03-26 18:47:56, INFO, Preprocess barcode02/...\\r\\n2024-03-26 18:48:06, INFO, Classify barcode02/...\\r\\n2024-03-26 18:48:07, INFO, Clustering barcode02/...\\r\\n2024-03-26 18:48:28, INFO, Consensus calling of barcode02/...\\r\\n2024-03-26 18:50:15, INFO, Output reports of barcode02/...\\r\\n2024-03-26 18:50:15, ERROR, Catch an Exception. Traceback:\\r\\nTraceback (most recent call last):\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/bin/DAJIN2\", line 10, in <module>\\r\\n    sys.exit(execute())\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/main.py\", line 236, in execute\\r\\n    execute_single_mode(arguments)\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/main.py\", line 48, in execute_single_mode\\r\\n    core.execute_sample(arguments)\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/core/core.py\", line 214, in execute_sample\\r\\n    report.report_bam.export_to_bam(\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/core/report/report_bam.py\", line 127, in export_to_bam\\r\\n    write_sam_to_bam(sam_headers + sam_content, path_sam_output, path_bam_output, THREADS)\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/site-packages/DAJIN2/core/report/report_bam.py\", line 86, in write_sam_to_bam\\r\\n    Path(path_sam).write_text(formatted_sam + \"\\n\")\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/pathlib.py\", line 1154, in write_text\\r\\n    with self.open(mode='w', encoding=encoding, errors=errors, newline=newline) as f:\\r\\n  File \"/home/igawa/miniconda3/envs/dajin2/lib/python3.10/pathlib.py\", line 1119, in open\\r\\n    return self._accessor.open(self, mode, buffering, encoding, errors,\\r\\nFileNotFoundError: [Errno 2] No such file or directory: 'DAJIN_Results/.tempdir/act1c/report/bam/tmp240891_allele1_control_indels_40.876%.sam'\\r\\n```\\r\\nIt may be an error in dajin2 code, specifically in pathlib.py?\\r\\nI'm happy if this error will be fixed by dajin2 update.\\r\\n\\r\\nThanks,", "FAIL_TO_PASS": ["tests/src/report/test_mutation_exporter.py::test_revcomp_cssplits_insertion", "tests/src/report/test_mutation_exporter.py::test_report_mutations_genome_coodinates", "tests/src/report/test_mutation_exporter.py::test_revcomp_cssplits_substitution_with_N", "tests/src/report/test_mutation_exporter.py::test_group_by_mutation_inversion", "tests/src/report/test_mutation_exporter.py::test_revcomp_cssplits_N", "tests/src/report/test_mutation_exporter.py::test_report_mutations_inversion", "tests/src/report/test_mutation_exporter.py::test_revcomp_cssplits_insertion_with_N", "tests/src/report/test_mutation_exporter.py::test_report_mutations_various", "tests/src/report/test_sequence_exporter.py::test_convert_to_fasta", "tests/src/report/test_mutation_exporter.py::test_revcomp_cssplits_insertion_long", "tests/src/report/test_mutation_exporter.py::test_revcomp_cssplits_substitution", "tests/src/report/test_mutation_exporter.py::test_report_mutations_substitution", "tests/src/report/test_mutation_exporter.py::test_annotate_inversion", "tests/src/report/test_mutation_exporter.py::test_group_by_mutation_deletion", "tests/src/report/test_mutation_exporter.py::test_revcomp_cssplits_insertion_with_substitution", "tests/src/report/test_mutation_exporter.py::test_group_by_mutation_insertion", "tests/src/report/test_mutation_exporter.py::test_report_mutations_consecutive_substitution", "tests/src/report/test_mutation_exporter.py::test_report_mutations_deletion", "tests/src/report/test_mutation_exporter.py::test_report_mutations_insertion", "tests/src/report/test_mutation_exporter.py::test_revcomp_cssplits_deletion", "tests/src/report/test_mutation_exporter.py::test_revcomp_cssplits_inversion", "tests/src/report/test_mutation_exporter.py::test_report_mutations_insertion_with_substitution"], "PASS_TO_PASS": ["tests/src/utils/test_fastx_handler.py::test_extract_filename_change_filename", "tests/src/consensus/test_consensus.py::test_replace_sequence_error", "tests/src/utils/test_cssplits_handler.py::test_detect_insertion_within_deletion[insertion", "tests/src/clustering/test_kmer_generator.py::test_is_generator", "tests/src/preprocess/test_midsv_caller.py::test_has_inversion_in_splice", "tests/src/utils/test_cssplits_handler.py::test_standardize_case_no_special_characters", "tests/src/utils/test_cssplits_handler.py::test_detect_insertion_within_deletion[Insertion]", "tests/src/consensus/test_name_handler.py::test_add_key_by_allele_name[clust_sample0-allele_names0-expected_output0]", "tests/src/utils/test_cssplits_handler.py::test_call_sequence[cons_percentage_by_key5-AGGGT]", "tests/src/consensus/test_name_handler.py::test_call_allele_name[cons_sequences1-cons_percentages1-FASTA_ALLELES1-50-expected_output1]", "tests/src/classification/test_classification.py::test_extract_alleles_with_max_score_multiple_reads", "tests/src/report/test_insertion_refrector.py::test_get_index_of_insertions[=ATTGAGTTT-expected2]", "tests/src/utils/test_fastx_handler.py::test_sanitize_filename_with_empty_string", "tests/src/utils/test_cssplits_handler.py::test_add_match_operator_to_n_empty_input", "tests/src/utils/test_sam_handler.py::test_is_overlapping", "tests/src/consensus/test_name_handler.py::test_call_allele_name[cons_sequences0-cons_percentages0-FASTA_ALLELES0-50-expected_output0]", "tests/src/utils/test_cssplits_handler.py::test_is_start_of_deletion[0-cssplits1-3-False]", "tests/src/report/test_insertion_refrector.py::test_split_cstag[=AT+t=T-ga+c=GTTT-expected1]", "tests/src/utils/test_cssplits_handler.py::test_adjust_cs_insertion[+A|+C|+G|=T-+A|+C|+G|+T|]", "tests/src/utils/test_cssplits_handler.py::test_adjust_cs_insertion[*AG-+G|]", "tests/src/test_main.py::test_validate_columns_extra_not_accepted", "tests/src/utils/test_cssplits_handler.py::test_adjust_cs_insertion[=G-+G|]", "tests/src/utils/test_io.py::test_write_jsonl", "tests/src/clustering/test_score_handler.py::test_discard_matches_and_ns", "tests/src/utils/test_input_validator.py::test_fasta_without_error", "tests/src/consensus/test_name_handler.py::test_update_key_by_allele_name[cons0-allele_names0-expected_output0]", "tests/src/utils/test_cssplits_handler.py::test_standardize_case_special_characters", "tests/src/utils/test_multiprocess.py::test_generate_chunks", "tests/src/clustering/test_appender.py::test_add_readnum", "tests/src/utils/test_cssplits_handler.py::test_find_n_boundaries[cssplits2-expected2]", "tests/src/consensus/test_name_handler.py::test_format_allele_label[1-10-01]", "tests/src/consensus/test_consensus.py::test_call_percentage", "tests/src/report/test_insertion_refrector.py::test_apply_insertion[cs_split0-index_of_insertions0-expected0]", "tests/src/utils/test_cssplits_handler.py::test_detect_insertion_within_deletion[11-character", "tests/src/consensus/test_clust_subsetter.py::test_subset_clust_with_empty_sample", "tests/src/clustering/test_appender.py::test_add_percent", "tests/src/utils/test_sam_handler.py::test_remove_overlapped_reads_simulation", "tests/src/clustering/test_score_handler.py::test_discard_common_error", "tests/src/consensus/test_clust_subsetter.py::test_basic_subset_clust", "tests/src/utils/test_cssplits_handler.py::test_add_match_operator_to_n_with_n_starting_strings", "tests/src/clustering/test_score_handler.py::test_call_percentage", "tests/src/report/test_insertion_refrector.py::test_convert_to_cstag[cs_insertion1-=A*gt*gt]", "tests/src/preprocess/test_mapping.py::test_make_faidx_wrap", "tests/src/utils/test_cssplits_handler.py::test_find_n_boundaries[cssplits0-expected0]", "tests/src/utils/test_cssplits_handler.py::test_is_start_of_deletion[0-cssplits0-3-True]", "tests/src/utils/test_cssplits_handler.py::test_concatenate_cssplits_mixed", "tests/src/utils/test_cssplits_handler.py::test_standardize_case_parametrized[=XYZ-=XYZ]", "tests/src/preprocess/test_mapping.py::test_to_sam_stx2_splice", "tests/src/utils/test_cssplits_handler.py::test_call_sequence[cons_percentage_by_key7-AGGGNT]", "tests/src/utils/test_cssplits_handler.py::test_find_n_boundaries[cssplits1-expected1]", "tests/src/utils/test_multiprocess.py::test_generate_chunks_larger", "tests/src/preprocess/test_midsv_caller.py::test_convert_flag_to_strand[input_sample2-expected_output2]", "tests/src/preprocess/test_midsv_caller.py::test_extract_qname_of_map_ont_simulation", "tests/src/clustering/test_label_updator.py::test_relabel_with_consective_order", "tests/src/report/test_insertion_refrector.py::test_split_cstag[=AT+t=TGA+c=GTTT-expected0]", "tests/src/utils/test_input_validator.py::test_validate_fastq_content_empty", "tests/src/utils/test_fastx_handler.py::test_sanitize_filename_with_whitespace", "tests/src/utils/test_fastx_handler.py::test_dictionize_allele_fasta", "tests/src/utils/test_input_validator.py::test_fasta_error_without_control", "tests/src/preprocess/test_mapping.py::test_to_sam_threads", "tests/src/classification/test_classification.py::test_calc_match[=A,N,=G,=T-0.75]", "tests/src/report/test_insertion_refrector.py::test_split_cstag[=AT+t=T*ga*ag+c=GTTT-expected2]", "tests/src/consensus/test_name_handler.py::test_determine_suffix[ATCG-ATCC-True-_sv]", "tests/src/utils/test_sam_handler.py::test_remove_microhomology_overlapped_softclip", "tests/src/preprocess/test_midsv_caller.py::test_convert_consecutive_indels_to_match[=A,-C,-G,-T,+T|=A-=A,-C,-G,=T,=A]", "tests/src/utils/test_multiprocess.py::test_run_with_multiple_exceptions", "tests/src/utils/test_cssplits_handler.py::test_concatenate_cssplits_plus_symbol_torio", "tests/src/consensus/test_name_handler.py::test_determine_suffix[ATCG-ATCC-False-_indels]", "tests/src/utils/test_cssplits_handler.py::test_call_sequence[cons_percentage_by_key4-AGGGAT]", "tests/src/utils/test_multiprocess.py::test_target_with_exception", "tests/src/consensus/test_name_handler.py::test_format_allele_label[10-10-10]", "tests/src/clustering/test_label_merger.py::test_merge_mixed_cluster", "tests/src/consensus/test_consensus.py::test_adjust_to_100_percent_float", "tests/src/utils/test_multiprocess.py::test_generate_chunks_empty", "tests/src/utils/test_input_validator.py::test_validate_fasta_content_no_seq", "tests/src/clustering/test_score_handler.py::test_call_count", "tests/src/utils/test_fastx_handler.py::test_extract_filename_fail", "tests/src/report/test_insertion_refrector.py::test_apply_insertion[cs_split1-index_of_insertions1-expected1]", "tests/src/utils/test_input_validator.py::test_validate_fastq_content_without_error", "tests/src/utils/test_multiprocess.py::test_run_without_exception", "tests/src/utils/test_cssplits_handler.py::test_standardize_case_parametrized[*abc-*abc]", "tests/src/utils/test_cssplits_handler.py::test_call_sequence[cons_percentage_by_key3-AAT]", "tests/src/preprocess/test_mapping.py::test_to_sam_stx2", "tests/src/utils/test_sam_handler.py::test_split_cigar", "tests/src/utils/test_sam_handler.py::test_is_header", "tests/src/utils/test_cssplits_handler.py::test_call_sequence[cons_percentage_by_key8-A]", "tests/src/utils/test_io.py::test_convert_to_posix_winpath", "tests/src/preprocess/test_midsv_caller.py::test_extract_qname_of_map_ont_real", "tests/src/utils/test_cssplits_handler.py::test_adjust_cs_insertion[N-+N|]", "tests/src/utils/test_cssplits_handler.py::test_add_match_operator_to_n_no_n_starting_strings", "tests/src/utils/test_input_validator.py::test_non_proper_fasta_format", "tests/src/utils/test_cssplits_handler.py::test_detect_insertion_within_deletion[N", "tests/src/report/test_insertion_refrector.py::test_convert_to_cstag[cs_insertion2-=A-gg*gt]", "tests/src/utils/test_sam_handler.py::test_remove_microhomology_ACGT", "tests/src/preprocess/test_midsv_caller.py::test_has_inversion_in_splice_random_inversion", "tests/src/utils/test_sam_handler.py::test_remove_microhomology_real_all_500_reads", "tests/src/utils/test_io.py::test_convert_to_posix", "tests/src/utils/test_io.py::test_count_newlines_multiple_lines", "tests/src/clustering/test_label_merger.py::test_merge_minor_cluster", "tests/src/utils/test_cssplits_handler.py::test_concatenate_cssplits_plus_symbol", "tests/src/report/test_insertion_refrector.py::test_get_index_of_insertions[-expected3]", "tests/src/clustering/test_score_handler.py::test_update_insertion_scores_in_group_to_max", "tests/src/preprocess/test_midsv_caller.py::test_convert_consecutive_indels_to_match[=A,=C,=G,=T,=A-=A,=C,=G,=T,=A]", "tests/src/utils/test_fastx_handler.py::test_sanitize_filename_with_invalid_characters", "tests/src/utils/test_cssplits_handler.py::test_detect_insertion_within_deletion[Insertion", "tests/src/utils/test_sam_handler.py::test_remove_overlapped_reads_real_sample", "tests/src/utils/test_sam_handler.py::test_remove_microhomology_real_singe_read", "tests/src/consensus/test_consensus.py::test_adjust_to_100_percent", "tests/src/utils/test_cssplits_handler.py::test_call_sequence[cons_percentage_by_key1-AT]", "tests/src/utils/test_multiprocess.py::test_generate_chunks_one", "tests/src/clustering/test_score_handler.py::test_find_max_insertion_score_in_group", "tests/src/utils/test_cssplits_handler.py::test_concatenate_cssplits_single_element", "tests/src/clustering/test_label_updator.py::test_relabel_with_consective_order_start_2", "tests/src/utils/test_fastx_handler.py::test_dictionize_allele_fasta_wrap", "tests/src/consensus/test_clust_subsetter.py::test_subset_clust_with_less_than_num", "tests/src/clustering/test_score_handler.py::test_update_insertion_score", "tests/src/utils/test_fastx_handler.py::test_sanitize_filename_with_empty_path", "tests/src/utils/test_cssplits_handler.py::test_adjust_cs_insertion[-G-None]", "tests/src/utils/test_fastx_handler.py::test_extract_filename", "tests/src/utils/test_multiprocess.py::test_run_with_exception", "tests/src/report/test_insertion_refrector.py::test_get_index_of_insertions[=AT+t=TGA+c=GTTT-expected1]", "tests/src/preprocess/test_midsv_caller.py::test_convert_flag_to_strand[input_sample1-expected_output1]", "tests/src/consensus/test_name_handler.py::test_detect_sv_threshold", "tests/src/clustering/test_kmer_generator.py::test_with_specific_mutation_loci_and_compress_ins_false", "tests/src/utils/test_io.py::test_count_newlines_single_line_no_newline", "tests/src/utils/test_io.py::test_convert_to_posix_posixpath", "tests/src/utils/test_cssplits_handler.py::test_is_within_deletion[-A", "tests/src/utils/test_cssplits_handler.py::test_call_sequence[cons_percentage_by_key2-ACT]", "tests/src/utils/test_cssplits_handler.py::test_detect_insertion_within_deletion[10-character", "tests/src/test_main.py::test_validate_columns_missing_required", "tests/src/report/test_insertion_refrector.py::test_get_index_of_insertions[=AT+aatct=TGAGTTT-expected0]", "tests/src/classification/test_classification.py::test_calc_match[=A,-C,-G,=T-0.5]", "tests/src/consensus/test_clust_subsetter.py::test_subset_clust_with_custom_num", "tests/src/preprocess/test_mapping.py::test_make_faidx_real", "tests/src/utils/test_cssplits_handler.py::test_call_sequence[cons_percentage_by_key6-AGGGTT]", "tests/src/preprocess/test_midsv_caller.py::test_convert_consecutive_indels_to_match[=A,-C,-G,-T,+G|+T|=A-=A,-C,=G,=T,=A]", "tests/src/utils/test_cssplits_handler.py::test_standardize_case_parametrized[-DEF--def]", "tests/src/classification/test_classification.py::test_extract_alleles_with_max_score", "tests/src/preprocess/test_mapping.py::test_make_faidx", "tests/src/preprocess/test_midsv_caller.py::test_replace_internal_n_to_d", "tests/src/utils/test_sam_handler.py::test_calculate_alignment_length", "tests/src/clustering/test_score_handler.py::test_subtract_percentage", "tests/src/utils/test_fastx_handler.py::test_dictionize_allele_empty", "tests/src/utils/test_sam_handler.py::test_revcomp_sam", "tests/src/clustering/test_label_merger.py::test_map_clusters_to_previous", "tests/src/preprocess/test_midsv_caller.py::test_has_inversion_in_splice_random_deletion", "tests/src/preprocess/test_midsv_caller.py::test_convert_consecutive_indels_to_match[=A,-C,-G,-T,+C|+G|+T|=A-=A,=C,=G,=T,=A]", "tests/src/report/test_insertion_refrector.py::test_convert_to_cstag[cs_insertion0-=AT+ttacgt=TT]", "tests/src/utils/test_cssplits_handler.py::test_standardize_case_empty_input", "tests/src/utils/test_cssplits_handler.py::test_find_n_boundaries[cssplits3-expected3]", "tests/src/preprocess/test_midsv_caller.py::test_convert_consecutive_indels_to_match[-]", "tests/src/clustering/test_kmer_generator.py::test_with_specific_mutation_loci_and_compress_ins_true", "tests/src/utils/test_io.py::test_count_newlines_empty_file", "tests/src/utils/test_cssplits_handler.py::test_standardize_case_parametrized[+GHI-+ghi]", "tests/src/utils/test_cssplits_handler.py::test_concatenate_cssplits_same_symbols", "tests/src/utils/test_cssplits_handler.py::test_concatenate_cssplits_empty_input", "tests/src/utils/test_sam_handler.py::test_remove_microhomology_insertion", "tests/src/consensus/test_clust_subsetter.py::test_subset_clust_with_multiple_labels", "tests/src/preprocess/test_midsv_caller.py::test_replace_internal_n_to_d_multiple_samples", "tests/src/classification/test_classification.py::test_calc_match[=A,*CT,=G,=T-0.75]", "tests/src/classification/test_classification.py::test_calc_match[=A,=C,=G,=T-1.0]", "tests/src/utils/test_sam_handler.py::test_is_mapped", "tests/src/utils/test_sam_handler.py::test_reverse_flag", "tests/src/clustering/test_score_handler.py::test_group_consecutive_insertions", "tests/src/report/test_insertion_refrector.py::test_split_cstag[-expected3]", "tests/src/utils/test_input_validator.py::test_fasta_error_duplicated_sequences", "tests/src/preprocess/test_mapping.py::test_to_sam_tyr", "tests/src/utils/test_cssplits_handler.py::test_standardize_case_mixed", "tests/src/preprocess/test_midsv_caller.py::test_convert_flag_to_strand[input_sample0-expected_output0]", "tests/src/utils/test_sam_handler.py::test_remove_microhomology_deletion", "tests/src/utils/test_input_validator.py::test_fastq_extension", "tests/src/utils/test_cssplits_handler.py::test_is_within_deletion[-T", "tests/src/preprocess/test_midsv_caller.py::test_replace_internal_n_to_d_large_n", "tests/src/consensus/test_name_handler.py::test_format_allele_label[1-1000-0001]", "tests/src/test_main.py::test_validate_columns_all_required_present", "tests/src/consensus/test_name_handler.py::test_determine_suffix[ATCG-ATCG-False-_intact]", "tests/src/consensus/test_clust_subsetter.py::test_subset_clust_with_multiple_labels_with_less_than_nu", "tests/src/consensus/test_name_handler.py::test_format_allele_label[5-100-005]", "tests/src/classification/test_classification.py::test_calc_match[=A,=C,+T|+T|=G,=T-0.5]", "tests/src/utils/test_input_validator.py::test_exists", "tests/src/consensus/test_name_handler.py::test_format_allele_label[99-99-99]", "tests/src/utils/test_fastx_handler.py::test_sanitize_filename_with_valid_path", "tests/src/utils/test_input_validator.py::test_fasta_error_duplicated_identifiers", "tests/src/utils/test_cssplits_handler.py::test_is_start_of_deletion[1-cssplits2-3-False]", "tests/src/utils/test_cssplits_handler.py::test_call_sequence[cons_percentage_by_key0-AT]", "tests/src/utils/test_multiprocess.py::test_target_without_exception", "tests/src/preprocess/test_midsv_caller.py::test_convert_flag_to_strand[input_sample3-expected_output3]"], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/akikuno_dajin2:cee45aef748e23dcc95d41b724b792532dcf1e4b", "patch": "[\"diff --git a/docs/README_JP.md b/docs/README_JP.md\\nindex b3960b2..75209b5 100644\\n--- a/docs/README_JP.md\\n+++ b/docs/README_JP.md\\n@@ -42,6 +42,7 @@ conda activate env-dajin2\\n > CONDA_SUBDIR=osx-64 conda create -n env-dajin2 -c conda-forge -c bioconda python=3.10 DAJIN2 -y\\n > conda activate env-dajin2\\n > conda config --env --set subdir osx-64\\n+> python -c \\\"import platform; print(platform.machine())\\\" # 'arm64'„Åß„ÅØ„Å™„Åè„ÄÅ'x86_64'„Å®Ë°®Á§∫„Åï„Çå„Çã„Åì„Å®„Çí„ÅîÁ¢∫Ë™ç„Åè„Å†„Åï„ÅÑ\\n > ```\\n \\n ### [PyPI](https://pypi.org/project/DAJIN2/)\\n@@ -129,12 +130,17 @@ DAJIN2 <-c|--control> <-s|--sample> <-a|--allele> <-n|--name> \\\\\\n #### ÂÆüË°å‰æã\\n \\n ```bash\\n+# Example dataset„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\\n+wget https://github.com/akikuno/DAJIN2/raw/main/examples/example_single.tar.gz\\n+tar -xf example_single.tar.gz\\n+\\n+# DAJIN2„ÅÆÂÆüË°åÔºàÂçò‰∏Ä„Çµ„É≥„Éó„É´Ëß£ÊûêÔºâ\\n DAJIN2 \\\\\\n-    --control example/barcode01 \\\\\\n-    --sample example/barcode02 \\\\\\n-    --allele example/design.fa \\\\\\n-    --name IL6-knockin \\\\\\n-    --genome hg38 \\\\\\n+    --control example_single/control \\\\\\n+    --sample example_single/sample \\\\\\n+    --allele example_single/stx2_deletion.fa \\\\\\n+    --name stx2_deletion \\\\\\n+    --genome mm39 \\\\\\n     --threads 4\\n ```\\n \\n@@ -193,6 +199,11 @@ DAJIN2 batch <-f|--file> [-t|--threads] [-h]\\n #### ÂÆüË°å‰æã\\n \\n ```bash\\n+# Example dataset„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\\n+wget https://github.com/akikuno/DAJIN2/raw/main/examples/example_batch.tar.gz\\n+tar -xf example_batch.tar.gz\\n+\\n+# DAJIN2„ÅÆÂÆüË°åÔºà„Éê„ÉÉ„ÉÅÂá¶ÁêÜÔºâ\\n DAJIN2 --file batch.csv --threads 4\\n ```\\n \\n\",\"diff --git a/requirements.txt b/requirements.txt\\nindex 27870a7..e109e52 100644\\n--- a/requirements.txt\\n+++ b/requirements.txt\\n@@ -1,20 +1,20 @@\\n-numpy >= 1.20.0\\n-scipy >= 1.6.0\\n+numpy >= 1.24.0\\n+scipy >= 1.10.0\\n pandas >= 1.0.0\\n-openpyxl >= 3.0.0\\n-rapidfuzz >=3.0.0\\n-scikit-learn >= 1.0.0\\n+openpyxl >= 3.1.0\\n+rapidfuzz >=3.6.0\\n+scikit-learn >= 1.3.0\\n \\n mappy >= 2.24\\n-pysam >= 0.19.0\\n+pysam >= 0.21.0\\n \\n Flask >= 2.2.0\\n waitress >= 2.1.0\\n Jinja2 >= 3.1.0\\n \\n-plotly >= 5.0.0\\n+plotly >= 5.19.0\\n kaleido >= 0.2.0\\n \\n cstag >= 1.0.0\\n-midsv >= 0.10.1\\n-wslPath >=0.3.0\\n+midsv >= 0.11.0\\n+wslPath >=0.4.1\\n\",\"diff --git a/setup.py b/setup.py\\nindex 87c7e03..a264177 100644\\n--- a/setup.py\\n+++ b/setup.py\\n@@ -9,7 +9,7 @@ with open(\\\"requirements.txt\\\") as requirements_file:\\n \\n setuptools.setup(\\n     name=\\\"DAJIN2\\\",\\n-    version=\\\"0.4.2\\\",\\n+    version=\\\"0.4.3\\\",\\n     author=\\\"Akihiro Kuno\\\",\\n     author_email=\\\"akuno@md.tsukuba.ac.jp\\\",\\n     description=\\\"One-step genotyping tools for targeted long-read sequencing\\\",\\n\",\"diff --git a/src/DAJIN2/core/clustering/label_merger.py b/src/DAJIN2/core/clustering/label_merger.py\\nindex da132e9..42cd17c 100644\\n--- a/src/DAJIN2/core/clustering/label_merger.py\\n+++ b/src/DAJIN2/core/clustering/label_merger.py\\n@@ -11,20 +11,6 @@ def calculate_label_percentages(labels: list[int]) -> dict[int, float]:\\n     return {label: (count / total_labels * 100) for label, count in label_counts.items()}\\n \\n \\n-def merge_mixed_cluster(labels_control: list[int], labels_sample: list[int], threshold: float = 0.5) -> list[int]:\\n-    \\\"\\\"\\\"Merge labels in sample if they appear more than 'threshold' percentage in control.\\\"\\\"\\\"\\n-    labels_merged = labels_sample.copy()\\n-    label_percentages_control = calculate_label_percentages(labels_control)\\n-    mixed_labels = {label for label, percent in label_percentages_control.items() if percent > threshold}\\n-\\n-    new_label = max(labels_merged) + 1\\n-    for i, label in enumerate(labels_sample):\\n-        if label in mixed_labels:\\n-            labels_merged[i] = new_label\\n-\\n-    return labels_merged\\n-\\n-\\n def map_clusters_to_previous(labels_sample: list[int], labels_previous: list[int]) -> dict[int, int]:\\n     \\\"\\\"\\\"\\n     Determine which cluster in labels_previous corresponds to each cluster in labels_sample.\\n@@ -63,6 +49,8 @@ def merge_minor_cluster(\\n     minor_labels_percentage = {label for label, percent in label_percentages.items() if percent < threshold_percentage}\\n     minor_labels_readnumber = {label for label, num in Counter(labels_sample).items() if num <= threshold_readnumber}\\n     minor_labels = minor_labels_percentage | minor_labels_readnumber\\n+    if minor_labels == set():\\n+        return labels_sample\\n \\n     correspondence = map_clusters_to_previous(labels_sample, labels_previous)\\n     update_required_labels = get_update_required_labels(correspondence)\\n@@ -70,7 +58,23 @@ def merge_minor_cluster(\\n     labels_merged = labels_sample.copy()\\n     for m in minor_labels:\\n         new_label = max(labels_merged) + 1\\n-        labels_merged = [new_label if label in update_required_labels[correspondence[m]] else label for label in labels_merged]\\n+        labels_merged = [\\n+            new_label if label in update_required_labels[correspondence[m]] else label for label in labels_merged\\n+        ]\\n+\\n+    return labels_merged\\n+\\n+\\n+def merge_mixed_cluster(labels_control: list[int], labels_sample: list[int], threshold: float = 0.5) -> list[int]:\\n+    \\\"\\\"\\\"Merge labels in sample if they appear more than 'threshold' percentage in control.\\\"\\\"\\\"\\n+    labels_merged = labels_sample.copy()\\n+    label_percentages_control = calculate_label_percentages(labels_control)\\n+    mixed_labels = {label for label, percent in label_percentages_control.items() if percent > threshold}\\n+\\n+    new_label = max(labels_merged) + 1\\n+    for i, label in enumerate(labels_sample):\\n+        if label in mixed_labels:\\n+            labels_merged[i] = new_label\\n \\n     return labels_merged\\n \\n@@ -82,7 +86,7 @@ def merge_minor_cluster(\\n \\n def merge_labels(labels_control: list[int], labels_sample: list[int], labels_previous: list[int]) -> list[int]:\\n     labels_merged = merge_minor_cluster(\\n-        labels_sample, labels_previous, threshold_percentage=0.5, threshold_readnumber=10\\n+        labels_sample, labels_previous, threshold_percentage=0.5, threshold_readnumber=5\\n     )\\n     labels_merged = merge_mixed_cluster(labels_control, labels_merged)\\n     return labels_merged\\n\",\"diff --git a/src/DAJIN2/core/core.py b/src/DAJIN2/core/core.py\\nindex c7ee727..30708fd 100644\\n--- a/src/DAJIN2/core/core.py\\n+++ b/src/DAJIN2/core/core.py\\n@@ -70,8 +70,8 @@ def execute_control(arguments: dict):\\n     # Output BAM files\\n     ###########################################################\\n     logger.info(f\\\"Output BAM files of {arguments['control']}...\\\")\\n-    report.report_bam.export_to_bam(\\n-        ARGS.tempdir, ARGS.control_name, ARGS.genome_coordinates, ARGS.threads, is_control=True\\n+    report.bam_exporter.export_to_bam(\\n+        ARGS.tempdir, ARGS.control_name, ARGS.genome_coordinates, ARGS.threads, ARGS.uuid, is_control=True\\n     )\\n     ###########################################################\\n     # Finish call\\n@@ -204,15 +204,15 @@ def execute_sample(arguments: dict):\\n     # RESULT\\n     io.write_jsonl(RESULT_SAMPLE, Path(ARGS.tempdir, \\\"result\\\", f\\\"{ARGS.sample_name}.jsonl\\\"))\\n     # FASTA\\n-    report.report_files.export_to_fasta(ARGS.tempdir, ARGS.sample_name, cons_sequence)\\n-    report.report_files.export_reference_to_fasta(ARGS.tempdir, ARGS.sample_name)\\n+    report.sequence_exporter.export_to_fasta(ARGS.tempdir, ARGS.sample_name, cons_sequence)\\n+    report.sequence_exporter.export_reference_to_fasta(ARGS.tempdir, ARGS.sample_name)\\n     # HTML\\n-    report.report_files.export_to_html(ARGS.tempdir, ARGS.sample_name, cons_percentage)\\n+    report.sequence_exporter.export_to_html(ARGS.tempdir, ARGS.sample_name, cons_percentage)\\n     # CSV (Allele Info)\\n-    report.report_mutation.export_to_csv(ARGS.tempdir, ARGS.sample_name, ARGS.genome_coordinates, cons_percentage)\\n+    report.mutation_exporter.export_to_csv(ARGS.tempdir, ARGS.sample_name, ARGS.genome_coordinates, cons_percentage)\\n     # BAM\\n-    report.report_bam.export_to_bam(\\n-        ARGS.tempdir, ARGS.sample_name, ARGS.genome_coordinates, ARGS.threads, RESULT_SAMPLE\\n+    report.bam_exporter.export_to_bam(\\n+        ARGS.tempdir, ARGS.sample_name, ARGS.genome_coordinates, ARGS.threads, ARGS.uuid, RESULT_SAMPLE\\n     )\\n     for path_bam_igvjs in Path(ARGS.tempdir, \\\"cache\\\", \\\".igvjs\\\").glob(f\\\"{ARGS.control_name}_control.bam*\\\"):\\n         shutil.copy(path_bam_igvjs, Path(ARGS.tempdir, \\\"report\\\", \\\".igvjs\\\", ARGS.sample_name))\\n\",\"diff --git a/src/DAJIN2/core/preprocess/genome_fetcher.py b/src/DAJIN2/core/preprocess/genome_fetcher.py\\nindex 0f75ec7..5e95889 100644\\n--- a/src/DAJIN2/core/preprocess/genome_fetcher.py\\n+++ b/src/DAJIN2/core/preprocess/genome_fetcher.py\\n@@ -5,11 +5,19 @@ from urllib.request import urlopen\\n \\n def fetch_seq_coordinates(genome: str, blat_url: str, seq: str) -> dict:\\n     url = f\\\"{blat_url}?db={genome}&type=BLAT&userSeq={seq}\\\"\\n-    response = urlopen(url).read().decode(\\\"utf8\\\").split(\\\"\\\\n\\\")\\n-    matches = [x for x in response if \\\"100.0%\\\" in x]\\n+    records = urlopen(url).read().decode(\\\"utf8\\\").split(\\\"\\\\n\\\")\\n+    matches = []\\n+    for record in records:\\n+        if \\\"100.0%\\\" not in record:\\n+            continue\\n+        record_trim = [r for r in record.split(\\\" \\\") if r]\\n+        if record_trim[-1] == str(len(seq)):\\n+            matches = record_trim\\n+\\n     if not matches:\\n         raise ValueError(f\\\"{seq[:60]}... is not found in {genome}\\\")\\n-    chrom, strand, start, end, _ = matches[0].split()[-5:]\\n+\\n+    chrom, strand, start, end, _ = matches[-5:]\\n     return {\\\"chrom\\\": chrom, \\\"strand\\\": strand, \\\"start\\\": int(start), \\\"end\\\": int(end)}\\n \\n \\n\",\"diff --git a/src/DAJIN2/core/preprocess/midsv_caller.py b/src/DAJIN2/core/preprocess/midsv_caller.py\\nindex 1bf7753..c57378d 100644\\n--- a/src/DAJIN2/core/preprocess/midsv_caller.py\\n+++ b/src/DAJIN2/core/preprocess/midsv_caller.py\\n@@ -8,8 +8,7 @@ from itertools import chain, groupby\\n \\n from collections import Counter\\n \\n-from DAJIN2.utils import sam_handler\\n-from DAJIN2.utils import cssplits_handler\\n+from DAJIN2.utils import io, sam_handler, cssplits_handler\\n \\n \\n def has_inversion_in_splice(CIGAR: str) -> bool:\\n@@ -215,8 +214,8 @@ def generate_midsv(ARGS, is_control: bool = False, is_insertion: bool = False) -\\n             path_splice = Path(ARGS.tempdir, name, \\\"sam\\\", f\\\"splice_{allele}.sam\\\")\\n             path_output_midsv = Path(ARGS.tempdir, name, \\\"midsv\\\", f\\\"{allele}.json\\\")\\n \\n-        sam_ont = sam_handler.remove_overlapped_reads(list(sam_handler.read_sam(path_ont)))\\n-        sam_splice = sam_handler.remove_overlapped_reads(list(sam_handler.read_sam(path_splice)))\\n+        sam_ont = sam_handler.remove_overlapped_reads(list(io.read_sam(path_ont)))\\n+        sam_splice = sam_handler.remove_overlapped_reads(list(io.read_sam(path_splice)))\\n         qname_of_map_ont = extract_qname_of_map_ont(sam_ont, sam_splice)\\n         sam_of_map_ont = filter_sam_by_preset(sam_ont, qname_of_map_ont, preset=\\\"map-ont\\\")\\n         sam_of_splice = filter_sam_by_preset(sam_splice, qname_of_map_ont, preset=\\\"splice\\\")\\n\",\"diff --git a/src/DAJIN2/core/report/__init__.py b/src/DAJIN2/core/report/__init__.py\\nindex 638ea37..23934c6 100644\\n--- a/src/DAJIN2/core/report/__init__.py\\n+++ b/src/DAJIN2/core/report/__init__.py\\n@@ -1,3 +1,3 @@\\n-from DAJIN2.core.report import report_bam\\n-from DAJIN2.core.report import report_files\\n-from DAJIN2.core.report import report_mutation\\n+from DAJIN2.core.report import bam_exporter\\n+from DAJIN2.core.report import sequence_exporter\\n+from DAJIN2.core.report import mutation_exporter\\n\",\"diff --git a/src/DAJIN2/core/report/bam_exporter.py b/src/DAJIN2/core/report/bam_exporter.py\\nnew file mode 100644\\nindex 0000000..e6b86fc\\n--- /dev/null\\n+++ b/src/DAJIN2/core/report/bam_exporter.py\\n@@ -0,0 +1,149 @@\\n+from __future__ import annotations\\n+\\n+from collections import defaultdict\\n+from itertools import groupby\\n+from pathlib import Path\\n+\\n+import pysam\\n+\\n+from DAJIN2.utils import io, sam_handler\\n+\\n+\\n+def recalculate_sam_coodinates_to_reference(sam: list[list[str]], GENOME_COODINATES: dict) -> list[str]:\\n+    \\\"\\\"\\\"Recalculate SAM genomic coordinates with the reference genome, not with the FASTA_ALLELE\\\"\\\"\\\"\\n+    sam_headers = [s for s in sam if s[0].startswith(\\\"@\\\")]\\n+    sam_contents = [s for s in sam if not s[0].startswith(\\\"@\\\")]\\n+    for s in sam_headers:\\n+        if s[0] != \\\"@SQ\\\":\\n+            continue\\n+        s[1] = f'SN:{GENOME_COODINATES[\\\"chrom\\\"]}'\\n+        s[2] = f'LN:{GENOME_COODINATES[\\\"chrom_size\\\"]}'\\n+    for s in sam_contents:\\n+        s[2] = GENOME_COODINATES[\\\"chrom\\\"]\\n+    if GENOME_COODINATES[\\\"strand\\\"] == \\\"-\\\":\\n+        sam_contents = sam_handler.revcomp_sam(sam_contents, GENOME_COODINATES[\\\"end\\\"])\\n+    else:\\n+        for s in sam_contents:\\n+            s[3] = str(int(s[3]) + GENOME_COODINATES[\\\"start\\\"] - 1)\\n+    return sam_headers + sam_contents\\n+\\n+\\n+def convert_pos_to_one_indexed(sam_lines: list[list[str]]) -> list[list[str]]:\\n+    \\\"\\\"\\\"Convert SAM POS from 0-indexed to 1-indexed\\\"\\\"\\\"\\n+\\n+    def convert_line(line: list[str]) -> list[str]:\\n+        if not line[0].startswith(\\\"@\\\") and line[3] == \\\"0\\\":\\n+            line[3] = \\\"1\\\"\\n+        return line\\n+\\n+    return [convert_line(line) for line in sam_lines]\\n+\\n+\\n+def group_by_name(sam_contents: list[str], clust_sample: list[dict]) -> dict[list]:\\n+    \\\"\\\"\\\"Group alignments in map-ont.sam by allele name (NAME)\\\"\\\"\\\"\\n+    sam_contents.sort()\\n+    clust_sample_sorted = sorted(clust_sample, key=lambda x: x[\\\"QNAME\\\"])\\n+\\n+    qnames: set[str] = {c[\\\"QNAME\\\"] for c in clust_sample_sorted}\\n+\\n+    sam_groups = defaultdict(list)\\n+    idx_sam_contents = 0\\n+    idx_clust_sample = 0\\n+    while idx_sam_contents < len(sam_contents) and idx_clust_sample < len(clust_sample_sorted):\\n+        alignments_sam = sam_contents[idx_sam_contents][:-1]  # Discard CS tags to reduce file size\\n+        alignments_clsut_sample = clust_sample_sorted[idx_clust_sample]\\n+        qname_sam = alignments_sam[0]\\n+\\n+        if qname_sam not in qnames:\\n+            idx_sam_contents += 1\\n+            continue\\n+\\n+        if qname_sam == alignments_clsut_sample[\\\"QNAME\\\"]:\\n+            key = alignments_clsut_sample[\\\"NAME\\\"]\\n+            sam_groups[key].append(alignments_sam)\\n+            idx_sam_contents += 1\\n+        else:\\n+            idx_clust_sample += 1\\n+\\n+    return dict(sam_groups)\\n+\\n+\\n+###############################################################################\\n+# igvjs\\n+###############################################################################\\n+\\n+\\n+def subset_qnames(RESULT_SAMPLE, readnum: int = 100) -> dict[set[str]]:\\n+    qnames_by_name = defaultdict(set)\\n+    for name, group in groupby(RESULT_SAMPLE, key=lambda x: x[\\\"NAME\\\"]):\\n+        group = list(group)\\n+        qnames = [res[\\\"QNAME\\\"] for res in group[:readnum]]\\n+        qnames_by_name[name] = set(qnames)\\n+    return dict(qnames_by_name)\\n+\\n+\\n+def subset_reads(sam_content: list[str], qnames: set[str]) -> list[str]:\\n+    return [sam for sam in sam_content if sam[0] in qnames]\\n+\\n+\\n+###############################################################################\\n+# Output\\n+###############################################################################\\n+\\n+\\n+def write_sam_to_bam(sam: list[list[str]], path_sam: str | Path, path_bam: str | Path, threads: int = 1) -> None:\\n+    formatted_sam = \\\"\\\\n\\\".join(\\\"\\\\t\\\".join(s) for s in sam)\\n+    Path(path_sam).write_text(formatted_sam + \\\"\\\\n\\\")\\n+    pysam.sort(\\\"-@\\\", f\\\"{threads}\\\", \\\"-o\\\", str(path_bam), str(path_sam))\\n+    pysam.index(\\\"-@\\\", f\\\"{threads}\\\", str(path_bam))\\n+\\n+\\n+def update_sam(sam: list, GENOME_COODINATES: dict = {}) -> list:\\n+    sam_records = sam.copy()\\n+    sam_records = sam_handler.remove_overlapped_reads(sam_records)\\n+    sam_records = sam_handler.remove_microhomology(sam_records)\\n+    if GENOME_COODINATES[\\\"genome\\\"]:\\n+        return recalculate_sam_coodinates_to_reference(sam_records, GENOME_COODINATES)\\n+    else:\\n+        return convert_pos_to_one_indexed(sam_records)\\n+\\n+\\n+def export_to_bam(TEMPDIR, NAME, GENOME_COODINATES, THREADS, UUID, RESULT_SAMPLE=None, is_control=False) -> None:\\n+    path_sam_input = Path(TEMPDIR, NAME, \\\"sam\\\", \\\"map-ont_control.sam\\\")\\n+    sam_records = list(io.read_sam(path_sam_input))\\n+\\n+    # Update sam\\n+    sam_updated = update_sam(sam_records, GENOME_COODINATES)\\n+\\n+    # Output SAM and BAM\\n+    path_sam_output = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\", f\\\"temp_{UUID}_{NAME}_control.sam\\\")\\n+    path_bam_output = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\", NAME, f\\\"{NAME}.bam\\\")\\n+    write_sam_to_bam(sam_updated, path_sam_output, path_bam_output, THREADS)\\n+\\n+    # Prepare SAM headers and contents\\n+    sam_headers = [s for s in sam_updated if s[0].startswith(\\\"@\\\")]\\n+    sam_contents = [s for s in sam_updated if not s[0].startswith(\\\"@\\\")]\\n+    if is_control:\\n+        qnames: set[str] = set(list(set(s[0] for s in sam_contents[:10000]))[:100])\\n+        sam_subset = [s for s in sam_updated if s[0] in qnames]\\n+        path_sam_output = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\", f\\\"temp_{UUID}_{NAME}_control_cache.sam\\\")\\n+        path_bam_output = Path(TEMPDIR, \\\"cache\\\", \\\".igvjs\\\", NAME, \\\"control.bam\\\")\\n+        write_sam_to_bam(sam_headers + sam_subset, path_sam_output, path_bam_output, THREADS)\\n+    else:\\n+        sam_groups = group_by_name(sam_contents, RESULT_SAMPLE)\\n+        qnames_by_name = subset_qnames(RESULT_SAMPLE)\\n+        # Output SAM and BAM\\n+        for name, sam_content in sam_groups.items():\\n+            # BAM\\n+            path_sam_output = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\", f\\\"temp_{UUID}_{name}.sam\\\")\\n+            path_bam_output = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\", NAME, f\\\"{NAME}_{name}.bam\\\")\\n+            write_sam_to_bam(sam_headers + sam_content, path_sam_output, path_bam_output, THREADS)\\n+            # igvjs\\n+            sam_subset = subset_reads(sam_content, qnames_by_name[name])\\n+            path_sam_output = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\", f\\\"temp_{UUID}_{name}_subset.sam\\\")\\n+            path_bam_output = Path(TEMPDIR, \\\"report\\\", \\\".igvjs\\\", NAME, f\\\"{name}.bam\\\")\\n+            write_sam_to_bam(sam_headers + sam_subset, path_sam_output, path_bam_output, THREADS)\\n+\\n+    # Remove temporary files\\n+    sam_temp = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\").glob(f\\\"temp_{UUID}*.sam\\\")\\n+    [s.unlink() for s in sam_temp]\\n\",\"diff --git a/src/DAJIN2/core/report/mutation_exporter.py b/src/DAJIN2/core/report/mutation_exporter.py\\nnew file mode 100644\\nindex 0000000..f388243\\n--- /dev/null\\n+++ b/src/DAJIN2/core/report/mutation_exporter.py\\n@@ -0,0 +1,146 @@\\n+from __future__ import annotations\\n+\\n+\\n+from pathlib import Path\\n+from itertools import groupby\\n+from DAJIN2.utils.cssplits_handler import revcomp_cssplits\\n+\\n+# import midsv\\n+# from DAJIN2.core import preprocess\\n+\\n+###########################################################\\n+# group by mutation\\n+###########################################################\\n+\\n+\\n+def annotate_inversion(cssplits: list[str]) -> list[str]:\\n+    return [\\\"@\\\" + cs if cs[-1].islower() else cs for cs in cssplits]\\n+\\n+\\n+def group_by_mutation(cssplits: list[str]) -> list[list[str]]:\\n+    return [list(group) for _, group in groupby(cssplits, key=lambda x: x[0])]\\n+\\n+\\n+def flatten(lst: list[list]) -> list:\\n+    results_flattend = []\\n+    for result in lst:\\n+        if isinstance(result[0], list):\\n+            for res in result:\\n+                results_flattend.append(res)\\n+        else:\\n+            results_flattend.append(result)\\n+    return results_flattend\\n+\\n+\\n+###########################################################\\n+# report mutations\\n+###########################################################\\n+\\n+\\n+def _handle_match(group, genome, start, end, header, chromosome):\\n+    end += len(group)\\n+    start = end\\n+    return None, start, end\\n+\\n+\\n+def _handle_substitution(group, genome, start, end, header, chromosome):\\n+    result = []\\n+    for g in group:\\n+        ref = g[1]\\n+        mut = g[2]\\n+        result.append([header, genome, chromosome, start, end, f\\\"substitution: {ref}>{mut}\\\"])\\n+        end += 1\\n+        start = end\\n+    if len(result) == 1:\\n+        result = result[0]\\n+    return result, start, end\\n+\\n+\\n+def _handle_deletion(group, genome, start, end, header, chromosome):\\n+    end += len(group) - 1\\n+    size = len(group)\\n+    seq = \\\"\\\".join([g[-1] for g in group])\\n+    result = [header, genome, chromosome, start, end, f\\\"{size}bp deletion: {seq}\\\"]\\n+    end += 1\\n+    start = end\\n+    return result, start, end\\n+\\n+\\n+def _handle_insertion(group, genome, start, end, header, chromosome):\\n+    group = group[0]\\n+    size = group.count(\\\"|\\\")\\n+    seq_insertion = \\\"\\\".join([g[-1] for g in group.split(\\\"|\\\")[:-1]])\\n+    seq_last = group.split(\\\"|\\\")[-1]\\n+    result = []\\n+    result.append([header, genome, chromosome, start, end, f\\\"{size}bp insertion: {seq_insertion}\\\"])\\n+    if seq_last.startswith(\\\"=\\\"):\\n+        pass\\n+    elif seq_last.startswith(\\\"-\\\"):\\n+        result.append([header, genome, chromosome, start, end, f\\\"1bp deletion: {seq_last[-1]}\\\"])\\n+    if len(result) == 1:\\n+        result = result[0]\\n+    end += 1\\n+    start = end\\n+    return result, start, end\\n+\\n+\\n+def _handle_inversion(group, genome, start, end, header, chromosome):\\n+    end += len(group) - 1\\n+    size = len(group)\\n+    seq = \\\"\\\".join([g[-1].upper() for g in group])\\n+    result = [header, genome, chromosome, start, end, f\\\"{size}bp inversion: {seq}\\\"]\\n+    end += 1\\n+    start = end\\n+    return result, start, end\\n+\\n+\\n+def _handle_unknown(group, genome, start, end, header, chromosome):\\n+    end += len(group) - 1\\n+    size = len(group)\\n+    result = [header, genome, chromosome, start, end, f\\\"{size}bp unknown bases\\\"]\\n+    end += 1\\n+    start = end\\n+    return result, start, end\\n+\\n+\\n+def report_mutations(cssplits_grouped, GENOME_COORDINATES, header):\\n+    genome = GENOME_COORDINATES[\\\"genome\\\"]\\n+    chromosome = GENOME_COORDINATES[\\\"chrom\\\"]\\n+    start = end = GENOME_COORDINATES[\\\"start\\\"]\\n+    handlers = {\\n+        \\\"=\\\": _handle_match,\\n+        \\\"*\\\": _handle_substitution,\\n+        \\\"-\\\": _handle_deletion,\\n+        \\\"+\\\": _handle_insertion,\\n+        \\\"@\\\": _handle_inversion,\\n+        \\\"N\\\": _handle_unknown,\\n+    }\\n+    results = []\\n+    for group in cssplits_grouped:\\n+        for prefix, handler in handlers.items():\\n+            if group[0].startswith(prefix):\\n+                result, start, end = handler(group, genome, start, end, header, chromosome)\\n+                if prefix == \\\"=\\\":\\n+                    continue\\n+                results.append(result)\\n+    return flatten(results)\\n+\\n+\\n+###########################################################\\n+# main\\n+###########################################################\\n+\\n+\\n+def export_to_csv(TEMPDIR: Path | str, SAMPLE_NAME: str, GENOME_COORDINATES: dict, cons_percentage: dict[list]) -> None:\\n+    results = [[\\\"Allele ID\\\", \\\"Genome\\\", \\\"Chromosome\\\", \\\"Start\\\", \\\"End\\\", \\\"Mutation\\\"]]\\n+    for header, cons in cons_percentage.items():\\n+        cssplits = [max(c, key=c.get) for c in cons]\\n+        if GENOME_COORDINATES.get(\\\"strand\\\") == \\\"-\\\":\\n+            cssplits = revcomp_cssplits(cssplits)\\n+        cssplits_inversion = annotate_inversion(cssplits)\\n+        cssplits_grouped = group_by_mutation(cssplits_inversion)\\n+        result = report_mutations(cssplits_grouped, GENOME_COORDINATES, header)\\n+        results.extend(result)\\n+    results_csv = \\\"\\\\n\\\".join([\\\",\\\".join(map(str, r)) for r in results]) + \\\"\\\\n\\\"\\n+    path_output = Path(TEMPDIR, \\\"report\\\", \\\"MUTATION_INFO\\\", f\\\"{SAMPLE_NAME}.csv\\\")\\n+    path_output.write_text(results_csv)\\n\",\"diff --git a/src/DAJIN2/core/report/report_bam.py b/src/DAJIN2/core/report/report_bam.py\\ndeleted file mode 100644\\nindex f6c7be5..0000000\\n--- a/src/DAJIN2/core/report/report_bam.py\\n+++ /dev/null\\n@@ -1,135 +0,0 @@\\n-from __future__ import annotations\\n-\\n-import random\\n-from collections import defaultdict\\n-from itertools import groupby\\n-from pathlib import Path\\n-\\n-import midsv\\n-import pysam\\n-\\n-from DAJIN2.utils import sam_handler\\n-\\n-\\n-def realign(sam: list[list[str]], GENOME_COODINATES: dict) -> list[str]:\\n-    sam_headers = [s for s in sam if s[0].startswith(\\\"@\\\")]\\n-    sam_contents = [s for s in sam if not s[0].startswith(\\\"@\\\")]\\n-    for s in sam_headers:\\n-        if s[0] != \\\"@SQ\\\":\\n-            continue\\n-        s[1] = f'SN:{GENOME_COODINATES[\\\"chrom\\\"]}'\\n-        s[2] = f'LN:{GENOME_COODINATES[\\\"chrom_size\\\"]}'\\n-    for s in sam_contents:\\n-        s[2] = GENOME_COODINATES[\\\"chrom\\\"]\\n-    if GENOME_COODINATES[\\\"strand\\\"] == \\\"-\\\":\\n-        sam_contents = sam_handler.revcomp_sam(sam_contents, GENOME_COODINATES[\\\"end\\\"])\\n-    else:\\n-        for s in sam_contents:\\n-            s[3] = str(int(s[3]) + GENOME_COODINATES[\\\"start\\\"] - 1)\\n-    return sam_headers + sam_contents\\n-\\n-\\n-def group_by_name(sam_contents: list[str], clust_sample: list[dict]) -> dict[list]:\\n-    sam_contents.sort()\\n-    clust_sample_qname = sorted(clust_sample, key=lambda x: x[\\\"QNAME\\\"])\\n-    clust_sample_qname_set = set()\\n-    for qnames in clust_sample_qname:\\n-        qname = qnames[\\\"QNAME\\\"]\\n-        clust_sample_qname_set.add(qname)\\n-    sam_groups = defaultdict(list)\\n-    idx_left = 0\\n-    idx_right = 0\\n-    while idx_left < len(sam_contents) and idx_right < len(clust_sample_qname):\\n-        read_left = sam_contents[idx_left][:-1]\\n-        read_right = clust_sample_qname[idx_right]\\n-        qname_left = read_left[0]\\n-        qname_right = read_right[\\\"QNAME\\\"]\\n-        if qname_left not in clust_sample_qname_set:\\n-            idx_left += 1\\n-            continue\\n-        if qname_left == qname_right:\\n-            key = read_right[\\\"NAME\\\"]\\n-            sam_groups[key].append(read_left)\\n-            idx_left += 1\\n-        else:\\n-            idx_right += 1\\n-    return sam_groups\\n-\\n-\\n-###############################################################################\\n-# igvjs\\n-###############################################################################\\n-\\n-\\n-def subset_qnames(RESULT_SAMPLE, readnum: int = 100) -> dict[set[str]]:\\n-    qnames_by_name = defaultdict(set)\\n-    for name, group in groupby(RESULT_SAMPLE, key=lambda x: x[\\\"NAME\\\"]):\\n-        group = list(group)\\n-        qnames = [res[\\\"QNAME\\\"] for res in group[:readnum]]\\n-        qnames_by_name[name] = set(qnames)\\n-    return qnames_by_name\\n-\\n-\\n-def subset_reads(name, sam_content, qnames_by_name):\\n-    qnames = qnames_by_name[name]\\n-    sam_subset = [sam for sam in sam_content if sam[0] in qnames]\\n-    return sam_subset\\n-\\n-\\n-###############################################################################\\n-# Output\\n-###############################################################################\\n-\\n-\\n-def write_sam_to_bam(sam: list[list[str]], path_sam: str | Path, path_bam: str | Path, threads: int = 1) -> None:\\n-    formatted_sam = \\\"\\\\n\\\".join(\\\"\\\\t\\\".join(s) for s in sam)\\n-    Path(path_sam).write_text(formatted_sam + \\\"\\\\n\\\")\\n-    pysam.sort(\\\"-@\\\", f\\\"{threads}\\\", \\\"-o\\\", str(path_bam), str(path_sam))\\n-    pysam.index(\\\"-@\\\", f\\\"{threads}\\\", str(path_bam))\\n-\\n-\\n-def update_sam(sam: list, GENOME_COODINATES: dict = {}) -> list:\\n-    sam_update = sam.copy()\\n-    sam_update = sam_handler.remove_overlapped_reads(sam_update)\\n-    sam_update = sam_handler.remove_microhomology(sam_update)\\n-    if \\\"genome\\\" in GENOME_COODINATES:\\n-        sam_update = realign(sam_update, GENOME_COODINATES)\\n-    return sam_update\\n-\\n-\\n-def export_to_bam(TEMPDIR, NAME, GENOME_COODINATES, THREADS, RESULT_SAMPLE=None, is_control=False) -> None:\\n-    randomnum = random.randint(100_000, 999_999)\\n-    path_sam_input = Path(TEMPDIR, NAME, \\\"sam\\\", \\\"map-ont_control.sam\\\")\\n-    sam = list(midsv.read_sam(path_sam_input))\\n-    # Update sam\\n-    sam_update = update_sam(sam, GENOME_COODINATES)\\n-    # Output SAM and BAM\\n-    path_sam_output = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\", f\\\"tmp{randomnum}_{NAME}_control.sam\\\")\\n-    path_bam_output = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\", NAME, f\\\"{NAME}.bam\\\")\\n-    write_sam_to_bam(sam_update, path_sam_output, path_bam_output, THREADS)\\n-    # Prepare SAM headers and contents\\n-    sam_headers = [s for s in sam_update if s[0].startswith(\\\"@\\\")]\\n-    sam_contents = [s for s in sam_update if not s[0].startswith(\\\"@\\\")]\\n-    if is_control:\\n-        qnames = set(list(set(s[0] for s in sam_contents[:10000]))[:100])\\n-        sam_subset = [s for s in sam_update if s[0] in qnames]\\n-        path_sam_output = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\", f\\\"tmp{randomnum}_{NAME}_control_cache.sam\\\")\\n-        path_bam_output = Path(TEMPDIR, \\\"cache\\\", \\\".igvjs\\\", NAME, \\\"control.bam\\\")\\n-        write_sam_to_bam(sam_headers + sam_subset, path_sam_output, path_bam_output, THREADS)\\n-    else:\\n-        sam_groups = group_by_name(sam_contents, RESULT_SAMPLE)\\n-        qnames_by_name = subset_qnames(RESULT_SAMPLE)\\n-        # Output SAM and BAM\\n-        for name, sam_content in sam_groups.items():\\n-            # BAM\\n-            path_sam_output = Path(TEMPDIR, \\\"report\\\", \\\"bam\\\", f\\\"tmp{randomnum}_{name}.sam\\\")\\n-            path_bam_output = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\", NAME, f\\\"{NAME}_{name}.bam\\\")\\n-            write_sam_to_bam(sam_headers + sam_content, path_sam_output, path_bam_output, THREADS)\\n-            # igvjs\\n-            sam_subset = subset_reads(name, sam_content, qnames_by_name)\\n-            path_sam_output = Path(TEMPDIR, \\\"report\\\", \\\"bam\\\", f\\\"tmp{randomnum}_{name}_subset.sam\\\")\\n-            path_bam_output = Path(TEMPDIR, \\\"report\\\", \\\".igvjs\\\", NAME, f\\\"{name}.bam\\\")\\n-            write_sam_to_bam(sam_headers + sam_subset, path_sam_output, path_bam_output, THREADS)\\n-    # Remove temporary files\\n-    sam_temp = Path(TEMPDIR, \\\"report\\\", \\\"BAM\\\").glob(f\\\"tmp{randomnum}*.sam\\\")\\n-    [s.unlink() for s in sam_temp]\\n\",\"diff --git a/src/DAJIN2/core/report/report_files.py b/src/DAJIN2/core/report/report_files.py\\ndeleted file mode 100644\\nindex 3661c5b..0000000\\n--- a/src/DAJIN2/core/report/report_files.py\\n+++ /dev/null\\n@@ -1,69 +0,0 @@\\n-from __future__ import annotations\\n-\\n-import textwrap\\n-import cstag\\n-from pathlib import Path\\n-from DAJIN2.utils.cssplits_handler import convert_cssplits_to_cstag\\n-from DAJIN2.core.report.insertion_reflector import reflect_ref_insertion_to_query\\n-\\n-\\n-def convert_to_fasta(header: str, sequence: str) -> str:\\n-    header = \\\">\\\" + header\\n-    sequence_wrapped = textwrap.wrap(sequence, 80)\\n-    fasta = \\\"\\\\n\\\".join([header, *sequence_wrapped]) + \\\"\\\\n\\\"\\n-\\n-    return fasta\\n-\\n-\\n-def convert_to_html(TEMPDIR: Path, SAMPLE_NAME: str, header: str, cons_per: list[dict]) -> str:\\n-    cons_cssplit = [max(cons, key=cons.get) for cons in cons_per]\\n-    cons_cstag = convert_cssplits_to_cstag(cons_cssplit)\\n-\\n-    allele = header.split(\\\"_\\\")[1]\\n-    if Path(TEMPDIR, SAMPLE_NAME, \\\"cstag\\\", f\\\"{allele}.txt\\\").exists():\\n-        ref_cstag = Path(TEMPDIR, SAMPLE_NAME, \\\"cstag\\\", f\\\"{allele}.txt\\\").read_text()\\n-        cons_cstag = reflect_ref_insertion_to_query(ref_cstag, cons_cstag)\\n-\\n-    return cstag.to_html(cons_cstag, f\\\"{SAMPLE_NAME} {header.replace('_', ' ')}\\\")\\n-\\n-\\n-##################################################\\n-# Export files\\n-##################################################\\n-\\n-\\n-def export_to_fasta(TEMPDIR: Path, SAMPLE_NAME: str, cons_sequence: dict) -> None:\\n-    for header, sequence in cons_sequence.items():\\n-        path_output = Path(TEMPDIR, \\\"report\\\", \\\"FASTA\\\", SAMPLE_NAME, f\\\"{SAMPLE_NAME}_{header}.fasta\\\")\\n-        path_output.write_text(convert_to_fasta(f\\\"{SAMPLE_NAME}_{header}\\\", sequence))\\n-\\n-\\n-def parse_fasta(file_path: Path) -> tuple[str, str]:\\n-    \\\"\\\"\\\"Parses a FASTA file and returns the header and concatenated sequence.\\\"\\\"\\\"\\n-    with open(file_path, \\\"r\\\") as f:\\n-        lines = f.readlines()\\n-\\n-    header = lines[0].strip().lstrip(\\\">\\\")\\n-    sequence = \\\"\\\".join(line.strip() for line in lines[1:])\\n-\\n-    return header, sequence\\n-\\n-\\n-def export_reference_to_fasta(TEMPDIR: Path, SAMPLE_NAME: str) -> None:\\n-    for fasta in Path(TEMPDIR, SAMPLE_NAME, \\\"fasta\\\").glob(\\\"*.fasta\\\"):\\n-        header, sequence = parse_fasta(fasta)\\n-        path_output = Path(TEMPDIR, \\\"report\\\", \\\"FASTA\\\", SAMPLE_NAME, f\\\"{header}.fasta\\\")\\n-        path_output.write_text(convert_to_fasta(f\\\"{SAMPLE_NAME}_{header}\\\", sequence))\\n-\\n-\\n-def export_to_html(TEMPDIR: Path, SAMPLE_NAME: str, cons_percentage: dict[list]) -> None:\\n-    for header, cons_per in cons_percentage.items():\\n-        path_output = Path(TEMPDIR, \\\"report\\\", \\\"HTML\\\", SAMPLE_NAME, f\\\"{SAMPLE_NAME}_{header}.html\\\")\\n-        path_output.write_text(convert_to_html(TEMPDIR, SAMPLE_NAME, header, cons_per))\\n-\\n-\\n-# def to_vcf(TEMPDIR: Path, SAMPLE_NAME: str, GENOME_COODINATES: dict[str, str], cons_percentage: dict[list]) -> str:\\n-#     pass\\n-#     for header, cons_per in cons_percentage.items():\\n-#         path_output = Path(TEMPDIR, \\\"report\\\", \\\"HTML\\\", SAMPLE_NAME, f\\\"{SAMPLE_NAME}_{header}.vcf\\\")\\n-#         path_output.write_text(_to_html(TEMPDIR, SAMPLE_NAME, header, cons_per))\\n\",\"diff --git a/src/DAJIN2/core/report/report_mutation.py b/src/DAJIN2/core/report/report_mutation.py\\ndeleted file mode 100644\\nindex f388243..0000000\\n--- a/src/DAJIN2/core/report/report_mutation.py\\n+++ /dev/null\\n@@ -1,146 +0,0 @@\\n-from __future__ import annotations\\n-\\n-\\n-from pathlib import Path\\n-from itertools import groupby\\n-from DAJIN2.utils.cssplits_handler import revcomp_cssplits\\n-\\n-# import midsv\\n-# from DAJIN2.core import preprocess\\n-\\n-###########################################################\\n-# group by mutation\\n-###########################################################\\n-\\n-\\n-def annotate_inversion(cssplits: list[str]) -> list[str]:\\n-    return [\\\"@\\\" + cs if cs[-1].islower() else cs for cs in cssplits]\\n-\\n-\\n-def group_by_mutation(cssplits: list[str]) -> list[list[str]]:\\n-    return [list(group) for _, group in groupby(cssplits, key=lambda x: x[0])]\\n-\\n-\\n-def flatten(lst: list[list]) -> list:\\n-    results_flattend = []\\n-    for result in lst:\\n-        if isinstance(result[0], list):\\n-            for res in result:\\n-                results_flattend.append(res)\\n-        else:\\n-            results_flattend.append(result)\\n-    return results_flattend\\n-\\n-\\n-###########################################################\\n-# report mutations\\n-###########################################################\\n-\\n-\\n-def _handle_match(group, genome, start, end, header, chromosome):\\n-    end += len(group)\\n-    start = end\\n-    return None, start, end\\n-\\n-\\n-def _handle_substitution(group, genome, start, end, header, chromosome):\\n-    result = []\\n-    for g in group:\\n-        ref = g[1]\\n-        mut = g[2]\\n-        result.append([header, genome, chromosome, start, end, f\\\"substitution: {ref}>{mut}\\\"])\\n-        end += 1\\n-        start = end\\n-    if len(result) == 1:\\n-        result = result[0]\\n-    return result, start, end\\n-\\n-\\n-def _handle_deletion(group, genome, start, end, header, chromosome):\\n-    end += len(group) - 1\\n-    size = len(group)\\n-    seq = \\\"\\\".join([g[-1] for g in group])\\n-    result = [header, genome, chromosome, start, end, f\\\"{size}bp deletion: {seq}\\\"]\\n-    end += 1\\n-    start = end\\n-    return result, start, end\\n-\\n-\\n-def _handle_insertion(group, genome, start, end, header, chromosome):\\n-    group = group[0]\\n-    size = group.count(\\\"|\\\")\\n-    seq_insertion = \\\"\\\".join([g[-1] for g in group.split(\\\"|\\\")[:-1]])\\n-    seq_last = group.split(\\\"|\\\")[-1]\\n-    result = []\\n-    result.append([header, genome, chromosome, start, end, f\\\"{size}bp insertion: {seq_insertion}\\\"])\\n-    if seq_last.startswith(\\\"=\\\"):\\n-        pass\\n-    elif seq_last.startswith(\\\"-\\\"):\\n-        result.append([header, genome, chromosome, start, end, f\\\"1bp deletion: {seq_last[-1]}\\\"])\\n-    if len(result) == 1:\\n-        result = result[0]\\n-    end += 1\\n-    start = end\\n-    return result, start, end\\n-\\n-\\n-def _handle_inversion(group, genome, start, end, header, chromosome):\\n-    end += len(group) - 1\\n-    size = len(group)\\n-    seq = \\\"\\\".join([g[-1].upper() for g in group])\\n-    result = [header, genome, chromosome, start, end, f\\\"{size}bp inversion: {seq}\\\"]\\n-    end += 1\\n-    start = end\\n-    return result, start, end\\n-\\n-\\n-def _handle_unknown(group, genome, start, end, header, chromosome):\\n-    end += len(group) - 1\\n-    size = len(group)\\n-    result = [header, genome, chromosome, start, end, f\\\"{size}bp unknown bases\\\"]\\n-    end += 1\\n-    start = end\\n-    return result, start, end\\n-\\n-\\n-def report_mutations(cssplits_grouped, GENOME_COORDINATES, header):\\n-    genome = GENOME_COORDINATES[\\\"genome\\\"]\\n-    chromosome = GENOME_COORDINATES[\\\"chrom\\\"]\\n-    start = end = GENOME_COORDINATES[\\\"start\\\"]\\n-    handlers = {\\n-        \\\"=\\\": _handle_match,\\n-        \\\"*\\\": _handle_substitution,\\n-        \\\"-\\\": _handle_deletion,\\n-        \\\"+\\\": _handle_insertion,\\n-        \\\"@\\\": _handle_inversion,\\n-        \\\"N\\\": _handle_unknown,\\n-    }\\n-    results = []\\n-    for group in cssplits_grouped:\\n-        for prefix, handler in handlers.items():\\n-            if group[0].startswith(prefix):\\n-                result, start, end = handler(group, genome, start, end, header, chromosome)\\n-                if prefix == \\\"=\\\":\\n-                    continue\\n-                results.append(result)\\n-    return flatten(results)\\n-\\n-\\n-###########################################################\\n-# main\\n-###########################################################\\n-\\n-\\n-def export_to_csv(TEMPDIR: Path | str, SAMPLE_NAME: str, GENOME_COORDINATES: dict, cons_percentage: dict[list]) -> None:\\n-    results = [[\\\"Allele ID\\\", \\\"Genome\\\", \\\"Chromosome\\\", \\\"Start\\\", \\\"End\\\", \\\"Mutation\\\"]]\\n-    for header, cons in cons_percentage.items():\\n-        cssplits = [max(c, key=c.get) for c in cons]\\n-        if GENOME_COORDINATES.get(\\\"strand\\\") == \\\"-\\\":\\n-            cssplits = revcomp_cssplits(cssplits)\\n-        cssplits_inversion = annotate_inversion(cssplits)\\n-        cssplits_grouped = group_by_mutation(cssplits_inversion)\\n-        result = report_mutations(cssplits_grouped, GENOME_COORDINATES, header)\\n-        results.extend(result)\\n-    results_csv = \\\"\\\\n\\\".join([\\\",\\\".join(map(str, r)) for r in results]) + \\\"\\\\n\\\"\\n-    path_output = Path(TEMPDIR, \\\"report\\\", \\\"MUTATION_INFO\\\", f\\\"{SAMPLE_NAME}.csv\\\")\\n-    path_output.write_text(results_csv)\\n\",\"diff --git a/src/DAJIN2/core/report/sequence_exporter.py b/src/DAJIN2/core/report/sequence_exporter.py\\nnew file mode 100644\\nindex 0000000..3661c5b\\n--- /dev/null\\n+++ b/src/DAJIN2/core/report/sequence_exporter.py\\n@@ -0,0 +1,69 @@\\n+from __future__ import annotations\\n+\\n+import textwrap\\n+import cstag\\n+from pathlib import Path\\n+from DAJIN2.utils.cssplits_handler import convert_cssplits_to_cstag\\n+from DAJIN2.core.report.insertion_reflector import reflect_ref_insertion_to_query\\n+\\n+\\n+def convert_to_fasta(header: str, sequence: str) -> str:\\n+    header = \\\">\\\" + header\\n+    sequence_wrapped = textwrap.wrap(sequence, 80)\\n+    fasta = \\\"\\\\n\\\".join([header, *sequence_wrapped]) + \\\"\\\\n\\\"\\n+\\n+    return fasta\\n+\\n+\\n+def convert_to_html(TEMPDIR: Path, SAMPLE_NAME: str, header: str, cons_per: list[dict]) -> str:\\n+    cons_cssplit = [max(cons, key=cons.get) for cons in cons_per]\\n+    cons_cstag = convert_cssplits_to_cstag(cons_cssplit)\\n+\\n+    allele = header.split(\\\"_\\\")[1]\\n+    if Path(TEMPDIR, SAMPLE_NAME, \\\"cstag\\\", f\\\"{allele}.txt\\\").exists():\\n+        ref_cstag = Path(TEMPDIR, SAMPLE_NAME, \\\"cstag\\\", f\\\"{allele}.txt\\\").read_text()\\n+        cons_cstag = reflect_ref_insertion_to_query(ref_cstag, cons_cstag)\\n+\\n+    return cstag.to_html(cons_cstag, f\\\"{SAMPLE_NAME} {header.replace('_', ' ')}\\\")\\n+\\n+\\n+##################################################\\n+# Export files\\n+##################################################\\n+\\n+\\n+def export_to_fasta(TEMPDIR: Path, SAMPLE_NAME: str, cons_sequence: dict) -> None:\\n+    for header, sequence in cons_sequence.items():\\n+        path_output = Path(TEMPDIR, \\\"report\\\", \\\"FASTA\\\", SAMPLE_NAME, f\\\"{SAMPLE_NAME}_{header}.fasta\\\")\\n+        path_output.write_text(convert_to_fasta(f\\\"{SAMPLE_NAME}_{header}\\\", sequence))\\n+\\n+\\n+def parse_fasta(file_path: Path) -> tuple[str, str]:\\n+    \\\"\\\"\\\"Parses a FASTA file and returns the header and concatenated sequence.\\\"\\\"\\\"\\n+    with open(file_path, \\\"r\\\") as f:\\n+        lines = f.readlines()\\n+\\n+    header = lines[0].strip().lstrip(\\\">\\\")\\n+    sequence = \\\"\\\".join(line.strip() for line in lines[1:])\\n+\\n+    return header, sequence\\n+\\n+\\n+def export_reference_to_fasta(TEMPDIR: Path, SAMPLE_NAME: str) -> None:\\n+    for fasta in Path(TEMPDIR, SAMPLE_NAME, \\\"fasta\\\").glob(\\\"*.fasta\\\"):\\n+        header, sequence = parse_fasta(fasta)\\n+        path_output = Path(TEMPDIR, \\\"report\\\", \\\"FASTA\\\", SAMPLE_NAME, f\\\"{header}.fasta\\\")\\n+        path_output.write_text(convert_to_fasta(f\\\"{SAMPLE_NAME}_{header}\\\", sequence))\\n+\\n+\\n+def export_to_html(TEMPDIR: Path, SAMPLE_NAME: str, cons_percentage: dict[list]) -> None:\\n+    for header, cons_per in cons_percentage.items():\\n+        path_output = Path(TEMPDIR, \\\"report\\\", \\\"HTML\\\", SAMPLE_NAME, f\\\"{SAMPLE_NAME}_{header}.html\\\")\\n+        path_output.write_text(convert_to_html(TEMPDIR, SAMPLE_NAME, header, cons_per))\\n+\\n+\\n+# def to_vcf(TEMPDIR: Path, SAMPLE_NAME: str, GENOME_COODINATES: dict[str, str], cons_percentage: dict[list]) -> str:\\n+#     pass\\n+#     for header, cons_per in cons_percentage.items():\\n+#         path_output = Path(TEMPDIR, \\\"report\\\", \\\"HTML\\\", SAMPLE_NAME, f\\\"{SAMPLE_NAME}_{header}.vcf\\\")\\n+#         path_output.write_text(_to_html(TEMPDIR, SAMPLE_NAME, header, cons_per))\\n\",\"diff --git a/src/DAJIN2/main.py b/src/DAJIN2/main.py\\nindex 0d54110..c764b46 100644\\n--- a/src/DAJIN2/main.py\\n+++ b/src/DAJIN2/main.py\\n@@ -20,7 +20,7 @@ from DAJIN2.core import core\\n from DAJIN2.utils import io, config, report_generator, input_validator, multiprocess\\n \\n \\n-DAJIN_VERSION = \\\"0.4.2\\\"\\n+DAJIN_VERSION = \\\"0.4.3\\\"\\n \\n \\n def generate_report(name: str) -> None:\\n\",\"diff --git a/src/DAJIN2/utils/io.py b/src/DAJIN2/utils/io.py\\nindex 608183c..c690f2c 100644\\n--- a/src/DAJIN2/utils/io.py\\n+++ b/src/DAJIN2/utils/io.py\\n@@ -19,6 +19,12 @@ from openpyxl import load_workbook, Workbook\\n ###########################################################\\n \\n \\n+def read_sam(path_of_sam: str | Path) -> Generator[list]:\\n+    with open(path_of_sam) as f:\\n+        for line in f:\\n+            yield line.strip().split(\\\"\\\\t\\\")\\n+\\n+\\n def load_pickle(file_path: Path):\\n     with open(file_path, \\\"rb\\\") as f:\\n         return pickle.load(f)\\n\",\"diff --git a/src/DAJIN2/utils/sam_handler.py b/src/DAJIN2/utils/sam_handler.py\\nindex 4668a8d..d7dc3b9 100644\\n--- a/src/DAJIN2/utils/sam_handler.py\\n+++ b/src/DAJIN2/utils/sam_handler.py\\n@@ -2,8 +2,6 @@ from __future__ import annotations\\n \\n import re\\n \\n-from pathlib import Path\\n-from typing import Generator\\n from itertools import groupby\\n from DAJIN2.utils.dna_handler import revcomp\\n \\n@@ -26,17 +24,6 @@ def is_mapped(s: list[str]) -> bool:\\n \\n \\n ###########################################################\\n-# Read sam\\n-###########################################################\\n-\\n-\\n-def read_sam(path_of_sam: str | Path) -> Generator[list]:\\n-    with open(path_of_sam) as f:\\n-        for line in f:\\n-            yield line.strip().split(\\\"\\\\t\\\")\\n-\\n-\\n-###########################################################\\n # remove_overlapped_reads\\n ###########################################################\\n \\n\"]", "test_patch": "[\"diff --git a/docs/RELEASE.md b/docs/RELEASE.md\\nindex 9cbb3af..d7e12d7 100644\\n--- a/docs/RELEASE.md\\n+++ b/docs/RELEASE.md\\n@@ -13,9 +13,58 @@\\n - VCF„ÄÅPDF„ÇíÂá∫Âäõ„Åô„Çã\\n - ÈÄÜ‰Ωç„Ç¢„É¨„É´„Åß„ÅÆÊ§úË®º„ÇíÂä†„Åà„Çã\\n - nCATS„Åå„Åª„Åó„ÅÑ‚Ä¶\\n+- Docker image„Å´„Åó„Å¶„ÄÅdarwin-arm64„Åß„ÇÇÂãï„Åè„Çà„ÅÜ„Å´„Åô„Çã\\n+- Flask„Åß„ÅØ„Å™„Åè„ÄÅstreamlit„ÅßGUI„Çí‰Ωú„Çã\\n  -->\\n \\n-# v0.4.2 (2024-03-25)\\n+# v0.4.3 (2024-03-29)\\n+\\n+<!-- ## üí• Breaking -->\\n+## üìù Documentation\\n+\\n++ Update example dataset and a description of README.md/README_JP.md [Commit Detail](https://github.com/akikuno/DAJIN2/commit/2f9b57057f978b7870e80179c035564c4ee54a40)\\n+\\n+\\n+<!-- ## üöÄ New Features -->\\n+## üêõ Bug Fixes\\n+\\n++ Update `preprocess.genome_fetcher_fetch_seq_coordinates` to accurately verify that the entire length of the input sequence is present within the reference sequence. Previously, partial 100% matches were inadvertently accepted; this revision aims to ensure the full alignment of the input sequence with the reference. [Commit Detail](https://github.com/akikuno/DAJIN2/commit/25584734e21e2c8da92d1de12bce498dfc341d03)\\n+\\n++ Update `report.bam_exporter` to be case-sensitive and consistent with directory names. This is to avoid errors caused by the difference between report/bam and report/BAM on Ubuntu, which is case-sensitive to directory names. [Commit Detail](https://github.com/akikuno/DAJIN2/commit/011b21ab32b6965a65e9b442bbf3f2854a44db8e)\\n+  + Thank you @takeiga for reporting the issue #24 !\\n+\\n+\\n+## üîß Maintenance\\n+\\n++ Change `threshold_readnumber` at `labem_merger.merge_labels` from 10 to 5 to capture 1% alleles from 500 total reads. [Commit Detail](https://github.com/akikuno/DAJIN2/commit/8448a8ec1f9efd4d15687a695ab993dc0a27efae)\\n+\\n++ Update the `requirements.txt` to install a newer version of the library. [Commit Detail](https://github.com/akikuno/DAJIN2/commit/d1cbf95b6a16ea720e0033e9a125d6201b99bcee)\\n+\\n++ Update `report.report_bam` and rename to `report.bam_exporter`: [Commit Detail](https://github.com/akikuno/DAJIN2/commit/011b21ab32b6965a65e9b442bbf3f2854a44db8e)\\n+  + Use UUID instead of random number for the temporary file name.\\n+  + Rename `realign` to `recalculate_sam_coodinates_to_reference` for the readability of the function name.\\n+  + Add `convert_pos_to_one_indexed` to convert the 0-based position to 1-based position and suppress samtools warning.\\n+    + Warning: `[W::sam_parse1] mapped query cannot have zero coordinate; treated as unmapped`\\n+  + Add tests for the `write_sam_to_bam` function\\n+\\n++ Move `read_sam` function from sam_handler to io module. [Commit Detail](https://github.com/akikuno/DAJIN2/commit/f9b9382ab706530b0cd4c34d7ff8f8c79002b654)\\n+\\n++ Rename `report.report_mutation`, `report.report_files` to `report.mutation_exporter` and `report.sequence_exporter` to be more explicit. [Commit Detail](https://github.com/akikuno/DAJIN2/commit/35d8250876cd845623e63c898d7c608d27a82a45)\\n+\\n+\\n+<!-- ## ‚õîÔ∏è Deprecated -->\\n+\\n+<!-- \\n+[Commit Detail](https://github.com/akikuno/DAJIN2/commit/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx)\\n+-->\\n+\\n+\\n+-------------------------------------------------------------\\n+\\n+# Past Releases\\n+\\n+<details>\\n+<summary> v0.4.2 (2024-03-25) </summary>\\n \\n ## üîß Maintenance\\n \\n@@ -37,10 +86,7 @@\\n \\n + Standardize to use `dataclass` instead of `NamedTuple`. [Commit Detail](https://github.com/akikuno/DAJIN2/commit/b7c34fbcda51ef037488f1f58564fa72128033f1)\\n \\n-\\n--------------------------------------------------------------\\n-\\n-# Past Releases\\n+</details>\\n \\n \\n <details>\\n\",\"diff --git a/tests/src/report/test_bam_exporter.py b/tests/src/report/test_bam_exporter.py\\nnew file mode 100644\\nindex 0000000..fb26938\\n--- /dev/null\\n+++ b/tests/src/report/test_bam_exporter.py\\n@@ -0,0 +1,36 @@\\n+from __future__ import annotations\\n+\\n+import pytest\\n+from pathlib import Path\\n+from unittest.mock import patch\\n+from src.DAJIN2.core.report import bam_exporter\\n+\\n+###############################################################################\\n+# Output\\n+###############################################################################\\n+\\n+\\n+@pytest.fixture\\n+def mock_pysam_sort_and_index():\\n+    with patch(\\\"pysam.sort\\\") as mock_sort:\\n+        with patch(\\\"pysam.index\\\") as mock_index:\\n+            yield mock_sort, mock_index\\n+\\n+\\n+def test_write_sam_to_bam(mock_pysam_sort_and_index):\\n+    mock_sort, mock_index = mock_pysam_sort_and_index\\n+    sam_data = [[\\\"r1\\\", \\\"seq1\\\", \\\"+\\\", \\\"chr1\\\", \\\"1000\\\"], [\\\"r2\\\", \\\"seq2\\\", \\\"-\\\", \\\"chr2\\\", \\\"2000\\\"]]\\n+    path_sam = \\\"test.sam\\\"\\n+    path_bam = \\\"test.bam\\\"\\n+    bam_exporter.write_sam_to_bam(sam_data, path_sam, path_bam)\\n+\\n+    mock_sort.assert_called_once()\\n+    mock_index.assert_called_once()\\n+\\n+    with open(path_sam) as f:\\n+        content = f.read()\\n+        expected_content = \\\"r1\\\\tseq1\\\\t+\\\\tchr1\\\\t1000\\\\nr2\\\\tseq2\\\\t-\\\\tchr2\\\\t2000\\\\n\\\"\\n+        assert content == expected_content\\n+\\n+    # „ÉÜ„Çπ„ÉàÂæå„ÅÆ„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó\\n+    Path(path_sam).unlink()\\n\",\"diff --git a/tests/src/report/test_mutation_exporter.py b/tests/src/report/test_mutation_exporter.py\\nnew file mode 100644\\nindex 0000000..93fc7b7\\n--- /dev/null\\n+++ b/tests/src/report/test_mutation_exporter.py\\n@@ -0,0 +1,210 @@\\n+from __future__ import annotations\\n+\\n+from src.DAJIN2.core import report\\n+\\n+###########################################################\\n+# revcomp_cssplits\\n+###########################################################\\n+\\n+\\n+def test_revcomp_cssplits_substitution():\\n+    cssplits = [\\\"=A\\\", \\\"*AG\\\", \\\"=C\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.revcomp_cssplits(cssplits)\\n+    answer = [\\\"=C\\\", \\\"=G\\\", \\\"*TC\\\", \\\"=T\\\"]\\n+    assert test == answer\\n+\\n+\\n+def test_revcomp_cssplits_substitution_with_N():\\n+    cssplits = [\\\"=A\\\", \\\"*AN\\\", \\\"N\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.revcomp_cssplits(cssplits)\\n+    answer = [\\\"=C\\\", \\\"N\\\", \\\"*TN\\\", \\\"=T\\\"]\\n+    assert test == answer\\n+\\n+\\n+def test_revcomp_cssplits_insertion():\\n+    cssplits = [\\\"=A\\\", \\\"+A|+A|+T|+G|=A\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.revcomp_cssplits(cssplits)\\n+    answer = [\\\"=C\\\", \\\"=T\\\", \\\"+C|+A|+T|+T|=T\\\"]\\n+    assert test == answer\\n+\\n+\\n+def test_revcomp_cssplits_insertion_long():\\n+    cssplits = [\\\"=A\\\", \\\"=A\\\", \\\"+A|+A|+T|+G|=A\\\", \\\"=G\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.revcomp_cssplits(cssplits)\\n+    answer = [\\\"=C\\\", \\\"=C\\\", \\\"=T\\\", \\\"+C|+A|+T|+T|=T\\\", \\\"=T\\\"]\\n+    assert test == answer\\n+\\n+\\n+def test_revcomp_cssplits_insertion_with_substitution():\\n+    cssplits = [\\\"=A\\\", \\\"+A|+A|+T|+G|*AG\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.revcomp_cssplits(cssplits)\\n+    answer = [\\\"=C\\\", \\\"*TC\\\", \\\"+C|+A|+T|+T|=T\\\"]\\n+    assert test == answer\\n+\\n+\\n+def test_revcomp_cssplits_insertion_with_N():\\n+    cssplits = [\\\"N\\\", \\\"+A|+A|+T|+G|N\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.revcomp_cssplits(cssplits)\\n+    answer = [\\\"=C\\\", \\\"N\\\", \\\"+C|+A|+T|+T|N\\\"]\\n+    assert test == answer\\n+\\n+\\n+def test_revcomp_cssplits_deletion():\\n+    cssplits = [\\\"=A\\\", \\\"-C\\\", \\\"-A\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.revcomp_cssplits(cssplits)\\n+    answer = [\\\"=C\\\", \\\"-T\\\", \\\"-G\\\", \\\"=T\\\"]\\n+    assert test == answer\\n+\\n+\\n+def test_revcomp_cssplits_N():\\n+    cssplits = [\\\"=A\\\", \\\"N\\\", \\\"N\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.revcomp_cssplits(cssplits)\\n+    answer = [\\\"=C\\\", \\\"N\\\", \\\"N\\\", \\\"=T\\\"]\\n+    assert test == answer\\n+\\n+\\n+def test_revcomp_cssplits_inversion():\\n+    cssplits = [\\\"=A\\\", \\\"=a\\\", \\\"=g\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.revcomp_cssplits(cssplits)\\n+    answer = [\\\"=C\\\", \\\"=c\\\", \\\"=t\\\", \\\"=T\\\"]\\n+    assert test == answer\\n+\\n+\\n+###########################################################\\n+# annotate inversion\\n+###########################################################\\n+\\n+\\n+def test_annotate_inversion():\\n+    cssplits = [\\\"=A\\\", \\\"=a\\\", \\\"=g\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.annotate_inversion(cssplits)\\n+    answer = [\\\"=A\\\", \\\"@=a\\\", \\\"@=g\\\", \\\"=G\\\"]\\n+    assert test == answer\\n+\\n+\\n+###########################################################\\n+# group by mutation\\n+###########################################################\\n+\\n+\\n+def test_group_by_mutation_deletion():\\n+    cssplits = [\\\"=A\\\", \\\"-G\\\", \\\"-T\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.group_by_mutation(cssplits)\\n+    answer = [[\\\"=A\\\"], [\\\"-G\\\", \\\"-T\\\"], [\\\"=G\\\"]]\\n+    assert test == answer\\n+\\n+\\n+def test_group_by_mutation_insertion():\\n+    cssplits = [\\\"=A\\\", \\\"+A|+A|=G\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.group_by_mutation(cssplits)\\n+    answer = [[\\\"=A\\\"], [\\\"+A|+A|=G\\\"], [\\\"=G\\\"]]\\n+    assert test == answer\\n+\\n+\\n+def test_group_by_mutation_inversion():\\n+    cssplits = [\\\"=A\\\", \\\"@=a\\\", \\\"@=g\\\", \\\"=G\\\"]\\n+    test = report.mutation_exporter.group_by_mutation(cssplits)\\n+    answer = [[\\\"=A\\\"], [\\\"@=a\\\", \\\"@=g\\\"], [\\\"=G\\\"]]\\n+    assert test == answer\\n+\\n+\\n+########################################################################\\n+# _report_mutations\\n+########################################################################\\n+\\n+\\n+def test_report_mutations_substitution():\\n+    cssplits = [\\\"=A\\\", \\\"*AG\\\", \\\"=G\\\"]\\n+    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 2, \\\"strand\\\": \\\"+\\\"}\\n+    header = \\\"test\\\"\\n+    cssplits_inversion = report.mutation_exporter.annotate_inversion(cssplits)\\n+    cssplits_grouped = report.mutation_exporter.group_by_mutation(cssplits_inversion)\\n+    test = report.mutation_exporter.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n+    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 1, \\\"substitution: A>G\\\"]]\\n+    assert test == answer\\n+\\n+\\n+def test_report_mutations_consecutive_substitution():\\n+    cssplits = [\\\"=A\\\", \\\"*AG\\\", \\\"*CT\\\", \\\"=G\\\"]\\n+    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 3, \\\"strand\\\": \\\"+\\\"}\\n+    header = \\\"test\\\"\\n+    cssplits_inversion = report.mutation_exporter.annotate_inversion(cssplits)\\n+    cssplits_grouped = report.mutation_exporter.group_by_mutation(cssplits_inversion)\\n+    test = report.mutation_exporter.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n+    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 1, \\\"substitution: A>G\\\"], [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 2, 2, \\\"substitution: C>T\\\"]]\\n+    assert test == answer\\n+\\n+\\n+def test_report_mutations_deletion():\\n+    cssplits = [\\\"=A\\\", \\\"-G\\\", \\\"-T\\\", \\\"=G\\\"]\\n+    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 3, \\\"strand\\\": \\\"+\\\"}\\n+    header = \\\"test\\\"\\n+    cssplits_inversion = report.mutation_exporter.annotate_inversion(cssplits)\\n+    cssplits_grouped = report.mutation_exporter.group_by_mutation(cssplits_inversion)\\n+    test = report.mutation_exporter.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n+    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 2, \\\"2bp deletion: GT\\\"]]\\n+    assert test == answer\\n+\\n+\\n+def test_report_mutations_insertion():\\n+    cssplits = [\\\"=A\\\", \\\"+G|+T|=A\\\", \\\"=G\\\"]\\n+    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 3, \\\"strand\\\": \\\"+\\\"}\\n+    header = \\\"test\\\"\\n+    cssplits_inversion = report.mutation_exporter.annotate_inversion(cssplits)\\n+    cssplits_grouped = report.mutation_exporter.group_by_mutation(cssplits_inversion)\\n+    test = report.mutation_exporter.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n+    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 1, \\\"2bp insertion: GT\\\"]]\\n+    assert test == answer\\n+\\n+\\n+def test_report_mutations_insertion_with_substitution():\\n+    cssplits = [\\\"=A\\\", \\\"+G|+T|*GA\\\", \\\"=G\\\"]\\n+    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 3, \\\"strand\\\": \\\"+\\\"}\\n+    header = \\\"test\\\"\\n+    cssplits_inversion = report.mutation_exporter.annotate_inversion(cssplits)\\n+    cssplits_grouped = report.mutation_exporter.group_by_mutation(cssplits_inversion)\\n+    test = report.mutation_exporter.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n+    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 1, \\\"2bp insertion: GT\\\"]]\\n+    assert test == answer\\n+\\n+\\n+def test_report_mutations_inversion():\\n+    cssplits = [\\\"=A\\\", \\\"=a\\\", \\\"=t\\\", \\\"=G\\\"]\\n+    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 4, \\\"strand\\\": \\\"+\\\"}\\n+    header = \\\"test\\\"\\n+    cssplits_inversion = report.mutation_exporter.annotate_inversion(cssplits)\\n+    cssplits_grouped = report.mutation_exporter.group_by_mutation(cssplits_inversion)\\n+    test = report.mutation_exporter.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n+    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 2, \\\"2bp inversion: AT\\\"]]\\n+    assert test == answer\\n+\\n+\\n+def test_report_mutations_various():\\n+    cssplits = [\\\"=A\\\", \\\"*AG\\\", \\\"+A|+A|-A\\\", \\\"N\\\", \\\"-G\\\", \\\"*CG\\\", \\\"*AG\\\", \\\"=a\\\", \\\"=t\\\", \\\"=A\\\"]\\n+    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 4, \\\"strand\\\": \\\"+\\\"}\\n+    header = \\\"test\\\"\\n+    cssplits_inversion = report.mutation_exporter.annotate_inversion(cssplits)\\n+    cssplits_grouped = report.mutation_exporter.group_by_mutation(cssplits_inversion)\\n+    test = report.mutation_exporter.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n+    answer = [\\n+        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 1, \\\"substitution: A>G\\\"],\\n+        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 2, 2, \\\"2bp insertion: AA\\\"],\\n+        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 2, 2, \\\"1bp deletion: A\\\"],\\n+        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 3, 3, \\\"1bp unknown bases\\\"],\\n+        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 4, 4, \\\"1bp deletion: G\\\"],\\n+        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 5, 5, \\\"substitution: C>G\\\"],\\n+        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 6, 6, \\\"substitution: A>G\\\"],\\n+        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 7, 8, \\\"2bp inversion: AT\\\"],\\n+    ]\\n+    assert test == answer\\n+\\n+\\n+def test_report_mutations_genome_coodinates():\\n+    cssplits = [\\\"=A\\\", \\\"*AG\\\", \\\"=G\\\"]\\n+    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chrX\\\", \\\"start\\\": 100, \\\"end\\\": 103, \\\"strand\\\": \\\"+\\\"}\\n+    header = \\\"test\\\"\\n+    cssplits_inversion = report.mutation_exporter.annotate_inversion(cssplits)\\n+    cssplits_grouped = report.mutation_exporter.group_by_mutation(cssplits_inversion)\\n+    test = report.mutation_exporter.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n+    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chrX\\\", 101, 101, \\\"substitution: A>G\\\"]]\\n+    assert test == answer\\n\",\"diff --git a/tests/src/report/test_report_af.py b/tests/src/report/test_report_af.py\\ndeleted file mode 100644\\nindex f4b6f43..0000000\\n--- a/tests/src/report/test_report_af.py\\n+++ /dev/null\\n@@ -1,46 +0,0 @@\\n-# from __future__ import annotations\\n-# from src.DAJIN2.core.report import report_af\\n-# import pandas as pd\\n-# from importlib import reload\\n-# from pathlib import Path\\n-\\n-# reload(report_af)\\n-\\n-\\n-# def test_all_allele():\\n-#     x = [\\n-#         {\\\"QNAME\\\": \\\"nobita\\\", \\\"ALLELE\\\": \\\"albino\\\", \\\"SV\\\": False, \\\"LABEL\\\": 1, \\\"NAME\\\": \\\"albino_intact_1\\\"},\\n-#         {\\\"QNAME\\\": \\\"shizuka\\\", \\\"ALLELE\\\": \\\"albino\\\", \\\"SV\\\": False, \\\"LABEL\\\": 2, \\\"NAME\\\": \\\"albino_sv_2\\\"},\\n-#         {\\\"QNAME\\\": \\\"suneo\\\", \\\"ALLELE\\\": \\\"control\\\", \\\"SV\\\": False, \\\"LABEL\\\": 3, \\\"NAME\\\": \\\"control_variants_3\\\"},\\n-#         {\\\"QNAME\\\": \\\"gian\\\", \\\"ALLELE\\\": \\\"control\\\", \\\"SV\\\": True, \\\"LABEL\\\": 4, \\\"NAME\\\": \\\"control_sv_4\\\"},\\n-#         {\\\"QNAME\\\": \\\"dora\\\", \\\"ALLELE\\\": \\\"albino\\\", \\\"SV\\\": True, \\\"LABEL\\\": 5, \\\"NAME\\\": \\\"control_sv_5\\\"},\\n-#     ]\\n-#     df_clust_sample = pd.DataFrame(x)\\n-#     df_clust_sample[\\\"SAMPLE\\\"] = \\\"test\\\"\\n-#     colum = df_clust_sample.columns.to_list()\\n-#     colum = colum[-1:] + colum[:-1]\\n-#     test = df_clust_sample[colum]\\n-#     answer = pd.read_csv(\\\"tests/data/report_af_all_allele/answer.csv\\\")\\n-#     assert test.to_json() == answer.to_json()\\n-\\n-\\n-# def test_summary_allele():\\n-#     # prepare inputs\\n-#     clust_sample = Path(\\\"tests/data/report_af_summary_allele/clust_sample.txt\\\").read_text()\\n-#     clust_sample = eval(clust_sample)\\n-#     sample_name = \\\"barcode31\\\"\\n-#     test = report_af.summary_allele(clust_sample, sample_name)\\n-#     answer = pd.read_csv(\\\"tests/data/report_af_summary_allele/answer.csv\\\")\\n-#     assert test.to_json() == answer.to_json()\\n-\\n-\\n-# # def test_plot():\\n-# #     df = pd.read_csv(\\\"tests/data/report_af_plot/test_input.csv\\\")\\n-# #     g_test = report_af.plot(df)\\n-# #     filename = tempfile.NamedTemporaryFile().name + \\\".eps\\\"\\n-# #     g_test.save(filename=filename)\\n-# #     test = Path(filename).read_text().split(\\\"\\\\n\\\")\\n-# #     test = [t for t in test if not t.startswith(r\\\"%\\\")]\\n-# #     answer = Path(\\\"tests/data/report_af_plot/answer.eps\\\").read_text().split(\\\"\\\\n\\\")\\n-# #     answer = [a for a in answer if not a.startswith(r\\\"%\\\")]\\n-# #     assert test == answer\\n\",\"diff --git a/tests/src/report/test_report_files.py b/tests/src/report/test_report_files.py\\ndeleted file mode 100644\\nindex 26d38c5..0000000\\n--- a/tests/src/report/test_report_files.py\\n+++ /dev/null\\n@@ -1,15 +0,0 @@\\n-from __future__ import annotations\\n-\\n-from src.DAJIN2.core import report\\n-\\n-########################################################################\\n-# Convert to files\\n-########################################################################\\n-\\n-\\n-def test_convert_to_fasta():\\n-    header = \\\"test_sequence\\\"\\n-    cons_seq = \\\"A\\\" * 81\\n-    test = report.report_files.convert_to_fasta(header, cons_seq)\\n-    answer = \\\">test_sequence\\\\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\\\\nA\\\\n\\\"\\n-    assert test == answer\\n\",\"diff --git a/tests/src/report/test_report_mutation.py b/tests/src/report/test_report_mutation.py\\ndeleted file mode 100644\\nindex 6e5260d..0000000\\n--- a/tests/src/report/test_report_mutation.py\\n+++ /dev/null\\n@@ -1,210 +0,0 @@\\n-from __future__ import annotations\\n-\\n-from src.DAJIN2.core import report\\n-\\n-###########################################################\\n-# revcomp_cssplits\\n-###########################################################\\n-\\n-\\n-def test_revcomp_cssplits_substitution():\\n-    cssplits = [\\\"=A\\\", \\\"*AG\\\", \\\"=C\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.revcomp_cssplits(cssplits)\\n-    answer = [\\\"=C\\\", \\\"=G\\\", \\\"*TC\\\", \\\"=T\\\"]\\n-    assert test == answer\\n-\\n-\\n-def test_revcomp_cssplits_substitution_with_N():\\n-    cssplits = [\\\"=A\\\", \\\"*AN\\\", \\\"N\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.revcomp_cssplits(cssplits)\\n-    answer = [\\\"=C\\\", \\\"N\\\", \\\"*TN\\\", \\\"=T\\\"]\\n-    assert test == answer\\n-\\n-\\n-def test_revcomp_cssplits_insertion():\\n-    cssplits = [\\\"=A\\\", \\\"+A|+A|+T|+G|=A\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.revcomp_cssplits(cssplits)\\n-    answer = [\\\"=C\\\", \\\"=T\\\", \\\"+C|+A|+T|+T|=T\\\"]\\n-    assert test == answer\\n-\\n-\\n-def test_revcomp_cssplits_insertion_long():\\n-    cssplits = [\\\"=A\\\", \\\"=A\\\", \\\"+A|+A|+T|+G|=A\\\", \\\"=G\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.revcomp_cssplits(cssplits)\\n-    answer = [\\\"=C\\\", \\\"=C\\\", \\\"=T\\\", \\\"+C|+A|+T|+T|=T\\\", \\\"=T\\\"]\\n-    assert test == answer\\n-\\n-\\n-def test_revcomp_cssplits_insertion_with_substitution():\\n-    cssplits = [\\\"=A\\\", \\\"+A|+A|+T|+G|*AG\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.revcomp_cssplits(cssplits)\\n-    answer = [\\\"=C\\\", \\\"*TC\\\", \\\"+C|+A|+T|+T|=T\\\"]\\n-    assert test == answer\\n-\\n-\\n-def test_revcomp_cssplits_insertion_with_N():\\n-    cssplits = [\\\"N\\\", \\\"+A|+A|+T|+G|N\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.revcomp_cssplits(cssplits)\\n-    answer = [\\\"=C\\\", \\\"N\\\", \\\"+C|+A|+T|+T|N\\\"]\\n-    assert test == answer\\n-\\n-\\n-def test_revcomp_cssplits_deletion():\\n-    cssplits = [\\\"=A\\\", \\\"-C\\\", \\\"-A\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.revcomp_cssplits(cssplits)\\n-    answer = [\\\"=C\\\", \\\"-T\\\", \\\"-G\\\", \\\"=T\\\"]\\n-    assert test == answer\\n-\\n-\\n-def test_revcomp_cssplits_N():\\n-    cssplits = [\\\"=A\\\", \\\"N\\\", \\\"N\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.revcomp_cssplits(cssplits)\\n-    answer = [\\\"=C\\\", \\\"N\\\", \\\"N\\\", \\\"=T\\\"]\\n-    assert test == answer\\n-\\n-\\n-def test_revcomp_cssplits_inversion():\\n-    cssplits = [\\\"=A\\\", \\\"=a\\\", \\\"=g\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.revcomp_cssplits(cssplits)\\n-    answer = [\\\"=C\\\", \\\"=c\\\", \\\"=t\\\", \\\"=T\\\"]\\n-    assert test == answer\\n-\\n-\\n-###########################################################\\n-# annotate inversion\\n-###########################################################\\n-\\n-\\n-def test_annotate_inversion():\\n-    cssplits = [\\\"=A\\\", \\\"=a\\\", \\\"=g\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.annotate_inversion(cssplits)\\n-    answer = [\\\"=A\\\", \\\"@=a\\\", \\\"@=g\\\", \\\"=G\\\"]\\n-    assert test == answer\\n-\\n-\\n-###########################################################\\n-# group by mutation\\n-###########################################################\\n-\\n-\\n-def test_group_by_mutation_deletion():\\n-    cssplits = [\\\"=A\\\", \\\"-G\\\", \\\"-T\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.group_by_mutation(cssplits)\\n-    answer = [[\\\"=A\\\"], [\\\"-G\\\", \\\"-T\\\"], [\\\"=G\\\"]]\\n-    assert test == answer\\n-\\n-\\n-def test_group_by_mutation_insertion():\\n-    cssplits = [\\\"=A\\\", \\\"+A|+A|=G\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.group_by_mutation(cssplits)\\n-    answer = [[\\\"=A\\\"], [\\\"+A|+A|=G\\\"], [\\\"=G\\\"]]\\n-    assert test == answer\\n-\\n-\\n-def test_group_by_mutation_inversion():\\n-    cssplits = [\\\"=A\\\", \\\"@=a\\\", \\\"@=g\\\", \\\"=G\\\"]\\n-    test = report.report_mutation.group_by_mutation(cssplits)\\n-    answer = [[\\\"=A\\\"], [\\\"@=a\\\", \\\"@=g\\\"], [\\\"=G\\\"]]\\n-    assert test == answer\\n-\\n-\\n-########################################################################\\n-# _report_mutations\\n-########################################################################\\n-\\n-\\n-def test_report_mutations_substitution():\\n-    cssplits = [\\\"=A\\\", \\\"*AG\\\", \\\"=G\\\"]\\n-    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 2, \\\"strand\\\": \\\"+\\\"}\\n-    header = \\\"test\\\"\\n-    cssplits_inversion = report.report_mutation.annotate_inversion(cssplits)\\n-    cssplits_grouped = report.report_mutation.group_by_mutation(cssplits_inversion)\\n-    test = report.report_mutation.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n-    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 1, \\\"substitution: A>G\\\"]]\\n-    assert test == answer\\n-\\n-\\n-def test_report_mutations_consecutive_substitution():\\n-    cssplits = [\\\"=A\\\", \\\"*AG\\\", \\\"*CT\\\", \\\"=G\\\"]\\n-    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 3, \\\"strand\\\": \\\"+\\\"}\\n-    header = \\\"test\\\"\\n-    cssplits_inversion = report.report_mutation.annotate_inversion(cssplits)\\n-    cssplits_grouped = report.report_mutation.group_by_mutation(cssplits_inversion)\\n-    test = report.report_mutation.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n-    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 1, \\\"substitution: A>G\\\"], [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 2, 2, \\\"substitution: C>T\\\"]]\\n-    assert test == answer\\n-\\n-\\n-def test_report_mutations_deletion():\\n-    cssplits = [\\\"=A\\\", \\\"-G\\\", \\\"-T\\\", \\\"=G\\\"]\\n-    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 3, \\\"strand\\\": \\\"+\\\"}\\n-    header = \\\"test\\\"\\n-    cssplits_inversion = report.report_mutation.annotate_inversion(cssplits)\\n-    cssplits_grouped = report.report_mutation.group_by_mutation(cssplits_inversion)\\n-    test = report.report_mutation.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n-    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 2, \\\"2bp deletion: GT\\\"]]\\n-    assert test == answer\\n-\\n-\\n-def test_report_mutations_insertion():\\n-    cssplits = [\\\"=A\\\", \\\"+G|+T|=A\\\", \\\"=G\\\"]\\n-    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 3, \\\"strand\\\": \\\"+\\\"}\\n-    header = \\\"test\\\"\\n-    cssplits_inversion = report.report_mutation.annotate_inversion(cssplits)\\n-    cssplits_grouped = report.report_mutation.group_by_mutation(cssplits_inversion)\\n-    test = report.report_mutation.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n-    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 1, \\\"2bp insertion: GT\\\"]]\\n-    assert test == answer\\n-\\n-\\n-def test_report_mutations_insertion_with_substitution():\\n-    cssplits = [\\\"=A\\\", \\\"+G|+T|*GA\\\", \\\"=G\\\"]\\n-    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 3, \\\"strand\\\": \\\"+\\\"}\\n-    header = \\\"test\\\"\\n-    cssplits_inversion = report.report_mutation.annotate_inversion(cssplits)\\n-    cssplits_grouped = report.report_mutation.group_by_mutation(cssplits_inversion)\\n-    test = report.report_mutation.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n-    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 1, \\\"2bp insertion: GT\\\"]]\\n-    assert test == answer\\n-\\n-\\n-def test_report_mutations_inversion():\\n-    cssplits = [\\\"=A\\\", \\\"=a\\\", \\\"=t\\\", \\\"=G\\\"]\\n-    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 4, \\\"strand\\\": \\\"+\\\"}\\n-    header = \\\"test\\\"\\n-    cssplits_inversion = report.report_mutation.annotate_inversion(cssplits)\\n-    cssplits_grouped = report.report_mutation.group_by_mutation(cssplits_inversion)\\n-    test = report.report_mutation.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n-    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 2, \\\"2bp inversion: AT\\\"]]\\n-    assert test == answer\\n-\\n-\\n-def test_report_mutations_various():\\n-    cssplits = [\\\"=A\\\", \\\"*AG\\\", \\\"+A|+A|-A\\\", \\\"N\\\", \\\"-G\\\", \\\"*CG\\\", \\\"*AG\\\", \\\"=a\\\", \\\"=t\\\", \\\"=A\\\"]\\n-    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chr1\\\", \\\"start\\\": 0, \\\"end\\\": 4, \\\"strand\\\": \\\"+\\\"}\\n-    header = \\\"test\\\"\\n-    cssplits_inversion = report.report_mutation.annotate_inversion(cssplits)\\n-    cssplits_grouped = report.report_mutation.group_by_mutation(cssplits_inversion)\\n-    test = report.report_mutation.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n-    answer = [\\n-        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 1, 1, \\\"substitution: A>G\\\"],\\n-        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 2, 2, \\\"2bp insertion: AA\\\"],\\n-        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 2, 2, \\\"1bp deletion: A\\\"],\\n-        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 3, 3, \\\"1bp unknown bases\\\"],\\n-        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 4, 4, \\\"1bp deletion: G\\\"],\\n-        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 5, 5, \\\"substitution: C>G\\\"],\\n-        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 6, 6, \\\"substitution: A>G\\\"],\\n-        [\\\"test\\\", \\\"mm10\\\", \\\"chr1\\\", 7, 8, \\\"2bp inversion: AT\\\"],\\n-    ]\\n-    assert test == answer\\n-\\n-\\n-def test_report_mutations_genome_coodinates():\\n-    cssplits = [\\\"=A\\\", \\\"*AG\\\", \\\"=G\\\"]\\n-    GENOME_COODINATES = {\\\"genome\\\": \\\"mm10\\\", \\\"chrom\\\": \\\"chrX\\\", \\\"start\\\": 100, \\\"end\\\": 103, \\\"strand\\\": \\\"+\\\"}\\n-    header = \\\"test\\\"\\n-    cssplits_inversion = report.report_mutation.annotate_inversion(cssplits)\\n-    cssplits_grouped = report.report_mutation.group_by_mutation(cssplits_inversion)\\n-    test = report.report_mutation.report_mutations(cssplits_grouped, GENOME_COODINATES, header)\\n-    answer = [[\\\"test\\\", \\\"mm10\\\", \\\"chrX\\\", 101, 101, \\\"substitution: A>G\\\"]]\\n-    assert test == answer\\n\",\"diff --git a/tests/src/report/test_sequence_exporter.py b/tests/src/report/test_sequence_exporter.py\\nnew file mode 100644\\nindex 0000000..60f8819\\n--- /dev/null\\n+++ b/tests/src/report/test_sequence_exporter.py\\n@@ -0,0 +1,15 @@\\n+from __future__ import annotations\\n+\\n+from src.DAJIN2.core import report\\n+\\n+########################################################################\\n+# Convert to files\\n+########################################################################\\n+\\n+\\n+def test_convert_to_fasta():\\n+    header = \\\"test_sequence\\\"\\n+    cons_seq = \\\"A\\\" * 81\\n+    test = report.sequence_exporter.convert_to_fasta(header, cons_seq)\\n+    answer = \\\">test_sequence\\\\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\\\\nA\\\\n\\\"\\n+    assert test == answer\"]", "hints_text": ""}
