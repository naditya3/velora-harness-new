{"instance_id": "9916354481794765", "repo": "sdatkinson/neural-amp-modeler", "base_commit": "76576fc40fdabcd14f00021a487e13ac48e0580b", "problem_statement": "LSTM:\\nWould be fun/possible lighter-weight model", "FAIL_TO_PASS": ["tests/test_nam/test_importable.py::test_importable"], "PASS_TO_PASS": ["tests/test_nam/test_models/test_hyper_net.py::TestHyperConvNet::test_init[True-Tanh]", "tests/test_nam/test_models/test_conv_net.py::TestConvNet::test_init[True-Tanh]", "tests/test_nam/test_models/test_hyper_net.py::TestHyperConvNet::test_init[False-ReLU]", "tests/test_nam/test_data.py::TestDataset::test_init_zero_delay", "tests/test_install.py::test_torch", "tests/test_nam/test_models/test_hyper_net.py::TestHyperConvNet::test_export[False-ReLU]", "tests/test_nam/test_models/test_hyper_net.py::TestHyperConvNet::test_export[True-Tanh]", "tests/test_nam/test_data.py::TestDataset::test_init", "tests/test_nam/test_models/test_conv_net.py::TestConvNet::test_init[False-ReLU]", "tests/test_nam/test_models/test_hyper_net.py::TestHyperConvNet::test_export_cpp_header"], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/sdatkinson_neural-amp-modeler:76576fc40fdabcd14f00021a487e13ac48e0580b", "patch": "[\"diff --git a/bin/train/inputs/config_data_single_pair.json b/bin/train/inputs/config_data_single_pair.json\\ndeleted file mode 100644\\nindex 2cfe68c..0000000\\n--- a/bin/train/inputs/config_data_single_pair.json\\n+++ /dev/null\\n@@ -1,18 +0,0 @@\\n-{\\n-    \\\"train\\\": {\\n-        \\\"start\\\": null,\\n-        \\\"stop\\\": 36576000,\\n-        \\\"ny\\\": 1024\\n-    },\\n-    \\\"validation\\\": {\\n-        \\\"start\\\": 36576000,\\n-        \\\"stop\\\": null,\\n-        \\\"ny\\\": null\\n-    },\\n-    \\\"common\\\": {\\n-        \\\"x_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\source.wav\\\",\\n-        \\\"y_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\target.wav\\\",\\n-        \\\"nx\\\": 8191,\\n-        \\\"delay\\\": 0\\n-    }\\n-}\\n\\\\ No newline at end of file\\n\",\"diff --git a/bin/train/inputs/config_data_two_pairs.json b/bin/train/inputs/config_data_two_pairs.json\\ndeleted file mode 100644\\nindex 03931a1..0000000\\n--- a/bin/train/inputs/config_data_two_pairs.json\\n+++ /dev/null\\n@@ -1,16 +0,0 @@\\n-{\\n-    \\\"train\\\": {\\n-        \\\"x_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\train\\\\\\\\source.wav\\\",\\n-        \\\"y_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\train\\\\\\\\target.wav\\\",\\n-        \\\"ny\\\": 1024\\n-    },\\n-    \\\"validation\\\": {\\n-        \\\"x_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\validation\\\\\\\\source.wav\\\",\\n-        \\\"y_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\validation\\\\\\\\target.wav\\\",\\n-        \\\"ny\\\": null\\n-    },\\n-    \\\"common\\\": {\\n-        \\\"nx\\\": 8191,\\n-        \\\"delay\\\": 0\\n-    }\\n-}\\n\\\\ No newline at end of file\\n\",\"diff --git a/bin/train/inputs/config_learning.json b/bin/train/inputs/config_learning.json\\ndeleted file mode 100644\\nindex c7e22bc..0000000\\n--- a/bin/train/inputs/config_learning.json\\n+++ /dev/null\\n@@ -1,17 +0,0 @@\\n-{\\n-    \\\"train_dataloader\\\": {\\n-        \\\"batch_size\\\": 16,\\n-        \\\"shuffle\\\": true,\\n-        \\\"pin_memory\\\": true,\\n-        \\\"drop_last\\\": true,\\n-        \\\"num_workers\\\": 4\\n-    },\\n-    \\\"val_dataloader\\\": {\\n-    },\\n-    \\\"trainer\\\": {\\n-        \\\"gpus\\\": 1,\\n-        \\\"max_epochs\\\": 1000\\n-    },\\n-    \\\"trainer_fit_kwargs\\\": {\\n-    }\\n-}\\n\\\\ No newline at end of file\\n\",\"diff --git a/bin/train/inputs/config_model.json b/bin/train/inputs/config_model.json\\ndeleted file mode 100644\\nindex afb04f0..0000000\\n--- a/bin/train/inputs/config_model.json\\n+++ /dev/null\\n@@ -1,25 +0,0 @@\\n-{\\n-    \\\"net\\\": {\\n-        \\\"name\\\": \\\"ConvNet\\\",\\n-        \\\"config\\\": {\\n-            \\\"channels\\\": 16,\\n-            \\\"dilations\\\": [1,2,4,8,16,32,64,128,256,512,1024,2048,1,2,4,8,16,32,64,128,256,512,1024,2048],\\n-            \\\"batchnorm\\\": true,\\n-            \\\"activation\\\": \\\"Tanh\\\"\\n-        }\\n-    },\\n-    \\\"optimizer\\\": {\\n-        \\\"lr\\\": 0.003\\n-    },\\n-    \\\"lr_scheduler\\\": {\\n-        \\\"class\\\": \\\"ReduceLROnPlateau\\\",\\n-        \\\"kwargs\\\": {\\n-            \\\"factor\\\": 0.5,\\n-            \\\"patience\\\": 50,\\n-            \\\"cooldown\\\": 50,\\n-            \\\"min_lr\\\": 1.0e-5,\\n-            \\\"verbose\\\": true\\n-        },\\n-        \\\"monitor\\\": \\\"val_loss\\\"\\n-    }\\n-}\\n\\\\ No newline at end of file\\n\",\"diff --git a/bin/train/inputs/data/single_pair.json b/bin/train/inputs/data/single_pair.json\\nnew file mode 100644\\nindex 0000000..2cfe68c\\n--- /dev/null\\n+++ b/bin/train/inputs/data/single_pair.json\\n@@ -0,0 +1,18 @@\\n+{\\n+    \\\"train\\\": {\\n+        \\\"start\\\": null,\\n+        \\\"stop\\\": 36576000,\\n+        \\\"ny\\\": 1024\\n+    },\\n+    \\\"validation\\\": {\\n+        \\\"start\\\": 36576000,\\n+        \\\"stop\\\": null,\\n+        \\\"ny\\\": null\\n+    },\\n+    \\\"common\\\": {\\n+        \\\"x_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\source.wav\\\",\\n+        \\\"y_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\target.wav\\\",\\n+        \\\"nx\\\": 8191,\\n+        \\\"delay\\\": 0\\n+    }\\n+}\\n\\\\ No newline at end of file\\n\",\"diff --git a/bin/train/inputs/data/two_pairs.json b/bin/train/inputs/data/two_pairs.json\\nnew file mode 100644\\nindex 0000000..03931a1\\n--- /dev/null\\n+++ b/bin/train/inputs/data/two_pairs.json\\n@@ -0,0 +1,16 @@\\n+{\\n+    \\\"train\\\": {\\n+        \\\"x_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\train\\\\\\\\source.wav\\\",\\n+        \\\"y_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\train\\\\\\\\target.wav\\\",\\n+        \\\"ny\\\": 1024\\n+    },\\n+    \\\"validation\\\": {\\n+        \\\"x_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\validation\\\\\\\\source.wav\\\",\\n+        \\\"y_path\\\": \\\"C:\\\\\\\\path\\\\\\\\to\\\\\\\\validation\\\\\\\\target.wav\\\",\\n+        \\\"ny\\\": null\\n+    },\\n+    \\\"common\\\": {\\n+        \\\"nx\\\": 8191,\\n+        \\\"delay\\\": 0\\n+    }\\n+}\\n\\\\ No newline at end of file\\n\",\"diff --git a/bin/train/inputs/learning/default.json b/bin/train/inputs/learning/default.json\\nnew file mode 100644\\nindex 0000000..afbfee4\\n--- /dev/null\\n+++ b/bin/train/inputs/learning/default.json\\n@@ -0,0 +1,17 @@\\n+{\\n+    \\\"train_dataloader\\\": {\\n+        \\\"batch_size\\\": 32,\\n+        \\\"shuffle\\\": true,\\n+        \\\"pin_memory\\\": true,\\n+        \\\"drop_last\\\": true,\\n+        \\\"num_workers\\\": 4\\n+    },\\n+    \\\"val_dataloader\\\": {\\n+    },\\n+    \\\"trainer\\\": {\\n+        \\\"gpus\\\": 1,\\n+        \\\"max_epochs\\\": 1000\\n+    },\\n+    \\\"trainer_fit_kwargs\\\": {\\n+    }\\n+}\\n\\\\ No newline at end of file\\n\",\"diff --git a/bin/train/inputs/models/convnet.json b/bin/train/inputs/models/convnet.json\\nnew file mode 100644\\nindex 0000000..afb04f0\\n--- /dev/null\\n+++ b/bin/train/inputs/models/convnet.json\\n@@ -0,0 +1,25 @@\\n+{\\n+    \\\"net\\\": {\\n+        \\\"name\\\": \\\"ConvNet\\\",\\n+        \\\"config\\\": {\\n+            \\\"channels\\\": 16,\\n+            \\\"dilations\\\": [1,2,4,8,16,32,64,128,256,512,1024,2048,1,2,4,8,16,32,64,128,256,512,1024,2048],\\n+            \\\"batchnorm\\\": true,\\n+            \\\"activation\\\": \\\"Tanh\\\"\\n+        }\\n+    },\\n+    \\\"optimizer\\\": {\\n+        \\\"lr\\\": 0.003\\n+    },\\n+    \\\"lr_scheduler\\\": {\\n+        \\\"class\\\": \\\"ReduceLROnPlateau\\\",\\n+        \\\"kwargs\\\": {\\n+            \\\"factor\\\": 0.5,\\n+            \\\"patience\\\": 50,\\n+            \\\"cooldown\\\": 50,\\n+            \\\"min_lr\\\": 1.0e-5,\\n+            \\\"verbose\\\": true\\n+        },\\n+        \\\"monitor\\\": \\\"val_loss\\\"\\n+    }\\n+}\\n\\\\ No newline at end of file\\n\",\"diff --git a/bin/train/inputs/models/lstm.json b/bin/train/inputs/models/lstm.json\\nnew file mode 100644\\nindex 0000000..0bd8496\\n--- /dev/null\\n+++ b/bin/train/inputs/models/lstm.json\\n@@ -0,0 +1,32 @@\\n+{\\n+    \\\"_comments\\\": [\\n+        \\\"Reminders and tips:\\\",\\n+        \\\" * For your data, use nx=1, and use a long ny like 32768.\\\",\\n+        \\\" * For this model, it really helps if you have the delay in your data set\\\",\\n+        \\\"   correctly. I've seen improvements fixing a delay that was off by 10\\\",\\n+        \\\"   samples.\\\",\\n+        \\\" * gamma below is picked so that we end up with a learning rate of about\\\",\\n+        \\\"   1e-4 after 1000 epochs. I've found LSTMs to work with a pretty aggressive\\\",\\n+        \\\"   learning rate that would be out of the question for other architectures.\\\",\\n+        \\\" * Number of units between 8 and 96, layers from 1 to 5 all seem to be ok\\\",\\n+        \\\"   depending on the dataset, though bigger models might not make real-time.\\\"\\n+    ],\\n+    \\\"net\\\": {\\n+        \\\"name\\\": \\\"LSTM\\\",\\n+        \\\"config\\\": {\\n+            \\\"hidden_size\\\": 24,\\n+            \\\"train_burn_in\\\": 4096,\\n+            \\\"train_truncate\\\": 1024,\\n+            \\\"num_layers\\\": 3\\n+        }\\n+    },\\n+    \\\"optimizer\\\": {\\n+        \\\"lr\\\": 0.01\\n+    },\\n+    \\\"lr_scheduler\\\": {\\n+        \\\"class\\\": \\\"ExponentialLR\\\",\\n+        \\\"kwargs\\\": {\\n+            \\\"gamma\\\": 0.995\\n+        }\\n+    }\\n+}\\n\\\\ No newline at end of file\\n\",\"diff --git a/bin/train/main.py b/bin/train/main.py\\nindex f9a1b7c..90f4725 100644\\n--- a/bin/train/main.py\\n+++ b/bin/train/main.py\\n@@ -73,6 +73,31 @@ def plot(\\n         plt.show()\\n \\n \\n+def _create_callbacks(learning_config):\\n+    \\\"\\\"\\\"\\n+    Checkpointing, essentially\\n+    \\\"\\\"\\\"\\n+    # Checkpoints should be run every time the validation check is run.\\n+    # So base it off of learning_config[\\\"trainer\\\"][\\\"val_check_interval\\\"] if it's there.\\n+    if \\\"val_check_interval\\\" in learning_config[\\\"trainer\\\"]:\\n+        kwargs = {\\n+            \\\"every_n_train_steps\\\": learning_config[\\\"trainer\\\"][\\\"val_check_interval\\\"]\\n+        }\\n+    else:\\n+        kwargs = {\\\"every_n_epochs\\\": 1}\\n+\\n+    checkpoint_best = pl.callbacks.model_checkpoint.ModelCheckpoint(\\n+        filename=\\\"{epoch:04d}_{step}_{ESR:.3e}_{MSE:.3e}\\\",\\n+        save_top_k=3,\\n+        monitor=\\\"val_loss\\\",\\n+        **kwargs,\\n+    )\\n+    checkpoint_last = pl.callbacks.model_checkpoint.ModelCheckpoint(\\n+        filename=\\\"checkpoint_last_{epoch:04d}_{step}\\\", **kwargs\\n+    )\\n+    return [checkpoint_best, checkpoint_last]\\n+\\n+\\n def main(args):\\n     outdir = ensure_outdir(args.outdir)\\n     # Read\\n@@ -101,17 +126,7 @@ def main(args):\\n     # ckpt_path = Path(outdir, \\\"checkpoints\\\")\\n     # ckpt_path.mkdir()\\n     trainer = pl.Trainer(\\n-        callbacks=[\\n-            pl.callbacks.model_checkpoint.ModelCheckpoint(\\n-                filename=\\\"{epoch}_{val_loss:.6f}\\\",\\n-                save_top_k=3,\\n-                monitor=\\\"val_loss\\\",\\n-                every_n_epochs=1,\\n-            ),\\n-            pl.callbacks.model_checkpoint.ModelCheckpoint(\\n-                filename=\\\"checkpoint_last_{epoch:04d}\\\", every_n_epochs=1\\n-            ),\\n-        ],\\n+        callbacks=_create_callbacks(learning_config),\\n         default_root_dir=outdir,\\n         **learning_config[\\\"trainer\\\"],\\n     )\\n\",\"diff --git a/nam/_version.py b/nam/_version.py\\nindex 3ced358..493f741 100644\\n--- a/nam/_version.py\\n+++ b/nam/_version.py\\n@@ -1 +1 @@\\n-__version__ = \\\"0.2.1\\\"\\n+__version__ = \\\"0.3.0\\\"\\n\",\"diff --git a/nam/data.py b/nam/data.py\\nindex eadc052..71ace9e 100644\\n--- a/nam/data.py\\n+++ b/nam/data.py\\n@@ -18,7 +18,7 @@ from tqdm import tqdm\\n from ._core import InitializableFromConfig\\n \\n _REQUIRED_SAMPWIDTH = 3\\n-_REQUIRED_RATE = 48_000\\n+REQUIRED_RATE = 48_000\\n _REQUIRED_CHANNELS = 1  # Mono\\n \\n \\n@@ -47,7 +47,7 @@ def wav_to_np(\\n     x_wav = wavio.read(str(filename))\\n     assert x_wav.data.shape[1] == _REQUIRED_CHANNELS, \\\"Mono\\\"\\n     assert x_wav.sampwidth == _REQUIRED_SAMPWIDTH, \\\"24-bit\\\"\\n-    assert x_wav.rate == _REQUIRED_RATE, \\\"48 kHz\\\"\\n+    assert x_wav.rate == REQUIRED_RATE, \\\"48 kHz\\\"\\n \\n     if require_match is not None:\\n         assert required_shape is None\\n@@ -83,20 +83,20 @@ def wav_to_tensor(\\n         return torch.Tensor(arr)\\n \\n \\n-def tensor_to_wav(\\n-    x: torch.Tensor,\\n+def tensor_to_wav(x: torch.Tensor, *args, **kwargs):\\n+    np_to_wav(x.detach().cpu().numpy(), *args, **kwargs)\\n+\\n+\\n+def np_to_wav(\\n+    x: np.ndarray,\\n     filename: Union[str, Path],\\n     rate: int = 48_000,\\n     sampwidth: int = 3,\\n     scale=\\\"none\\\",\\n ):\\n     wavio.write(\\n-        filename,\\n-        (torch.clamp(x, -1.0, 1.0) * (2 ** (8 * sampwidth - 1)))\\n-        .detach()\\n-        .cpu()\\n-        .numpy()\\n-        .astype(np.int32),\\n+        str(filename),\\n+        (np.clip(x, -1.0, 1.0) * (2 ** (8 * sampwidth - 1))).astype(np.int32),\\n         rate,\\n         scale=scale,\\n         sampwidth=sampwidth,\\n\",\"diff --git a/nam/models/_exportable.py b/nam/models/_exportable.py\\nindex 28771d5..d7dec6d 100644\\n--- a/nam/models/_exportable.py\\n+++ b/nam/models/_exportable.py\\n@@ -3,7 +3,14 @@\\n # Author: Steven Atkinson (steven@atkinson.mn)\\n \\n import abc\\n+import json\\n from pathlib import Path\\n+from typing import Tuple\\n+\\n+import numpy as np\\n+\\n+from .._version import __version__\\n+from ..data import np_to_wav\\n \\n \\n class Exportable(abc.ABC):\\n@@ -11,7 +18,6 @@ class Exportable(abc.ABC):\\n     Interface for my custon export format for use in the plugin.\\n     \\\"\\\"\\\"\\n \\n-    @abc.abstractmethod\\n     def export(self, outdir: Path):\\n         \\\"\\\"\\\"\\n         Interface for exporting.\\n@@ -22,7 +28,27 @@ class Exportable(abc.ABC):\\n \\n         :param outdir: Assumed to exist. Can be edited inside at will.\\n         \\\"\\\"\\\"\\n-        pass\\n+        training = self.training\\n+        self.eval()\\n+        with open(Path(outdir, \\\"config.json\\\"), \\\"w\\\") as fp:\\n+            json.dump(\\n+                {\\n+                    \\\"version\\\": __version__,\\n+                    \\\"architecture\\\": self.__class__.__name__,\\n+                    \\\"config\\\": self._export_config(),\\n+                },\\n+                fp,\\n+                indent=4,\\n+            )\\n+        np.save(Path(outdir, \\\"weights.npy\\\"), self._export_weights())\\n+        x, y = self._export_input_output()\\n+        np.save(Path(outdir, \\\"inputs.npy\\\"), x)\\n+        np.save(Path(outdir, \\\"outputs.npy\\\"), y)\\n+        np_to_wav(x, Path(outdir, \\\"input.wav\\\"))\\n+        np_to_wav(y, Path(outdir, \\\"output.wav\\\"))\\n+\\n+        # And resume training state\\n+        self.train(training)\\n \\n     @abc.abstractmethod\\n     def export_cpp_header(self, filename: Path):\\n@@ -31,3 +57,27 @@ class Exportable(abc.ABC):\\n         as text\\n         \\\"\\\"\\\"\\n         pass\\n+\\n+    @abc.abstractmethod\\n+    def _export_config(self):\\n+        \\\"\\\"\\\"\\n+        Creates the JSON of the model's archtecture hyperparameters (number of layers, \\n+        number of units, etc)\\n+\\n+        :return: a JSON serializable object\\n+        \\\"\\\"\\\"\\n+        pass\\n+\\n+    @abc.abstractmethod\\n+    def _export_input_output(self) -> Tuple[np.ndarray, np.ndarray]:\\n+        \\\"\\\"\\\"\\n+        Create an input and corresponding output signal to verify its behavior.\\n+        \\\"\\\"\\\"\\n+        pass\\n+\\n+    @abc.abstractmethod\\n+    def _export_weights(self) -> np.ndarray:\\n+        \\\"\\\"\\\"\\n+        Flatten the weights out to a 1D array\\n+        \\\"\\\"\\\"\\n+        pass\\n\",\"diff --git a/nam/models/base.py b/nam/models/base.py\\nindex b81daa4..514f659 100644\\n--- a/nam/models/base.py\\n+++ b/nam/models/base.py\\n@@ -18,6 +18,7 @@ from .._core import InitializableFromConfig\\n from .conv_net import ConvNet\\n from .hyper_net import HyperConvNet\\n from .linear import Linear\\n+from .recurrent import LSTM\\n \\n \\n class ValidationLoss(Enum):\\n@@ -38,6 +39,13 @@ class ValidationLoss(Enum):\\n \\n @dataclass\\n class LossConfig(InitializableFromConfig):\\n+    \\\"\\\"\\\"\\n+    :param mask_first: How many of the first samples to ignore when comptuing the loss.\\n+    :param dc_weight: Weight for the DC loss term. If 0, ignored.\\n+    :params val_loss: Which loss to track for the best model checkpoint.\\n+    \\\"\\\"\\\"\\n+\\n+    mask_first: int = 0\\n     dc_weight: float = 0.0\\n     val_loss: ValidationLoss = ValidationLoss.MSE\\n \\n@@ -46,7 +54,15 @@ class LossConfig(InitializableFromConfig):\\n         config = super().parse_config(config)\\n         dc_weight = config.get(\\\"dc_weight\\\", 0.0)\\n         val_loss = ValidationLoss(config.get(\\\"val_loss\\\", \\\"mse\\\"))\\n-        return {\\\"dc_weight\\\": dc_weight, \\\"val_loss\\\": val_loss}\\n+        mask_first = config.get(\\\"mask_first\\\", 0)\\n+        return {\\\"mask_first\\\": mask_first, \\\"dc_weight\\\": dc_weight, \\\"val_loss\\\": val_loss}\\n+\\n+    def apply_mask(self, *args):\\n+        \\\"\\\"\\\"\\n+        :param args: (L,) or (B,)\\n+        :return: (L-M,) or (B, L-M)\\n+        \\\"\\\"\\\"\\n+        return tuple(a[..., self.mask_first :] for a in args)\\n \\n \\n class Model(pl.LightningModule, InitializableFromConfig):\\n@@ -118,6 +134,7 @@ class Model(pl.LightningModule, InitializableFromConfig):\\n             \\\"ConvNet\\\": ConvNet.init_from_config,\\n             \\\"HyperConvNet\\\": HyperConvNet.init_from_config,\\n             \\\"Linear\\\": Linear.init_from_config,\\n+            \\\"LSTM\\\": LSTM.init_from_config,\\n         }[net_config[\\\"name\\\"]](net_config[\\\"config\\\"])\\n         loss_config = LossConfig.init_from_config(config.get(\\\"loss\\\", {}))\\n         return {\\n\",\"diff --git a/nam/models/recurrent.py b/nam/models/recurrent.py\\nnew file mode 100644\\nindex 0000000..cbb7e72\\n--- /dev/null\\n+++ b/nam/models/recurrent.py\\n@@ -0,0 +1,179 @@\\n+# File: recurrent.py\\n+# Created Date: Saturday July 2nd 2022\\n+# Author: Steven Atkinson (steven@atkinson.mn)\\n+\\n+\\\"\\\"\\\"\\n+Recurrent models (LSTM)\\n+\\n+TODO batch_first=False (I get it...)\\n+\\\"\\\"\\\"\\n+\\n+import math\\n+from pathlib import Path\\n+from typing import Optional, Tuple\\n+\\n+import numpy as np\\n+import torch\\n+import torch.nn as nn\\n+\\n+from ..data import REQUIRED_RATE\\n+from ._base import BaseNet\\n+\\n+\\n+class LSTM(BaseNet):\\n+    \\\"\\\"\\\"\\n+    ABC for recurrent architectures\\n+    \\\"\\\"\\\"\\n+\\n+    def __init__(\\n+        self,\\n+        hidden_size,\\n+        train_burn_in: Optional[int] = None,\\n+        train_truncate: Optional[int] = None,\\n+        **lstm_kwargs\\n+    ):\\n+        \\\"\\\"\\\"\\n+        :param hidden_size: for LSTM\\n+        :param train_burn_in: Detach calculations from first (this many) samples when \\n+            training to burn in the hidden state.\\n+        :param train_truncate: detach the hidden & cell states every this many steps \\n+            during training so that backpropagation through time is faster + to simulate\\n+            better starting states for h(t0)&c(t0) (instead of zeros)\\n+            TODO recognition head to start the hidden state in a good place?\\n+        \\\"\\\"\\\"\\n+        super().__init__()\\n+        if \\\"batch_first\\\" in lstm_kwargs:\\n+            raise ValueError(\\\"batch_first cannot be set.\\\")\\n+        self._input_size = 1\\n+        self._core = nn.LSTM(\\n+            self._input_size, hidden_size, batch_first=True, **lstm_kwargs\\n+        )\\n+        self._head = nn.Linear(hidden_size, 1)\\n+        self._train_burn_in = train_burn_in\\n+        self._train_truncate = train_truncate\\n+\\n+    @property\\n+    def receptive_field(self) -> int:\\n+        return 1\\n+\\n+    @property\\n+    def pad_start_default(self) -> bool:\\n+        # I should simplify this...\\n+        return True\\n+\\n+    def export_cpp_header(self, filename: Path):\\n+        raise NotImplementedError()\\n+\\n+    def _forward(self, x):\\n+        \\\"\\\"\\\"\\n+        :param x: (B,L)\\n+        :return: (B,L)\\n+        \\\"\\\"\\\"\\n+        x = x[:, :, None]\\n+        if not self.training or self._train_truncate is None:\\n+            output_features = self._core(x)[0]\\n+        else:\\n+            last_hidden_state = None\\n+            output_features_list = []\\n+            if self._train_burn_in is not None:\\n+                last_output_features, last_hidden_state = self._core(\\n+                    x[:, : self._train_burn_in, :]\\n+                )\\n+                output_features_list.append(last_output_features.detach())\\n+            burn_in_offset = 0 if self._train_burn_in is None else self._train_burn_in\\n+            for i in range(burn_in_offset, x.shape[1], self._train_truncate):\\n+                last_output_features, last_hidden_state = self._core(\\n+                    x[:, i : i + self._train_truncate, :,],\\n+                    None\\n+                    if last_hidden_state is None\\n+                    else tuple(z.detach() for z in last_hidden_state),\\n+                )\\n+                output_features_list.append(last_output_features)\\n+            output_features = torch.cat(output_features_list, dim=1)\\n+        return self._head(output_features)[:, :, 0]\\n+\\n+    def _export_cell_weights(\\n+        self, i: int, hidden_state: torch.Tensor, cell_state: torch.Tensor\\n+    ) -> np.ndarray:\\n+        \\\"\\\"\\\"\\n+        * weight matrix (xh -> ifco)\\n+        * bias vector\\n+        * Initial hidden state\\n+        * Initial cell state\\n+        \\\"\\\"\\\"\\n+\\n+        tensors = [\\n+            torch.cat(\\n+                [\\n+                    getattr(self._core, f\\\"weight_ih_l{i}\\\").data,\\n+                    getattr(self._core, f\\\"weight_hh_l{i}\\\").data,\\n+                ],\\n+                dim=1,\\n+            ),\\n+            getattr(self._core, f\\\"bias_ih_l{i}\\\").data\\n+            + getattr(self._core, f\\\"bias_hh_l{i}\\\").data,\\n+            hidden_state,\\n+            cell_state,\\n+        ]\\n+        return np.concatenate([z.detach().cpu().numpy().flatten() for z in tensors])\\n+\\n+    def _export_config(self):\\n+        return {\\n+            \\\"input_size\\\": self._core.input_size,\\n+            \\\"hidden_size\\\": self._core.hidden_size,\\n+            \\\"num_layers\\\": self._core.num_layers,\\n+        }\\n+\\n+    def _export_input_output(self, x=None):\\n+        x = self._export_input_signal()[None, :, None] if x is None else x\\n+        y = self._head(self._core(x, self._get_initial_state())[0][0])[:, 0]\\n+        return x[0, :, 0].detach().cpu().numpy(), y.detach().cpu().numpy().flatten()\\n+\\n+    def _export_input_signal(self):\\n+        rate = REQUIRED_RATE\\n+        return torch.cat(\\n+            [\\n+                torch.zeros((rate,)),\\n+                0.5\\n+                * torch.sin(\\n+                    2.0 * math.pi * 220.0 * torch.linspace(0.0, 1.0, rate + 1)[:-1]\\n+                ),\\n+                torch.zeros((rate,)),\\n+            ]\\n+        )\\n+\\n+    def _export_weights(self):\\n+        \\\"\\\"\\\"\\n+        * Loop over cells:\\n+            * weight matrix (xh -> ifco)\\n+            * bias vector\\n+            * Initial hidden state\\n+            * Initial cell state\\n+        * Head weights\\n+        * Head bias\\n+        \\\"\\\"\\\"\\n+        return np.concatenate(\\n+            [\\n+                self._export_cell_weights(i, h, c)\\n+                for i, (h, c) in enumerate(zip(*self._get_initial_state()))\\n+            ]\\n+            + [\\n+                self._head.weight.data.detach().cpu().numpy().flatten(),\\n+                self._head.bias.data.detach().cpu().numpy().flatten(),\\n+            ]\\n+        )\\n+\\n+    def _get_initial_state(self, inputs=None) -> Tuple[torch.Tensor, torch.Tensor]:\\n+        \\\"\\\"\\\"\\n+        Convenience function to find a good hidden state to start the plugin at\\n+\\n+        DX=input size\\n+        L=num layers\\n+        S=sequence length\\n+        :param inputs: (1,S,DX)\\n+\\n+        :return: (L,DH), (L,DH)\\n+        \\\"\\\"\\\"\\n+        inputs = torch.zeros((1, 48_000, 1)) if inputs is None else inputs\\n+        _, (h, c) = self._core(inputs)\\n+        return h, c\\n\\\\ No newline at end of file\\n\"]", "test_patch": "[\"diff --git a/nam/models/_base.py b/nam/models/_base.py\\nindex 8d7675ff..7fec0616 100644\\n--- a/nam/models/_base.py\\n+++ b/nam/models/_base.py\\n@@ -39,7 +39,7 @@ def _forward(self, *args) -> torch.Tensor:\\n         \\\"\\\"\\\"\\n         pass\\n \\n-    def _test_signal(\\n+    def _export_input_output(\\n         self, seed=0, extra_length=13\\n     ) -> Tuple[torch.Tensor, torch.Tensor]:\\n         x = torch.Tensor(\\n\",\"diff --git a/nam/models/conv_net.py b/nam/models/conv_net.py\\nindex 76d1ba8c..c6f25c30 100644\\n--- a/nam/models/conv_net.py\\n+++ b/nam/models/conv_net.py\\n@@ -3,6 +3,7 @@\\n # Author: Steven Atkinson (steven@atkinson.mn)\\n \\n import json\\n+import math\\n from enum import Enum\\n from functools import partial\\n from pathlib import Path\\n@@ -16,7 +17,7 @@\\n \\n \\n from .. import __version__\\n-from ..data import wav_to_tensor\\n+from ..data import REQUIRED_RATE, wav_to_tensor\\n from ._base import BaseNet\\n \\n _CONV_NAME = \\\"conv\\\"\\n@@ -164,14 +165,73 @@ def _num_layers(self) -> int:\\n     def _batchnorm(self) -> bool:\\n         return _BATCHNORM_NAME in self._net._modules[\\\"block_0\\\"]._modules\\n \\n-    def export(self, outdir: Path):\\n+    def export_cpp_header(self, filename: Path):\\n+        with TemporaryDirectory() as tmpdir:\\n+            tmpdir = Path(tmpdir)\\n+            self.export(Path(tmpdir))\\n+            with open(Path(tmpdir, \\\"config.json\\\"), \\\"r\\\") as fp:\\n+                _c = json.load(fp)\\n+            version = _c[\\\"version\\\"]\\n+            config = _c[\\\"config\\\"]\\n+            with open(filename, \\\"w\\\") as f:\\n+                f.writelines(\\n+                    (\\n+                        \\\"#pragma once\\\\n\\\",\\n+                        \\\"// Automatically-generated model file\\\\n\\\",\\n+                        \\\"#include <vector>\\\\n\\\",\\n+                        f'#define PYTHON_MODEL_VERSION \\\"{version}\\\"\\\\n',\\n+                        f\\\"const int CHANNELS = {config['channels']};\\\\n\\\",\\n+                        f\\\"const bool BATCHNORM = {'true' if config['batchnorm'] else 'false'};\\\\n\\\",\\n+                        \\\"std::vector<int> DILATIONS{\\\"\\n+                        + \\\",\\\".join([str(d) for d in config[\\\"dilations\\\"]])\\n+                        + \\\"};\\\\n\\\",\\n+                        f\\\"const std::string ACTIVATION = \\\\\\\"{config['activation']}\\\\\\\";\\\\n\\\",\\n+                        \\\"std::vector<float> PARAMS{\\\"\\n+                        + \\\",\\\".join(\\n+                            [f\\\"{w:.16f}\\\" for w in np.load(Path(tmpdir, \\\"weights.npy\\\"))]\\n+                        )\\n+                        + \\\"};\\\\n\\\",\\n+                    )\\n+                )\\n+\\n+    def _export_config(self):\\n+        return {\\n+            \\\"channels\\\": self._channels,\\n+            \\\"dilations\\\": self._get_dilations(),\\n+            \\\"batchnorm\\\": self._batchnorm,\\n+            \\\"activation\\\": self._activation,\\n+        }\\n+\\n+    def _export_input_output(self, x=None) -> Tuple[np.ndarray, np.ndarray]:\\n+        \\\"\\\"\\\"\\n+        :return: (L,), (L,)\\n         \\\"\\\"\\\"\\n-        Files created:\\n-        * config.json\\n-        * weights.npy\\n-        * input.npy\\n-        * output.npy\\n+        with torch.no_grad():\\n+            training = self.training\\n+            self.eval()\\n+            x = self._export_input_signal() if x is None else x\\n+            y = self(x, pad_start=True)\\n+            self.train(training)\\n+            return tuple(z.detach().cpu().numpy() for z in (x, y))\\n+\\n+    def _export_input_signal(self):\\n+        \\\"\\\"\\\"\\n+        :return: (L,)\\n+        \\\"\\\"\\\"\\n+        rate = REQUIRED_RATE\\n+        return torch.cat(\\n+            [\\n+                torch.zeros((rate,)),\\n+                0.5\\n+                * torch.sin(\\n+                    2.0 * math.pi * 220.0 * torch.linspace(0.0, 1.0, rate + 1)[:-1]\\n+                ),\\n+                torch.zeros((rate,)),\\n+            ]\\n+        )\\n \\n+    def _export_weights(self) -> np.ndarray:\\n+        \\\"\\\"\\\"\\n         weights are serialized to weights.npy in the following order:\\n         * (expand: no params)\\n         * loop blocks 0,...,L-1\\n@@ -188,27 +248,7 @@ def export(self, outdir: Path):\\n             * weight (C, 1, 1)\\n             * bias (1, 1)\\n         * (flatten: no params)\\n-\\n-        A test input & output are also provided, input.npy and output.npy\\n         \\\"\\\"\\\"\\n-        training = self.training\\n-        self.eval()\\n-        with open(Path(outdir, \\\"config.json\\\"), \\\"w\\\") as fp:\\n-            json.dump(\\n-                {\\n-                    \\\"version\\\": __version__,\\n-                    \\\"architecture\\\": \\\"ConvNet\\\",\\n-                    \\\"config\\\": {\\n-                        \\\"channels\\\": self._channels,\\n-                        \\\"dilations\\\": self._get_dilations(),\\n-                        \\\"batchnorm\\\": self._batchnorm,\\n-                        \\\"activation\\\": self._activation,\\n-                    },\\n-                },\\n-                fp,\\n-                indent=4,\\n-            )\\n-\\n         params = []\\n         for i in range(self._num_layers):\\n             block_name = f\\\"block_{i}\\\"\\n@@ -228,45 +268,7 @@ def export(self, outdir: Path):\\n         params.append(head.weight.flatten())\\n         params.append(head.bias.flatten())\\n         params = torch.cat(params).detach().cpu().numpy()\\n-        # Hope I don't regret using np.save...\\n-        np.save(Path(outdir, \\\"weights.npy\\\"), params)\\n-\\n-        # And an input/output to verify correct computation:\\n-        x, y = self._test_signal()\\n-        np.save(Path(outdir, \\\"input.npy\\\"), x.detach().cpu().numpy())\\n-        np.save(Path(outdir, \\\"output.npy\\\"), y.detach().cpu().numpy())\\n-\\n-        # And resume training state\\n-        self.train(training)\\n-\\n-    def export_cpp_header(self, filename: Path):\\n-        with TemporaryDirectory() as tmpdir:\\n-            tmpdir = Path(tmpdir)\\n-            self.export(Path(tmpdir))\\n-            with open(Path(tmpdir, \\\"config.json\\\"), \\\"r\\\") as fp:\\n-                _c = json.load(fp)\\n-            version = _c[\\\"version\\\"]\\n-            config = _c[\\\"config\\\"]\\n-            with open(filename, \\\"w\\\") as f:\\n-                f.writelines(\\n-                    (\\n-                        \\\"#pragma once\\\\n\\\",\\n-                        \\\"// Automatically-generated model file\\\\n\\\",\\n-                        \\\"#include <vector>\\\\n\\\",\\n-                        f'#define PYTHON_MODEL_VERSION \\\"{version}\\\"\\\\n',\\n-                        f\\\"const int CHANNELS = {config['channels']};\\\\n\\\",\\n-                        f\\\"const bool BATCHNORM = {'true' if config['batchnorm'] else 'false'};\\\\n\\\",\\n-                        \\\"std::vector<int> DILATIONS{\\\"\\n-                        + \\\",\\\".join([str(d) for d in config[\\\"dilations\\\"]])\\n-                        + \\\"};\\\\n\\\",\\n-                        f\\\"const std::string ACTIVATION = \\\\\\\"{config['activation']}\\\\\\\";\\\\n\\\",\\n-                        \\\"std::vector<float> PARAMS{\\\"\\n-                        + \\\",\\\".join(\\n-                            [f\\\"{w:.16f}\\\" for w in np.load(Path(tmpdir, \\\"weights.npy\\\"))]\\n-                        )\\n-                        + \\\"};\\\\n\\\",\\n-                    )\\n-                )\\n+        return params\\n \\n     def _forward(self, x):\\n         y = self._net(x)\\n\",\"diff --git a/nam/models/hyper_net.py b/nam/models/hyper_net.py\\nindex 5ecb428c..6c8c0f19 100644\\n--- a/nam/models/hyper_net.py\\n+++ b/nam/models/hyper_net.py\\n@@ -359,13 +359,13 @@ def export(self, outdir: Path):\\n         training = self.training\\n         self.eval()\\n         with open(Path(outdir, \\\"config.json\\\"), \\\"w\\\") as fp:\\n-            json.dump(self._get_export_config(), fp, indent=4)\\n+            json.dump(self._export_config(), fp, indent=4)\\n \\n         # Hope I don't regret using np.save...\\n-        np.save(Path(outdir, \\\"weights.npy\\\"), self._get_export_params())\\n+        np.save(Path(outdir, \\\"weights.npy\\\"), self._export_weights())\\n \\n         # And an input/output to verify correct computation:\\n-        params, x, y = self._test_signal()\\n+        params, x, y = self._export_input_output()\\n         np.save(Path(outdir, \\\"test_signal_params.npy\\\"), params.detach().cpu().numpy())\\n         np.save(Path(outdir, \\\"test_signal_input.npy\\\"), x.detach().cpu().numpy())\\n         np.save(Path(outdir, \\\"test_signal_output.npy\\\"), y.detach().cpu().numpy())\\n@@ -505,7 +505,7 @@ def _get_dilations(self) -> List[int]:\\n                 dilations.append(layer.dilation[0])\\n         return dilations\\n \\n-    def _get_export_config(self):\\n+    def _export_config(self):\\n         return {\\n             \\\"version\\\": __version__,\\n             \\\"architecture\\\": \\\"HyperConvNet\\\",\\n@@ -525,16 +525,16 @@ def _get_export_config(self):\\n             },\\n         }\\n \\n-    def _get_export_params(self) -> np.ndarray:\\n+    def _export_weights(self) -> np.ndarray:\\n         \\\"\\\"\\\"\\n         Flatten the parameters of the network to be exported.\\n         See doctsring for .export() for ensured layout.\\n         \\\"\\\"\\\"\\n         return np.concatenate(\\n-            [self._hyper_net.get_export_params(), self._get_net_export_params()]\\n+            [self._hyper_net.get_export_params(), self._export_net_weights()]\\n         )\\n \\n-    def _get_net_export_params(self) -> np.ndarray:\\n+    def _export_net_weights(self) -> np.ndarray:\\n         \\\"\\\"\\\"\\n         Only the buffers--parameters are outputted by the hypernet!\\n         \\\"\\\"\\\"\\n@@ -550,7 +550,7 @@ def _get_net_export_params(self) -> np.ndarray:\\n             else torch.cat(params).detach().cpu().numpy()\\n         )\\n \\n-    def _test_signal(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\\n+    def _export_input_output(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\\n         params = torch.randn((self._hyper_net.input_dim,))\\n         x = torch.randn((2 * self.receptive_field,))\\n         x = 0.5 * x / x.abs().max()\\n\",\"diff --git a/nam/models/linear.py b/nam/models/linear.py\\nindex a957fddc..490a9147 100644\\n--- a/nam/models/linear.py\\n+++ b/nam/models/linear.py\\n@@ -55,7 +55,7 @@ def export(self, outdir: Path):\\n         np.save(Path(outdir, \\\"weights.npy\\\"), params)\\n \\n         # And an input/output to verify correct computation:\\n-        x, y = self._test_signal()\\n+        x, y = self._export_input_output()\\n         np.save(Path(outdir, \\\"input.npy\\\"), x.detach().cpu().numpy())\\n         np.save(Path(outdir, \\\"output.npy\\\"), y.detach().cpu().numpy())\\n \\n\",\"diff --git a/tests/test_nam/test_models/base.py b/tests/test_nam/test_models/base.py\\nindex b6d1ba2b..c0c25a1c 100644\\n--- a/tests/test_nam/test_models/base.py\\n+++ b/tests/test_nam/test_models/base.py\\n@@ -3,18 +3,28 @@\\n # Author: Steven Atkinson (steven@atkinson.mn)\\n \\n import abc\\n+from pathlib import Path\\n+from tempfile import TemporaryDirectory\\n \\n \\n class Base(abc.ABC):\\n     @classmethod\\n-    def setup_class(cls, args=None, kwargs=None):\\n+    def setup_class(cls, C, args=None, kwargs=None):\\n+        cls._C = C\\n         cls._args = () if args is None else args\\n         cls._kwargs = {} if kwargs is None else kwargs\\n \\n-    @abc.abstractmethod\\n-    def test_init(self):\\n-        pass\\n+    def test_init(self, args=None, kwargs=None):\\n+        obj = self._construct(args=args, kwargs=kwargs)\\n+        assert isinstance(obj, self._C)\\n+\\n+    def test_export(self, args=None, kwargs=None):\\n+        model = self._construct(args=args, kwargs=kwargs)\\n+        with TemporaryDirectory() as tmpdir:\\n+            model.export(Path(tmpdir))\\n+\\n+    def _construct(self, args=None, kwargs=None):\\n+        args = args if args is not None else self._args\\n+        kwargs = kwargs if kwargs is not None else self._kwargs\\n+        return self._C(*args, **kwargs)\\n \\n-    @abc.abstractmethod\\n-    def test_export(self):\\n-        pass\\n\",\"diff --git a/tests/test_nam/test_models/test_conv_net.py b/tests/test_nam/test_models/test_conv_net.py\\nindex 01bb7e59..d05189cc 100644\\n--- a/tests/test_nam/test_models/test_conv_net.py\\n+++ b/tests/test_nam/test_models/test_conv_net.py\\n@@ -13,27 +13,27 @@\\n \\n \\n class TestConvNet(Base):\\n+    @classmethod\\n+    def setup_class(cls):\\n+        channels = 3\\n+        dilations = [1, 2, 4]\\n+        return super().setup_class(\\n+            conv_net.ConvNet,\\n+            (channels, dilations),\\n+            {\\\"batchnorm\\\": False, \\\"activation\\\": \\\"Tanh\\\"},\\n+        )\\n+\\n     @pytest.mark.parametrize(\\n         (\\\"batchnorm,activation\\\"), ((False, \\\"ReLU\\\"), (True, \\\"Tanh\\\"))\\n     )\\n     def test_init(self, batchnorm, activation):\\n-        channels = 3\\n-        dilations = [1, 2, 4]\\n-        conv_net.ConvNet(\\n-            channels, dilations, batchnorm=batchnorm, activation=activation\\n-        )\\n+        super().test_init(kwargs={\\\"batchnorm\\\": batchnorm, \\\"activation\\\": activation})\\n \\n     @pytest.mark.parametrize(\\n         (\\\"batchnorm,activation\\\"), ((False, \\\"ReLU\\\"), (True, \\\"Tanh\\\"))\\n     )\\n     def test_export(self, batchnorm, activation):\\n-        channels = 3\\n-        dilations = [1, 2, 4]\\n-        model = conv_net.ConvNet(\\n-            channels, dilations, batchnorm=batchnorm, activation=activation\\n-        )\\n-        with TemporaryDirectory() as tmpdir:\\n-            model.export(Path(tmpdir))\\n+        super().test_export(kwargs={\\\"batchnorm\\\": batchnorm, \\\"activation\\\": activation})\\n \\n \\n if __name__ == \\\"__main__\\\":\\n\",\"diff --git a/tests/test_nam/test_models/test_hyper_net.py b/tests/test_nam/test_models/test_hyper_net.py\\nindex 04c13c29..9b01a78c 100644\\n--- a/tests/test_nam/test_models/test_hyper_net.py\\n+++ b/tests/test_nam/test_models/test_hyper_net.py\\n@@ -13,10 +13,15 @@\\n \\n \\n class TestHyperConvNet(Base):\\n+    @classmethod\\n+    def setup_class(cls):\\n+        return super().setup_class(hyper_net.HyperConvNet, (), {})\\n+\\n     @pytest.mark.parametrize(\\n         (\\\"batchnorm,activation\\\"), ((False, \\\"ReLU\\\"), (True, \\\"Tanh\\\"))\\n     )\\n     def test_init(self, batchnorm, activation):\\n+        # TODO refactor\\n         channels = 3\\n         dilations = [1, 2, 4]\\n         assert isinstance(\\n@@ -35,6 +40,7 @@ def test_init(self, batchnorm, activation):\\n         (\\\"batchnorm,activation\\\"), ((False, \\\"ReLU\\\"), (True, \\\"Tanh\\\"))\\n     )\\n     def test_export(self, batchnorm, activation):\\n+        # TODO refactor\\n         channels = 3\\n         dilations = [1, 2, 4]\\n         model = self._construct(\\n@@ -49,6 +55,7 @@ def test_export(self, batchnorm, activation):\\n             model.export(Path(tmpdir))\\n \\n     def test_export_cpp_header(self):\\n+        # TODO refactor\\n         with TemporaryDirectory() as tmpdir:\\n             self._construct().export_cpp_header(Path(tmpdir, \\\"model.h\\\"))\\n \\n@@ -70,8 +77,9 @@ def _config(self, batchnorm=True, activation=\\\"Tanh\\\", dilations=None, channels=7)\\n         }\\n \\n     def _construct(self, config=None):\\n+        # Override for simplicity...\\n         config = self._config() if config is None else config\\n-        return hyper_net.HyperConvNet.init_from_config(config)\\n+        return self._C.init_from_config(config)\\n \\n \\n if __name__ == \\\"__main__\\\":\\n\",\"diff --git a/tests/test_nam/test_models/test_recurrent.py b/tests/test_nam/test_models/test_recurrent.py\\nnew file mode 100644\\nindex 00000000..8b7be925\\n--- /dev/null\\n+++ b/tests/test_nam/test_models/test_recurrent.py\\n@@ -0,0 +1,19 @@\\n+# File: test_recurrent.py\\n+# Created Date: Sunday July 17th 2022\\n+# Author: Steven Atkinson (steven@atkinson.mn)\\n+\\n+from .base import Base\\n+\\n+from nam.models import recurrent\\n+\\n+\\n+class TestLSTM(Base):\\n+    @classmethod\\n+    def setup_class(cls):\\n+        hidden_size = 3\\n+        return super().setup_class(\\n+            recurrent.LSTM,\\n+            args=(hidden_size,),\\n+            kwargs={\\\"train_burn_in\\\": 3, \\\"train_truncate\\\": 5, \\\"num_layers\\\": 2},\\n+        )\\n+\\n\"]", "hints_text": ""}
