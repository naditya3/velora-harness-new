{"instance_id": "1267082758168404", "repo": "skypilot-org/skypilot", "base_commit": "f2033eabbd58e84a9e47f8339868d0ff3a9840e9", "problem_statement": "[Core] Fail to launch task on existing cluster with odd GPU numbers when region/zone specified:\\nReproducible code:\\r\\n```\\r\\nsky gpunode --gpus K80:4 --region us-central1 --cloud gcp -c test-gpu\\r\\nsky exec --gpus K80:3 --region us-central1 test-gpu 'echo hi'\\r\\n```\\r\\nIt raises:\\r\\n```\\r\\nTask from command: echo hi\\r\\nValueError: Accelerator \"K80\" is not available in \"us-central1\" region/zone.\\r\\n```\\r\\n\\r\\nHowever, `sky exec --gpus K80:2 --region us-central1 test-gpu 'echo hi'`works, which is inconsistent.", "FAIL_TO_PASS": ["tests/test_optimizer_dryruns.py::test_invalid_accelerators_regions", "tests/test_optimizer_dryruns.py::test_invalid_region", "tests/test_optimizer_dryruns.py::test_instance_type_mistmatches_accelerators"], "PASS_TO_PASS": ["tests/test_spot.py::TestReservedClustersOperations::test_autostop_spot_controller", "tests/test_optimizer_dryruns.py::test_parse_name_only_yaml", "tests/test_smoke.py::test_core_api", "tests/test_storage.py::TestStorageSpecValidation::test_source_and_noname", "tests/test_list_accelerators.py::test_list_accelerators_name_clouds_filter", "tests/test_cli.py::test_infer_gpunode_type", "tests/test_smoke.py::TestYamlSpecs::test_load_dump_yaml_config_equivalent", "tests/test_optimizer_dryruns.py::test_parse_accelerators_from_yaml", "tests/test_config.py::test_no_config", "tests/test_spot.py::test_spot_nonexist_strategy", "tests/test_optimizer_dryruns.py::test_invalid_cpus", "tests/test_optimizer_dryruns.py::test_parse_empty_yaml", "tests/test_optimizer_dryruns.py::test_invalid_instance_type", "tests/test_optimizer_dryruns.py::test_invalid_memory", "tests/test_optimizer_dryruns.py::test_parse_valid_envs_yaml", "tests/test_pycryptodome_version.py::test_pycryptodome_version", "tests/test_optimizer_dryruns.py::test_clouds_not_enabled", "tests/test_optimizer_dryruns.py::test_instance_type_mismatches_cpus", "tests/test_cli.py::test_show_gpus", "tests/test_cli.py::test_infer_tpunode_type", "tests/test_wheels.py::test_build_wheels", "tests/test_optimizer_dryruns.py::test_invalid_num_nodes", "tests/test_optimizer_dryruns.py::test_valid_image", "tests/test_storage.py::TestStorageSpecLocalSource::test_source_single_file", "tests/test_optimizer_dryruns.py::test_parse_invalid_envs_yaml", "tests/test_optimizer_dryruns.py::test_instance_type_mismatches_memory", "tests/test_list_accelerators.py::test_list_accelerators", "tests/test_cli.py::test_infer_cpunode_type", "tests/test_storage.py::TestStorageSpecValidation::test_source_and_name", "tests/test_storage.py::TestStorageSpecLocalSource::test_source_multifile_conflict", "tests/test_optimizer_dryruns.py::test_parse_memory_from_yaml", "tests/test_optimizer_dryruns.py::test_infer_cloud_from_instance_type", "tests/test_smoke.py::TestStorageWithCredentials::test_invalid_names[invalid_name_list1-StoreType.GCS]", "tests/test_list_accelerators.py::test_list_ccelerators_all", "tests/test_optimizer_dryruns.py::test_invalid_cloud_tpu", "tests/test_storage.py::TestStorageSpecValidation::test_uri_in_name", "tests/test_storage.py::TestStorageSpecLocalSource::test_source_trailing_slashes", "tests/test_list_accelerators.py::test_list_accelerators_positive_quantity_filter", "tests/test_spot.py::TestReservedClustersOperations::test_down_spot_controller", "tests/test_optimizer_dryruns.py::test_invalid_image", "tests/test_smoke.py::TestStorageWithCredentials::test_invalid_names[invalid_name_list0-StoreType.S3]", "tests/test_list_accelerators.py::test_list_accelerators_name_filter", "tests/test_storage.py::TestStorageSpecValidation::test_name_and_nosource", "tests/test_list_accelerators.py::test_list_accelerators_region_filter", "tests/test_spot.py::TestReservedClustersOperations::test_stop_spot_controller", "tests/test_storage.py::TestStorageSpecValidation::test_noname_and_nosource", "tests/test_spot.py::TestReservedClustersOperations::test_cancel_on_spot_controller", "tests/test_config.py::test_empty_config", "tests/test_list_accelerators.py::test_list_accelerators_name_quantity_filter", "tests/test_storage.py::TestStorageSpecLocalSource::test_nonexist_local_source", "tests/test_list_accelerators.py::test_list_accelerators_name_quantity_clouds_filter", "tests/test_optimizer_dryruns.py::test_parse_cpus_from_yaml", "tests/test_config.py::test_config_get_set_nested", "tests/test_config.py::test_config_with_env", "tests/test_optimizer_dryruns.py::test_invalid_zone"], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/skypilot-org_skypilot:f2033eabbd58e84a9e47f8339868d0ff3a9840e9", "patch": "[\"diff --git a/sky/clouds/aws.py b/sky/clouds/aws.py\\nindex 68fe88160a8..f186b036864 100644\\n--- a/sky/clouds/aws.py\\n+++ b/sky/clouds/aws.py\\n@@ -360,8 +360,8 @@ def make_deploy_resources_variables(\\n             **AWS._get_disk_specs(r.disk_tier)\\n         }\\n \\n-    def get_feasible_launchable_resources(self,\\n-                                          resources: 'resources_lib.Resources'):\\n+    def _get_feasible_launchable_resources(\\n+            self, resources: 'resources_lib.Resources'):\\n         if resources.instance_type is not None:\\n             assert resources.is_launchable(), resources\\n             # Treat Resources(AWS, p3.2x, V100) as Resources(AWS, p3.2x).\\n\",\"diff --git a/sky/clouds/azure.py b/sky/clouds/azure.py\\nindex b311f81daa0..9072c2954c0 100644\\n--- a/sky/clouds/azure.py\\n+++ b/sky/clouds/azure.py\\n@@ -248,7 +248,7 @@ def make_deploy_resources_variables(\\n             'disk_tier': Azure._get_disk_type(r.disk_tier)\\n         }\\n \\n-    def get_feasible_launchable_resources(self, resources):\\n+    def _get_feasible_launchable_resources(self, resources):\\n \\n         def failover_disk_tier(\\n                 instance_type: str,\\n@@ -288,11 +288,15 @@ def failover_disk_tier(\\n             return ([], [])\\n         if resources.instance_type is not None:\\n             assert resources.is_launchable(), resources\\n-            # Treat Resources(AWS, p3.2x, V100) as Resources(AWS, p3.2x).\\n+            ok, disk_tier = failover_disk_tier(resources.instance_type,\\n+                                               resources.disk_tier)\\n+            if not ok:\\n+                return ([], [])\\n+            # Treat Resources(Azure, Standard_NC4as_T4_v3, T4) as\\n+            # Resources(Azure, Standard_NC4as_T4_v3).\\n             resources = resources.copy(\\n                 accelerators=None,\\n-                disk_tier=failover_disk_tier(resources.instance_type,\\n-                                             resources.disk_tier),\\n+                disk_tier=disk_tier,\\n             )\\n             return ([resources], [])\\n \\n\",\"diff --git a/sky/clouds/cloud.py b/sky/clouds/cloud.py\\nindex 9e0ed47a3c1..e5109db69b3 100644\\n--- a/sky/clouds/cloud.py\\n+++ b/sky/clouds/cloud.py\\n@@ -12,7 +12,7 @@\\n \\n if typing.TYPE_CHECKING:\\n     from sky import status_lib\\n-    from sky import resources\\n+    from sky import resources as resources_lib\\n \\n \\n class CloudImplementationFeatures(enum.Enum):\\n@@ -219,7 +219,7 @@ def is_same_cloud(self, other):\\n \\n     def make_deploy_resources_variables(\\n         self,\\n-        resources: 'resources.Resources',\\n+        resources: 'resources_lib.Resources',\\n         region: 'Region',\\n         zones: Optional[List['Zone']],\\n     ) -> Dict[str, Optional[str]]:\\n@@ -294,6 +294,11 @@ def get_feasible_launchable_resources(self, resources):\\n \\n         Launchable resources require a cloud and an instance type be assigned.\\n         \\\"\\\"\\\"\\n+        if resources.is_launchable():\\n+            self._check_instance_type_accelerators_combination(resources)\\n+        return self._get_feasible_launchable_resources(resources)\\n+\\n+    def _get_feasible_launchable_resources(self, resources):\\n         raise NotImplementedError\\n \\n     @classmethod\\n@@ -387,8 +392,8 @@ def accelerator_in_region_or_zone(self,\\n         \\\"\\\"\\\"Returns whether the accelerator is valid in the region or zone.\\\"\\\"\\\"\\n         raise NotImplementedError\\n \\n-    def need_cleanup_after_preemption(self,\\n-                                      resource: 'resources.Resources') -> bool:\\n+    def need_cleanup_after_preemption(\\n+            self, resource: 'resources_lib.Resources') -> bool:\\n         \\\"\\\"\\\"Returns whether a spot resource needs cleanup after preeemption.\\n \\n         In most cases, spot resources do not need cleanup after preemption,\\n@@ -470,7 +475,46 @@ def check_disk_tier_enabled(cls, instance_type: str,\\n         raise NotImplementedError\\n \\n     @classmethod\\n-    # pylint: disable=unused-argument\\n+    def _check_instance_type_accelerators_combination(\\n+            cls, resources: 'resources_lib.Resources') -> None:\\n+        \\\"\\\"\\\"Errors out if the accelerator is not supported by the instance type.\\n+\\n+        This function is overridden by GCP for host-accelerator logic.\\n+\\n+        Raises:\\n+            ResourcesMismatchError: If the accelerator is not supported.\\n+        \\\"\\\"\\\"\\n+        assert resources.is_launchable(), resources\\n+\\n+        def _equal_accelerators(acc_requested, acc_from_instance_type):\\n+            if acc_requested is None:\\n+                return acc_from_instance_type is None\\n+            if acc_from_instance_type is None:\\n+                return False\\n+\\n+            for acc in acc_requested:\\n+                if acc not in acc_from_instance_type:\\n+                    return False\\n+                if acc_requested[acc] != acc_from_instance_type[acc]:\\n+                    return False\\n+            return True\\n+\\n+        acc_from_instance_type = (cls.get_accelerators_from_instance_type(\\n+            resources.instance_type))\\n+        if not _equal_accelerators(resources.accelerators,\\n+                                   acc_from_instance_type):\\n+            with ux_utils.print_exception_no_traceback():\\n+                raise exceptions.ResourcesMismatchError(\\n+                    'Infeasible resource demands found:'\\n+                    '\\\\n  Instance type requested: '\\n+                    f'{resources.instance_type}\\\\n'\\n+                    f'  Accelerators for {resources.instance_type}: '\\n+                    f'{acc_from_instance_type}\\\\n'\\n+                    f'  Accelerators requested: {resources.accelerators}\\\\n'\\n+                    f'To fix: either only specify instance_type, or '\\n+                    'change the accelerators field to be consistent.')\\n+\\n+    @classmethod\\n     def check_quota_available(cls,\\n                               region: str,\\n                               instance_type: str,\\n\",\"diff --git a/sky/clouds/gcp.py b/sky/clouds/gcp.py\\nindex c9d44f54cf8..75612582c1d 100644\\n--- a/sky/clouds/gcp.py\\n+++ b/sky/clouds/gcp.py\\n@@ -367,7 +367,7 @@ def make_deploy_resources_variables(\\n \\n         return resources_vars\\n \\n-    def get_feasible_launchable_resources(self, resources):\\n+    def _get_feasible_launchable_resources(self, resources):\\n         if resources.instance_type is not None:\\n             assert resources.is_launchable(), resources\\n             return ([resources], [])\\n@@ -719,18 +719,12 @@ def get_project_id(cls, dryrun: bool = False) -> str:\\n         return project_id\\n \\n     @staticmethod\\n-    def check_host_accelerator_compatibility(\\n-            instance_type: str, accelerators: Optional[Dict[str, int]]) -> None:\\n-        service_catalog.check_host_accelerator_compatibility(\\n-            instance_type, accelerators, 'gcp')\\n-\\n-    @staticmethod\\n-    def check_accelerator_attachable_to_host(\\n-            instance_type: str,\\n-            accelerators: Optional[Dict[str, int]],\\n-            zone: Optional[str] = None) -> None:\\n+    def _check_instance_type_accelerators_combination(\\n+            resources: 'resources.Resources') -> None:\\n+        assert resources.is_launchable(), resources\\n         service_catalog.check_accelerator_attachable_to_host(\\n-            instance_type, accelerators, zone, 'gcp')\\n+            resources.instance_type, resources.accelerators, resources.zone,\\n+            'gcp')\\n \\n     @classmethod\\n     def check_disk_tier_enabled(cls, instance_type: str,\\n\",\"diff --git a/sky/clouds/ibm.py b/sky/clouds/ibm.py\\nindex 90b709c0589..53887aa1805 100644\\n--- a/sky/clouds/ibm.py\\n+++ b/sky/clouds/ibm.py\\n@@ -246,8 +246,8 @@ def get_default_instance_type(\\n                                                          disk_tier=disk_tier,\\n                                                          clouds='ibm')\\n \\n-    def get_feasible_launchable_resources(self,\\n-                                          resources: 'resources_lib.Resources'):\\n+    def _get_feasible_launchable_resources(\\n+            self, resources: 'resources_lib.Resources'):\\n         \\\"\\\"\\\"Returns a list of feasible and launchable resources.\\n \\n         Feasible resources refer to an offering respecting the resource\\n\",\"diff --git a/sky/clouds/lambda_cloud.py b/sky/clouds/lambda_cloud.py\\nindex 2bf6e484d06..5a2d7deeba2 100644\\n--- a/sky/clouds/lambda_cloud.py\\n+++ b/sky/clouds/lambda_cloud.py\\n@@ -162,8 +162,8 @@ def make_deploy_resources_variables(\\n             'region': region.name,\\n         }\\n \\n-    def get_feasible_launchable_resources(self,\\n-                                          resources: 'resources_lib.Resources'):\\n+    def _get_feasible_launchable_resources(\\n+            self, resources: 'resources_lib.Resources'):\\n         if resources.use_spot or resources.disk_tier is not None:\\n             return ([], [])\\n         if resources.instance_type is not None:\\n\",\"diff --git a/sky/clouds/local.py b/sky/clouds/local.py\\nindex f7881933b75..64d561067d1 100644\\n--- a/sky/clouds/local.py\\n+++ b/sky/clouds/local.py\\n@@ -134,8 +134,8 @@ def make_deploy_resources_variables(\\n             zones: Optional[List['clouds.Zone']]) -> Dict[str, Optional[str]]:\\n         return {}\\n \\n-    def get_feasible_launchable_resources(self,\\n-                                          resources: 'resources_lib.Resources'):\\n+    def _get_feasible_launchable_resources(\\n+            self, resources: 'resources_lib.Resources'):\\n         if resources.disk_tier is not None:\\n             return ([], [])\\n         # The entire local cluster's resources is considered launchable, as the\\n\",\"diff --git a/sky/clouds/oci.py b/sky/clouds/oci.py\\nindex 2fe28d21825..34f2560754b 100644\\n--- a/sky/clouds/oci.py\\n+++ b/sky/clouds/oci.py\\n@@ -275,8 +275,8 @@ def make_deploy_resources_variables(\\n             'use_spot': resources.use_spot\\n         }\\n \\n-    def get_feasible_launchable_resources(self,\\n-                                          resources: 'resources_lib.Resources'):\\n+    def _get_feasible_launchable_resources(\\n+            self, resources: 'resources_lib.Resources'):\\n         if resources.instance_type is not None:\\n             assert resources.is_launchable(), resources\\n             resources = resources.copy(accelerators=None)\\n\",\"diff --git a/sky/clouds/scp.py b/sky/clouds/scp.py\\nindex 263b392a454..2a19e33350e 100644\\n--- a/sky/clouds/scp.py\\n+++ b/sky/clouds/scp.py\\n@@ -228,10 +228,14 @@ def _get_default_ami(cls, region_name: str, instance_type: str) -> str:\\n             'No image found in catalog for region '\\n             f'{region_name}. Try setting a valid image_id.')\\n \\n-    def get_feasible_launchable_resources(self,\\n-                                          resources: 'resources_lib.Resources'):\\n+    def _get_feasible_launchable_resources(\\n+            self, resources: 'resources_lib.Resources'):\\n         if resources.use_spot or resources.disk_tier is not None:\\n             return ([], [])\\n+        # Check if the host VM satisfies the min/max disk size limits.\\n+        is_allowed = self._is_disk_size_allowed(resources)\\n+        if not is_allowed:\\n+            return ([], [])\\n         if resources.instance_type is not None:\\n             assert resources.is_launchable(), resources\\n             # Accelerators are part of the instance type in SCP Cloud\\n@@ -326,7 +330,7 @@ def accelerator_in_region_or_zone(self,\\n             accelerator, acc_count, region, zone, 'scp')\\n \\n     @staticmethod\\n-    def is_disk_size_allowed(resources):\\n+    def _is_disk_size_allowed(resources):\\n         if (resources.disk_size and\\n             (resources.disk_size < _SCP_MIN_DISK_SIZE_GB or\\n              resources.disk_size > _SCP_MAX_DISK_SIZE_GB)):\\n@@ -334,8 +338,8 @@ def is_disk_size_allowed(resources):\\n                         f' {_SCP_MIN_DISK_SIZE_GB} GB '\\n                         f'and {_SCP_MAX_DISK_SIZE_GB} GB. '\\n                         f'Input: {resources.disk_size}')\\n-            return False, []\\n-        return True, [resources]\\n+            return False\\n+        return True\\n \\n     @classmethod\\n     def query_status(cls, name: str, tag_filters: Dict[str, str],\\n\",\"diff --git a/sky/clouds/service_catalog/__init__.py b/sky/clouds/service_catalog/__init__.py\\nindex 3116831b8ba..3a1150f4ed6 100644\\n--- a/sky/clouds/service_catalog/__init__.py\\n+++ b/sky/clouds/service_catalog/__init__.py\\n@@ -260,22 +260,6 @@ def get_region_zones_for_accelerators(\\n                                acc_name, acc_count, use_spot)\\n \\n \\n-def check_host_accelerator_compatibility(instance_type: str,\\n-                                         accelerators: Optional[Dict[str, int]],\\n-                                         clouds: CloudFilter = None) -> None:\\n-    \\\"\\\"\\\"GCP only: Check if host VM type is compatible with the accelerators.\\n-\\n-    This function is invoked whenever a Resources object is created.\\n-    This function ensures that TPUs and GPUs (except A100) are attached to N1,\\n-    and A100 GPUs are attached to A2 machines. However, it does NOT check\\n-    the maximum vCPU count and maximum memory limits for the accelerators\\n-    because any Resources like GCP(n1-highmem-64, {'V100': 0.01}) can be valid\\n-    for sky exec/launch on an existing cluster.\\n-    \\\"\\\"\\\"\\n-    _map_clouds_catalog(clouds, 'check_host_accelerator_compatibility',\\n-                        instance_type, accelerators)\\n-\\n-\\n def check_accelerator_attachable_to_host(instance_type: str,\\n                                          accelerators: Optional[Dict[str, int]],\\n                                          zone: Optional[str] = None,\\n\",\"diff --git a/sky/clouds/service_catalog/common.py b/sky/clouds/service_catalog/common.py\\nindex e55f5b33506..1c92c8e85ac 100644\\n--- a/sky/clouds/service_catalog/common.py\\n+++ b/sky/clouds/service_catalog/common.py\\n@@ -189,7 +189,7 @@ def _get_all_supported_regions_str() -> str:\\n \\n     filter_df = df\\n     if region is not None:\\n-        filter_df = filter_df[filter_df['Region'].str.lower() == region.lower()]\\n+        filter_df = _filter_region_zone(filter_df, region, None)\\n         if len(filter_df) == 0:\\n             with ux_utils.print_exception_no_traceback():\\n                 error_msg = (f'Invalid region {region!r}')\\n@@ -335,6 +335,15 @@ def _filter_with_mem(df: pd.DataFrame,\\n         return df[df['MemoryGiB'] == memory]\\n \\n \\n+def _filter_region_zone(df: pd.DataFrame, region: Optional[str],\\n+                        zone: Optional[str]) -> pd.DataFrame:\\n+    if region is not None:\\n+        df = df[df['Region'].str.lower() == region.lower()]\\n+    if zone is not None:\\n+        df = df[df['AvailabilityZone'].str.lower() == zone.lower()]\\n+    return df\\n+\\n+\\n def get_instance_type_for_cpus_mem_impl(\\n         df: pd.DataFrame, cpus: Optional[str],\\n         memory_gb_or_ratio: Optional[str]) -> Optional[str]:\\n@@ -391,10 +400,12 @@ def get_instance_type_for_accelerator_impl(\\n     \\\"\\\"\\\"\\n     result = df[(df['AcceleratorName'].str.fullmatch(acc_name, case=False)) &\\n                 (df['AcceleratorCount'] == acc_count)]\\n+    result = _filter_region_zone(result, region, zone)\\n     if len(result) == 0:\\n         fuzzy_result = df[\\n             (df['AcceleratorName'].str.contains(acc_name, case=False)) &\\n             (df['AcceleratorCount'] >= acc_count)]\\n+        fuzzy_result = _filter_region_zone(fuzzy_result, region, zone)\\n         fuzzy_result = fuzzy_result.sort_values('Price', ascending=True)\\n         fuzzy_result = fuzzy_result[['AcceleratorName',\\n                                      'AcceleratorCount']].drop_duplicates()\\n@@ -407,11 +418,7 @@ def get_instance_type_for_accelerator_impl(\\n \\n     result = _filter_with_cpus(result, cpus)\\n     result = _filter_with_mem(result, memory)\\n-    if region is not None:\\n-        result = result[result['Region'].str.lower() == region]\\n-    if zone is not None:\\n-        # NOTE: For Azure regions, zone must be None.\\n-        result = result[result['AvailabilityZone'] == zone]\\n+    result = _filter_region_zone(result, region, zone)\\n     if len(result) == 0:\\n         return ([], [])\\n \\n@@ -569,8 +576,7 @@ def get_image_id_from_tag_impl(df: pd.DataFrame, tag: str,\\n     an image that matches the tag.\\n     \\\"\\\"\\\"\\n     df = df[df['Tag'] == tag]\\n-    if region is not None:\\n-        df = df[df['Region'].str.lower() == region.lower()]\\n+    df = _filter_region_zone(df, region, None)\\n     assert len(df) <= 1, ('Multiple images found for tag '\\n                           f'{tag} in region {region}')\\n     if len(df) == 0:\\n@@ -585,7 +591,6 @@ def is_image_tag_valid_impl(df: pd.DataFrame, tag: str,\\n                             region: Optional[str]) -> bool:\\n     \\\"\\\"\\\"Returns True if the image tag is valid.\\\"\\\"\\\"\\n     df = df[df['Tag'] == tag]\\n-    if region is not None:\\n-        df = df[df['Region'].str.lower() == region.lower()]\\n+    df = _filter_region_zone(df, region, None)\\n     df = df.dropna(subset=['ImageId'])\\n     return len(df) > 0\\n\",\"diff --git a/sky/clouds/service_catalog/gcp_catalog.py b/sky/clouds/service_catalog/gcp_catalog.py\\nindex 3558e8b7f0a..e3f32a8ceef 100644\\n--- a/sky/clouds/service_catalog/gcp_catalog.py\\n+++ b/sky/clouds/service_catalog/gcp_catalog.py\\n@@ -398,12 +398,17 @@ def get_region_zones_for_accelerators(\\n     return common.get_region_zones(df, use_spot)\\n \\n \\n-def check_host_accelerator_compatibility(\\n-        instance_type: str, accelerators: Optional[Dict[str, int]]) -> None:\\n-    \\\"\\\"\\\"Check if the instance type is compatible with the accelerators.\\n+def check_accelerator_attachable_to_host(instance_type: str,\\n+                                         accelerators: Optional[Dict[str, int]],\\n+                                         zone: Optional[str] = None) -> None:\\n+    \\\"\\\"\\\"Check if the accelerators can be attached to the host.\\n+\\n+    This function checks the max CPU count and memory of the host that\\n+    the accelerators can be attached to.\\n \\n-    This function ensures that TPUs and GPUs except A100 are attached to N1,\\n-    and A100 GPUs are attached to A2 machines.\\n+    Raises:\\n+        exceptions.ResourcesMismatchError: If the accelerators cannot be\\n+            attached to the host.\\n     \\\"\\\"\\\"\\n     if accelerators is None:\\n         if instance_type.startswith('a2-'):\\n@@ -418,12 +423,12 @@ def check_host_accelerator_compatibility(\\n \\n     acc = list(accelerators.items())\\n     assert len(acc) == 1, acc\\n-    acc_name, _ = acc[0]\\n+    acc_name, acc_count = acc[0]\\n \\n     # Check if the accelerator is supported by GCP.\\n     if not list_accelerators(gpus_only=False, name_filter=acc_name):\\n         with ux_utils.print_exception_no_traceback():\\n-            raise exceptions.ResourcesUnavailableError(\\n+            raise exceptions.ResourcesMismatchError(\\n                 f'{acc_name} is not available in GCP. '\\n                 'See \\\\'sky show-gpus --cloud gcp\\\\'')\\n \\n@@ -438,45 +443,22 @@ def check_host_accelerator_compatibility(\\n \\n     # Treat A100 as a special case.\\n     if acc_name in _A100_INSTANCE_TYPE_DICTS:\\n-        # A100 must be attached to A2 instance type.\\n-        if not instance_type.startswith('a2-'):\\n+        a100_instance_type = _A100_INSTANCE_TYPE_DICTS[acc_name][acc_count]\\n+        if instance_type != a100_instance_type:\\n             with ux_utils.print_exception_no_traceback():\\n                 raise exceptions.ResourcesMismatchError(\\n-                    f'A100 GPUs cannot be attached to {instance_type}. '\\n-                    f'Use A2 machines instead. Please refer to '\\n+                    f'A100:{acc_count} cannot be attached to {instance_type}. '\\n+                    f'Use {a100_instance_type} instead. Please refer to '\\n                     'https://cloud.google.com/compute/docs/gpus#a100-gpus')\\n-        return\\n-\\n-    # Other GPUs must be attached to N1 machines.\\n-    # Refer to: https://cloud.google.com/compute/docs/machine-types#gpus\\n-    if not instance_type.startswith('n1-'):\\n+    elif not instance_type.startswith('n1-'):\\n+        # Other GPUs must be attached to N1 machines.\\n+        # Refer to: https://cloud.google.com/compute/docs/machine-types#gpus\\n         with ux_utils.print_exception_no_traceback():\\n             raise exceptions.ResourcesMismatchError(\\n                 f'{acc_name} GPUs cannot be attached to {instance_type}. '\\n                 'Use N1 instance types instead. Please refer to: '\\n                 'https://cloud.google.com/compute/docs/machine-types#gpus')\\n \\n-\\n-def check_accelerator_attachable_to_host(instance_type: str,\\n-                                         accelerators: Optional[Dict[str, int]],\\n-                                         zone: Optional[str] = None) -> None:\\n-    \\\"\\\"\\\"Check if the accelerators can be attached to the host.\\n-\\n-    This function checks the max CPU count and memory of the host that\\n-    the accelerators can be attached to.\\n-    \\\"\\\"\\\"\\n-    if accelerators is None:\\n-        return\\n-\\n-    acc = list(accelerators.items())\\n-    assert len(acc) == 1, acc\\n-    acc_name, acc_count = acc[0]\\n-\\n-    if acc_name.startswith('tpu-'):\\n-        # TODO(woosuk): Check max vCPUs and memory for each TPU type.\\n-        assert instance_type == 'TPU-VM' or instance_type.startswith('n1-')\\n-        return\\n-\\n     if acc_name in _A100_INSTANCE_TYPE_DICTS:\\n         valid_counts = list(_A100_INSTANCE_TYPE_DICTS[acc_name].keys())\\n     else:\\n@@ -488,25 +470,20 @@ def check_accelerator_attachable_to_host(instance_type: str,\\n                 f'{acc_name}:{acc_count} is not launchable on GCP. '\\n                 f'The valid {acc_name} counts are {valid_counts}.')\\n \\n-    if acc_name in _A100_INSTANCE_TYPE_DICTS:\\n-        a100_instance_type = _A100_INSTANCE_TYPE_DICTS[acc_name][acc_count]\\n-        if instance_type != a100_instance_type:\\n-            with ux_utils.print_exception_no_traceback():\\n-                raise exceptions.ResourcesMismatchError(\\n-                    f'A100:{acc_count} cannot be attached to {instance_type}. '\\n-                    f'Use {a100_instance_type} instead. Please refer to '\\n-                    'https://cloud.google.com/compute/docs/gpus#a100-gpus')\\n-        return\\n-\\n     # Check maximum vCPUs and memory.\\n-    max_cpus, max_memory = _NUM_ACC_TO_MAX_CPU_AND_MEMORY[acc_name][acc_count]\\n-    if acc_name == 'K80' and acc_count == 8:\\n-        if zone in ['asia-east1-a', 'us-east1-d']:\\n-            max_memory = 416\\n-    elif acc_name == 'P100' and acc_count == 4:\\n-        if zone in ['us-east1-c', 'europe-west1-d', 'europe-west1-b']:\\n-            max_cpus = 64\\n-            max_memory = 208\\n+    if acc_name in _A100_INSTANCE_TYPE_DICTS:\\n+        max_cpus, max_memory = get_vcpus_mem_from_instance_type(\\n+            a100_instance_type)\\n+    else:\\n+        max_cpus, max_memory = _NUM_ACC_TO_MAX_CPU_AND_MEMORY[acc_name][\\n+            acc_count]\\n+        if acc_name == 'K80' and acc_count == 8:\\n+            if zone in ['asia-east1-a', 'us-east1-d']:\\n+                max_memory = 416\\n+        elif acc_name == 'P100' and acc_count == 4:\\n+            if zone in ['us-east1-c', 'europe-west1-d', 'europe-west1-b']:\\n+                max_cpus = 64\\n+                max_memory = 208\\n \\n     # vCPU counts and memory sizes of N1 machines.\\n     df = _df[_df['InstanceType'] == instance_type]\\n\",\"diff --git a/sky/optimizer.py b/sky/optimizer.py\\nindex 33b570121b2..185708ac71a 100644\\n--- a/sky/optimizer.py\\n+++ b/sky/optimizer.py\\n@@ -273,7 +273,7 @@ def _estimate_nodes_cost_or_time(\\n                     error_msg = (\\n                         'No launchable resource found for task '\\n                         f'{node}.{location_hint}\\\\nThis means the '\\n-                        'catalog does not contain any instance types that '\\n+                        'catalog does not contain any resources that '\\n                         'satisfy this request.\\\\n'\\n                         'To fix: relax or change the resource requirements.\\\\n'\\n                         'Hint: \\\\'sky show-gpus --all\\\\' '\\n@@ -954,30 +954,6 @@ def _fill_in_launchable_resources(\\n                     f'{colorama.Style.BRIGHT}'\\n                     f'sky check {colorama.Style.RESET_ALL}, or change the '\\n                     'cloud requirement')\\n-        elif resources.is_launchable():\\n-            if isinstance(resources.cloud, clouds.GCP):\\n-                # Check if the host VM satisfies the max vCPU and memory limits.\\n-                clouds.GCP.check_accelerator_attachable_to_host(\\n-                    resources.instance_type, resources.accelerators,\\n-                    resources.zone)\\n-            # If the user has specified a GCP zone and the zone does not support\\n-            # the host-accelerator combination, then an error will be raised by\\n-            # the above check_accelerator_attachable_to_host() call.\\n-            # If the user has not specified any zone, a launchable will be made\\n-            # for every zone even if some of the zones do not support the\\n-            # host-accelerator combination. Then the provisioner may try to\\n-            # launch the instance, and fail over to other zones. We find this\\n-            # behavior acceptable because this will happen only when the user\\n-            # requested GCP 4:P100 or 8:K80 with a very large host VM.\\n-            elif isinstance(resources.cloud, clouds.SCP):\\n-                # Check if the host VM satisfies the min/max disk size limits.\\n-                is_allowed, launchable[resources] = \\\\\\n-                    clouds.SCP.is_disk_size_allowed(resources)\\n-                if not is_allowed:\\n-                    continue\\n-\\n-            launchable[resources] = _make_launchables_for_valid_region_zones(\\n-                resources)\\n         else:\\n             clouds_list = ([resources.cloud]\\n                            if resources.cloud is not None else enabled_clouds)\\n\",\"diff --git a/sky/resources.py b/sky/resources.py\\nindex 662a9923e78..3824c2e250f 100644\\n--- a/sky/resources.py\\n+++ b/sky/resources.py\\n@@ -162,7 +162,6 @@ def __init__(\\n         self._try_validate_local()\\n         self._try_validate_instance_type()\\n         self._try_validate_cpus_mem()\\n-        self._try_validate_accelerators()\\n         self._try_validate_spot()\\n         self._try_validate_image_id()\\n         self._try_validate_disk_tier()\\n@@ -505,7 +504,8 @@ def get_valid_regions_for_launchable(self) -> List[clouds.Region]:\\n         may have restricted the regions to be considered (e.g., a\\n         ssh_proxy_command dict with region names as keys).\\n         \\\"\\\"\\\"\\n-        assert self.is_launchable()\\n+        assert self.is_launchable(), self\\n+\\n         regions = self._cloud.regions_with_offering(self._instance_type,\\n                                                     self.accelerators,\\n                                                     self._use_spot,\\n@@ -624,56 +624,6 @@ def _try_validate_cpus_mem(self) -> None:\\n                             f'memory. {self.instance_type} has {mem} GB '\\n                             f'memory, but {self.memory} is requested.')\\n \\n-    def _try_validate_accelerators(self) -> None:\\n-        \\\"\\\"\\\"Validate accelerators against the instance type and region/zone.\\\"\\\"\\\"\\n-        acc_requested = self.accelerators\\n-        if (isinstance(self.cloud, clouds.GCP) and\\n-                self.instance_type is not None):\\n-            # Do this check even if acc_requested is None.\\n-            clouds.GCP.check_host_accelerator_compatibility(\\n-                self.instance_type, acc_requested)\\n-\\n-        if acc_requested is None:\\n-            return\\n-\\n-        if self.is_launchable() and not isinstance(self.cloud, clouds.GCP):\\n-            # GCP attaches accelerators to VMs, so no need for this check.\\n-            acc_requested = self.accelerators\\n-            acc_from_instance_type = (\\n-                self.cloud.get_accelerators_from_instance_type(\\n-                    self._instance_type))\\n-            if not Resources(accelerators=acc_requested).less_demanding_than(\\n-                    Resources(accelerators=acc_from_instance_type)):\\n-                with ux_utils.print_exception_no_traceback():\\n-                    raise ValueError(\\n-                        'Infeasible resource demands found:\\\\n'\\n-                        f'  Instance type requested: {self._instance_type}\\\\n'\\n-                        f'  Accelerators for {self._instance_type}: '\\n-                        f'{acc_from_instance_type}\\\\n'\\n-                        f'  Accelerators requested: {acc_requested}\\\\n'\\n-                        f'To fix: either only specify instance_type, or change '\\n-                        'the accelerators field to be consistent.')\\n-            # NOTE: should not clear 'self.accelerators' even for AWS/Azure,\\n-            # because e.g., the instance may have 4 GPUs, while the task\\n-            # specifies to use 1 GPU.\\n-\\n-        # Validate whether accelerator is available in specified region/zone.\\n-        acc, acc_count = list(acc_requested.items())[0]\\n-        # Fractional accelerators are temporarily bumped up to 1.\\n-        if 0 < acc_count < 1:\\n-            acc_count = 1\\n-        if self.region is not None or self.zone is not None:\\n-            if not self._cloud.accelerator_in_region_or_zone(\\n-                    acc, acc_count, self.region, self.zone):\\n-                error_str = (f'Accelerator \\\"{acc}\\\" is not available in '\\n-                             '\\\"{}\\\".')\\n-                if self.zone:\\n-                    error_str = error_str.format(self.zone)\\n-                else:\\n-                    error_str = error_str.format(self.region)\\n-                with ux_utils.print_exception_no_traceback():\\n-                    raise ValueError(error_str)\\n-\\n     def _try_validate_spot(self) -> None:\\n         if self._spot_recovery is None:\\n             return\\n\",\"diff --git a/sky/spot/recovery_strategy.py b/sky/spot/recovery_strategy.py\\nindex c2b1caa31ba..7cd3958a3e3 100644\\n--- a/sky/spot/recovery_strategy.py\\n+++ b/sky/spot/recovery_strategy.py\\n@@ -285,7 +285,8 @@ def _launch(self,\\n                            _is_launched_by_spot_controller=True)\\n                 logger.info('Spot cluster launched.')\\n             except (exceptions.InvalidClusterNameError,\\n-                    exceptions.NoCloudAccessError) as e:\\n+                    exceptions.NoCloudAccessError,\\n+                    exceptions.ResourcesMismatchError) as e:\\n                 logger.error('Failure happened before provisioning. '\\n                              f'{common_utils.format_exception(e)}')\\n                 if raise_on_failure:\\n\",\"diff --git a/sky/backends/backend.py b/sky/backends/backend.py\\nindex dc9f5f1e025..1dbc4ad00f3 100644\\n--- a/sky/backends/backend.py\\n+++ b/sky/backends/backend.py\\n@@ -82,12 +82,15 @@ def add_storage_objects(self, task: 'task_lib.Task') -> None:\\n \\n     @timeline.event\\n     @usage_lib.messages.usage.update_runtime('execute')\\n-    def execute(self, handle: _ResourceHandleType, task: 'task_lib.Task',\\n-                detach_run: bool) -> None:\\n+    def execute(self,\\n+                handle: _ResourceHandleType,\\n+                task: 'task_lib.Task',\\n+                detach_run: bool,\\n+                dryrun: bool = False) -> None:\\n         usage_lib.record_cluster_name_for_current_operation(\\n             handle.get_cluster_name())\\n         usage_lib.messages.usage.update_actual_task(task)\\n-        return self._execute(handle, task, detach_run)\\n+        return self._execute(handle, task, detach_run, dryrun)\\n \\n     @timeline.event\\n     def post_execute(self, handle: _ResourceHandleType, down: bool) -> None:\\n@@ -136,8 +139,11 @@ def _setup(self, handle: _ResourceHandleType, task: 'task_lib.Task',\\n                detach_setup: bool) -> None:\\n         raise NotImplementedError\\n \\n-    def _execute(self, handle: _ResourceHandleType, task: 'task_lib.Task',\\n-                 detach_run: bool) -> None:\\n+    def _execute(self,\\n+                 handle: _ResourceHandleType,\\n+                 task: 'task_lib.Task',\\n+                 detach_run: bool,\\n+                 dryrun: bool = False) -> None:\\n         raise NotImplementedError\\n \\n     def _post_execute(self, handle: _ResourceHandleType, down: bool) -> None:\\n\",\"diff --git a/sky/backends/backend_utils.py b/sky/backends/backend_utils.py\\nindex 40c254b1e46..144cffac579 100644\\n--- a/sky/backends/backend_utils.py\\n+++ b/sky/backends/backend_utils.py\\n@@ -2132,6 +2132,7 @@ def check_cluster_available(\\n     *,\\n     operation: str,\\n     check_cloud_vm_ray_backend: Literal[True] = True,\\n+    dryrun: bool = ...,\\n ) -> 'cloud_vm_ray_backend.CloudVmRayResourceHandle':\\n     ...\\n \\n@@ -2142,6 +2143,7 @@ def check_cluster_available(\\n     *,\\n     operation: str,\\n     check_cloud_vm_ray_backend: Literal[False],\\n+    dryrun: bool = ...,\\n ) -> backends.ResourceHandle:\\n     ...\\n \\n@@ -2151,6 +2153,7 @@ def check_cluster_available(\\n     *,\\n     operation: str,\\n     check_cloud_vm_ray_backend: bool = True,\\n+    dryrun: bool = False,\\n ) -> backends.ResourceHandle:\\n     \\\"\\\"\\\"Check if the cluster is available.\\n \\n@@ -2164,6 +2167,10 @@ def check_cluster_available(\\n         exceptions.CloudUserIdentityError: if we fail to get the current user\\n           identity.\\n     \\\"\\\"\\\"\\n+    if dryrun:\\n+        record = global_user_state.get_cluster_from_name(cluster_name)\\n+        assert record is not None, cluster_name\\n+        return record['handle']\\n     try:\\n         cluster_status, handle = refresh_cluster_status_handle(cluster_name)\\n     except exceptions.ClusterStatusFetchingError as e:\\n\",\"diff --git a/sky/backends/cloud_vm_ray_backend.py b/sky/backends/cloud_vm_ray_backend.py\\nindex 7d1d2694f0b..344e2a66680 100644\\n--- a/sky/backends/cloud_vm_ray_backend.py\\n+++ b/sky/backends/cloud_vm_ray_backend.py\\n@@ -1438,7 +1438,7 @@ def _retry_zones(\\n                     f'Failed to find catalog in region {region.name}: {e}')\\n                 continue\\n             if dryrun:\\n-                return\\n+                return config_dict\\n             cluster_config_file = config_dict['ray']\\n \\n             # Record early, so if anything goes wrong, 'sky status' will show\\n@@ -2412,10 +2412,9 @@ def _provision(\\n                 to_provision,\\n                 task.num_nodes,\\n                 prev_cluster_status=None)\\n-            if not dryrun:  # dry run doesn't need to check existing cluster.\\n-                # Try to launch the exiting cluster first\\n-                to_provision_config = self._check_existing_cluster(\\n-                    task, to_provision, cluster_name)\\n+            # Try to launch the exiting cluster first\\n+            to_provision_config = self._check_existing_cluster(\\n+                task, to_provision, cluster_name, dryrun)\\n             assert to_provision_config.resources is not None, (\\n                 'to_provision should not be None', to_provision_config)\\n \\n@@ -2493,7 +2492,8 @@ def _provision(\\n                             error_message,\\n                             failover_history=e.failover_history) from None\\n             if dryrun:\\n-                return None\\n+                record = global_user_state.get_cluster_from_name(cluster_name)\\n+                return record['handle'] if record is not None else None\\n             cluster_config_file = config_dict['ray']\\n \\n             handle = CloudVmRayResourceHandle(\\n@@ -3006,6 +3006,7 @@ def _execute(\\n         handle: CloudVmRayResourceHandle,\\n         task: task_lib.Task,\\n         detach_run: bool,\\n+        dryrun: bool = False,\\n     ) -> None:\\n         if task.run is None:\\n             logger.info('Run commands not specified or empty.')\\n@@ -3015,6 +3016,11 @@ def _execute(\\n         self.check_resources_fit_cluster(handle, task)\\n \\n         resources_str = backend_utils.get_task_resources_str(task)\\n+\\n+        if dryrun:\\n+            logger.info(f'Dryrun complete. Would have run:\\\\n{task}')\\n+            return\\n+\\n         job_id = self._add_job(handle, task.name, resources_str)\\n \\n         is_tpu_vm_pod = tpu_utils.is_tpu_vm_pod(handle.launched_resources)\\n@@ -3752,9 +3758,11 @@ def run_on_head(\\n \\n     @timeline.event\\n     def _check_existing_cluster(\\n-            self, task: task_lib.Task,\\n+            self,\\n+            task: task_lib.Task,\\n             to_provision: Optional[resources_lib.Resources],\\n-            cluster_name: str) -> RetryingVmProvisioner.ToProvisionConfig:\\n+            cluster_name: str,\\n+            dryrun: bool = False) -> RetryingVmProvisioner.ToProvisionConfig:\\n         \\\"\\\"\\\"Checks if the cluster exists and returns the provision config.\\n \\n         Raises:\\n@@ -3767,25 +3775,30 @@ def _check_existing_cluster(\\n         handle_before_refresh = None if record is None else record['handle']\\n         status_before_refresh = None if record is None else record['status']\\n \\n-        prev_cluster_status, handle = (\\n-            backend_utils.refresh_cluster_status_handle(\\n-                cluster_name,\\n-                # We force refresh for the init status to determine the actual\\n-                # state of a previous cluster in INIT state.\\n-                #\\n-                # This is important for the case, where an existing cluster is\\n-                # transitioned into INIT state due to key interruption during\\n-                # launching, with the following steps:\\n-                # (1) launch, after answering prompt immediately ctrl-c;\\n-                # (2) launch again.\\n-                # If we don't refresh the state of the cluster and reset it back\\n-                # to STOPPED, our failover logic will consider it as an abnormal\\n-                # cluster after hitting resources capacity limit on the cloud,\\n-                # and will start failover. This is not desired, because the user\\n-                # may want to keep the data on the disk of that cluster.\\n-                force_refresh_statuses={status_lib.ClusterStatus.INIT},\\n-                acquire_per_cluster_status_lock=False,\\n-            ))\\n+        prev_cluster_status, handle = (status_before_refresh,\\n+                                       handle_before_refresh)\\n+\\n+        if not dryrun:\\n+            prev_cluster_status, handle = (\\n+                backend_utils.refresh_cluster_status_handle(\\n+                    cluster_name,\\n+                    # We force refresh for the init status to determine the\\n+                    # actual state of a previous cluster in INIT state.\\n+                    #\\n+                    # This is important for the case, where an existing cluster\\n+                    # is transitioned into INIT state due to key interruption\\n+                    # during launching, with the following steps:\\n+                    # (1) launch, after answering prompt immediately ctrl-c;\\n+                    # (2) launch again.\\n+                    # If we don't refresh the state of the cluster and reset it\\n+                    # back to STOPPED, our failover logic will consider it as an\\n+                    # abnormal cluster after hitting resources capacity limit on\\n+                    # the cloud, and will start failover. This is not desired,\\n+                    # because the user may want to keep the data on the disk of\\n+                    # that cluster.\\n+                    force_refresh_statuses={status_lib.ClusterStatus.INIT},\\n+                    acquire_per_cluster_status_lock=False,\\n+                ))\\n         if prev_cluster_status is not None:\\n             assert handle is not None\\n             # Cluster already exists.\\n\",\"diff --git a/sky/backends/local_docker_backend.py b/sky/backends/local_docker_backend.py\\nindex 1293e538a47..9b2f2651705 100644\\n--- a/sky/backends/local_docker_backend.py\\n+++ b/sky/backends/local_docker_backend.py\\n@@ -265,8 +265,11 @@ def _setup(self, handle: LocalDockerResourceHandle, task: 'task_lib.Task',\\n             requested_resources=task.resources,\\n             ready=True)\\n \\n-    def _execute(self, handle: LocalDockerResourceHandle, task: 'task_lib.Task',\\n-                 detach_run: bool) -> None:\\n+    def _execute(self,\\n+                 handle: LocalDockerResourceHandle,\\n+                 task: 'task_lib.Task',\\n+                 detach_run: bool,\\n+                 dryrun: bool = False) -> None:\\n         \\\"\\\"\\\" Launches the container.\\\"\\\"\\\"\\n \\n         if detach_run:\\n@@ -283,6 +286,10 @@ def _execute(self, handle: LocalDockerResourceHandle, task: 'task_lib.Task',\\n             logger.info(f'Nothing to run; run command not specified:\\\\n{task}')\\n             return\\n \\n+        if dryrun:\\n+            logger.info(f'Dryrun complete. Would have run:\\\\n{task}')\\n+            return\\n+\\n         self._execute_task_one_node(handle, task)\\n \\n     def _post_execute(self, handle: LocalDockerResourceHandle,\\n\",\"diff --git a/sky/clouds/cloud.py b/sky/clouds/cloud.py\\nindex e5109db69b3..0f54cbd7747 100644\\n--- a/sky/clouds/cloud.py\\n+++ b/sky/clouds/cloud.py\\n@@ -562,6 +562,7 @@ def check_quota_available(cls,\\n         Returns:\\n             False if the quota is found to be zero, and true otherwise.\\n         \\\"\\\"\\\"\\n+        del region, instance_type, use_spot  # unused\\n \\n         return True\\n \\n\",\"diff --git a/sky/execution.py b/sky/execution.py\\nindex 810a4980a20..4abaf886ac6 100644\\n--- a/sky/execution.py\\n+++ b/sky/execution.py\\n@@ -328,24 +328,24 @@ def _execute(\\n                                            cluster_name=cluster_name,\\n                                            retry_until_up=retry_until_up)\\n \\n-        if dryrun:\\n-            logger.info('Dry run finished.')\\n+        if dryrun and handle is None:\\n+            logger.info('Dryrun finished.')\\n             return\\n \\n-        if Stage.SYNC_WORKDIR in stages:\\n+        if Stage.SYNC_WORKDIR in stages and not dryrun:\\n             if task.workdir is not None:\\n                 backend.sync_workdir(handle, task.workdir)\\n \\n-        if Stage.SYNC_FILE_MOUNTS in stages:\\n+        if Stage.SYNC_FILE_MOUNTS in stages and not dryrun:\\n             backend.sync_file_mounts(handle, task.file_mounts,\\n                                      task.storage_mounts)\\n \\n         if no_setup:\\n             logger.info('Setup commands skipped.')\\n-        elif Stage.SETUP in stages:\\n+        elif Stage.SETUP in stages and not dryrun:\\n             backend.setup(handle, task, detach_setup=detach_setup)\\n \\n-        if Stage.PRE_EXEC in stages:\\n+        if Stage.PRE_EXEC in stages and not dryrun:\\n             if idle_minutes_to_autostop is not None:\\n                 assert isinstance(backend, backends.CloudVmRayBackend)\\n                 backend.set_autostop(handle,\\n@@ -355,12 +355,12 @@ def _execute(\\n         if Stage.EXEC in stages:\\n             try:\\n                 global_user_state.update_last_use(handle.get_cluster_name())\\n-                backend.execute(handle, task, detach_run)\\n+                backend.execute(handle, task, detach_run, dryrun=dryrun)\\n             finally:\\n                 # Enables post_execute() to be run after KeyboardInterrupt.\\n                 backend.post_execute(handle, down)\\n \\n-        if Stage.DOWN in stages:\\n+        if Stage.DOWN in stages and not dryrun:\\n             if down and idle_minutes_to_autostop is None:\\n                 backend.teardown_ephemeral_storage(task)\\n                 backend.teardown(handle, terminate=True)\\n@@ -570,7 +570,8 @@ def exec(  # pylint: disable=redefined-builtin\\n     handle = backend_utils.check_cluster_available(\\n         cluster_name,\\n         operation='executing tasks',\\n-        check_cloud_vm_ray_backend=False)\\n+        check_cloud_vm_ray_backend=False,\\n+        dryrun=dryrun)\\n     _execute(entrypoint=entrypoint,\\n              dryrun=dryrun,\\n              down=down,\\n\",\"diff --git a/sky/clouds/cloud.py b/sky/clouds/cloud.py\\nindex 83abb877b17..b963bd8240d 100644\\n--- a/sky/clouds/cloud.py\\n+++ b/sky/clouds/cloud.py\\n@@ -494,7 +494,15 @@ def _check_instance_type_accelerators_combination(\\n         \\\"\\\"\\\"\\n         assert resources.is_launchable(), resources\\n \\n-        def _equal_accelerators(acc_requested, acc_from_instance_type):\\n+        def _equal_accelerators(\\n+                acc_requested: Optional[Dict[str, int]],\\n+                acc_from_instance_type: Optional[Dict[str, int]]) -> bool:\\n+            \\\"\\\"\\\"Check the requested accelerators equals to the instance type\\n+\\n+            Check the requested accelerators equals to the accelerators\\n+            from the instance type (both the accelerator type and the\\n+            count).\\n+            \\\"\\\"\\\"\\n             if acc_requested is None:\\n                 return acc_from_instance_type is None\\n             if acc_from_instance_type is None:\\n\",\"diff --git a/sky/clouds/service_catalog/common.py b/sky/clouds/service_catalog/common.py\\nindex 1c92c8e85ac..040a640a2c5 100644\\n--- a/sky/clouds/service_catalog/common.py\\n+++ b/sky/clouds/service_catalog/common.py\\n@@ -189,7 +189,7 @@ def _get_all_supported_regions_str() -> str:\\n \\n     filter_df = df\\n     if region is not None:\\n-        filter_df = _filter_region_zone(filter_df, region, None)\\n+        filter_df = _filter_region_zone(filter_df, region, zone=None)\\n         if len(filter_df) == 0:\\n             with ux_utils.print_exception_no_traceback():\\n                 error_msg = (f'Invalid region {region!r}')\\n@@ -576,7 +576,7 @@ def get_image_id_from_tag_impl(df: pd.DataFrame, tag: str,\\n     an image that matches the tag.\\n     \\\"\\\"\\\"\\n     df = df[df['Tag'] == tag]\\n-    df = _filter_region_zone(df, region, None)\\n+    df = _filter_region_zone(df, region, zone=None)\\n     assert len(df) <= 1, ('Multiple images found for tag '\\n                           f'{tag} in region {region}')\\n     if len(df) == 0:\\n@@ -591,6 +591,6 @@ def is_image_tag_valid_impl(df: pd.DataFrame, tag: str,\\n                             region: Optional[str]) -> bool:\\n     \\\"\\\"\\\"Returns True if the image tag is valid.\\\"\\\"\\\"\\n     df = df[df['Tag'] == tag]\\n-    df = _filter_region_zone(df, region, None)\\n+    df = _filter_region_zone(df, region, zone=None)\\n     df = df.dropna(subset=['ImageId'])\\n     return len(df) > 0\\n\"]", "test_patch": "[\"diff --git a/tests/test_cli.py b/tests/test_cli.py\\nindex 4a7dcba7a27..602a5575385 100644\\n--- a/tests/test_cli.py\\n+++ b/tests/test_cli.py\\n@@ -4,6 +4,8 @@\\n from click import testing as cli_testing\\n \\n import sky\\n+from sky import exceptions\\n+from sky import clouds\\n import sky.cli as cli\\n \\n CLOUDS_TO_TEST = ['aws', 'gcp', 'ibm', 'azure', 'lambda', 'scp', 'oci']\\n@@ -54,7 +56,7 @@ def test_accelerator_mismatch(enable_all_clouds):\\n     def _capture_mismatch_gpus_spec(file_path, gpus: str):\\n         result = cli_runner.invoke(cli.launch,\\n                                    [file_path, '--gpus', gpus, '--dryrun'])\\n-        assert isinstance(result.exception, ValueError)\\n+        assert isinstance(result.exception, exceptions.ResourcesMismatchError)\\n         assert 'Infeasible resource demands found:' in str(result.exception)\\n \\n     def _capture_match_gpus_spec(file_path, gpus: str):\\n@@ -70,11 +72,13 @@ def _capture_match_gpus_spec(file_path, gpus: str):\\n         _capture_mismatch_gpus_spec(f.name, 'T4:0.5')\\n         _capture_mismatch_gpus_spec(f.name, 'V100:2')\\n         _capture_mismatch_gpus_spec(f.name, 'v100:2')\\n+        _capture_mismatch_gpus_spec(f.name, 'V100:0.5')\\n \\n         _capture_match_gpus_spec(f.name, 'V100:1')\\n         _capture_match_gpus_spec(f.name, 'v100:1')\\n         _capture_match_gpus_spec(f.name, 'V100:0.5')\\n         _capture_match_gpus_spec(f.name, 'V100')\\n+        _capture_match_gpus_spec(f.name, 'V100:0.5')\\n \\n \\n def test_show_gpus():\\n\",\"diff --git a/tests/test_optimizer_dryruns.py b/tests/test_optimizer_dryruns.py\\nindex dc7b11768c6..7deb0718961 100644\\n--- a/tests/test_optimizer_dryruns.py\\n+++ b/tests/test_optimizer_dryruns.py\\n@@ -329,13 +329,34 @@ def test_instance_type_mistmatches_accelerators(monkeypatch):\\n         ('m4.2xlarge', 'V100'),\\n     ]\\n     for instance, acc in bad_instance_and_accs:\\n-        with pytest.raises(ValueError) as e:\\n+        with pytest.raises(exceptions.ResourcesMismatchError) as e:\\n             _test_resources_launch(monkeypatch,\\n                                    sky.AWS(),\\n                                    instance_type=instance,\\n                                    accelerators=acc)\\n         assert 'Infeasible resource demands found' in str(e.value)\\n \\n+    with pytest.raises(exceptions.ResourcesMismatchError) as e:\\n+        _test_resources_launch(monkeypatch,\\n+                               sky.GCP(),\\n+                               instance_type='n2-standard-8',\\n+                               accelerators={'V100': 1})\\n+        assert 'can only be attached to N1 VMs,' in str(e.value), str(e.value)\\n+\\n+    with pytest.raises(exceptions.ResourcesMismatchError) as e:\\n+        _test_resources_launch(monkeypatch,\\n+                               sky.GCP(),\\n+                               instance_type='a2-highgpu-1g',\\n+                               accelerators={'A100': 2})\\n+        assert 'cannot be attached to' in str(e.value), str(e.value)\\n+\\n+    with pytest.raises(exceptions.ResourcesMismatchError) as e:\\n+        _test_resources_launch(monkeypatch,\\n+                               sky.AWS(),\\n+                               instance_type='p3.16xlarge',\\n+                               accelerators={'V100': 1})\\n+        assert 'Infeasible resource demands found' in str(e.value)\\n+\\n \\n def test_instance_type_matches_accelerators(monkeypatch):\\n     _test_resources_launch(monkeypatch,\\n@@ -350,7 +371,7 @@ def test_instance_type_matches_accelerators(monkeypatch):\\n     _test_resources_launch(monkeypatch,\\n                            sky.AWS(),\\n                            instance_type='p3.16xlarge',\\n-                           accelerators={'V100': 1})\\n+                           accelerators={'V100': 8})\\n \\n \\n def test_invalid_instance_type(monkeypatch):\\n@@ -402,6 +423,13 @@ def test_invalid_region(monkeypatch):\\n             _test_resources(monkeypatch, cloud, region='invalid')\\n         assert 'Invalid region' in str(e.value)\\n \\n+    with pytest.raises(exceptions.ResourcesUnavailableError) as e:\\n+        _test_resources_launch(monkeypatch,\\n+                               sky.GCP(),\\n+                               region='us-west1',\\n+                               accelerators='tpu-v3-8')\\n+        assert 'No launchable resource found' in str(e.value)\\n+\\n \\n def test_invalid_zone(monkeypatch):\\n     for cloud in [sky.AWS(), sky.GCP()]:\\n\",\"diff --git a/.github/workflows/pytest.yml b/.github/workflows/pytest.yml\\nindex 2b36d95dde9..81a43cb49bb 100644\\n--- a/.github/workflows/pytest.yml\\n+++ b/.github/workflows/pytest.yml\\n@@ -19,6 +19,7 @@ jobs:\\n           - tests/test_cli.py\\n           - tests/test_config.py\\n           - tests/test_global_user_state.py\\n+          - tests/test_jobs.py\\n           - tests/test_list_accelerators.py\\n           - tests/test_optimizer_dryruns.py\\n           - tests/test_optimizer_random_dag.py\\n\",\"diff --git a/sky/clouds/service_catalog/aws_catalog.py b/sky/clouds/service_catalog/aws_catalog.py\\nindex ef6102d5cbb..fb0b39c3bea 100644\\n--- a/sky/clouds/service_catalog/aws_catalog.py\\n+++ b/sky/clouds/service_catalog/aws_catalog.py\\n@@ -68,6 +68,24 @@\\n                                  pull_frequency_hours=_PULL_FREQUENCY_HOURS)\\n \\n \\n+def _get_az_mappings(aws_user_hash: str) -> Optional[pd.DataFrame]:\\n+    az_mapping_path = common.get_catalog_path(\\n+        f'aws/az_mappings-{aws_user_hash}.csv')\\n+    if not os.path.exists(az_mapping_path):\\n+        az_mappings = None\\n+        if aws_user_hash != 'default':\\n+            # Fetch az mapping from AWS.\\n+            logger.info(f'{colorama.Style.DIM}Fetching availability zones '\\n+                        f'mapping for AWS...{colorama.Style.RESET_ALL}')\\n+            az_mappings = fetch_aws.fetch_availability_zone_mappings()\\n+        else:\\n+            return None\\n+        az_mappings.to_csv(az_mapping_path, index=False)\\n+    else:\\n+        az_mappings = pd.read_csv(az_mapping_path)\\n+    return az_mappings\\n+\\n+\\n def _fetch_and_apply_az_mapping(df: pd.DataFrame) -> pd.DataFrame:\\n     \\\"\\\"\\\"Maps zone IDs (use1-az1) to zone names (us-east-1x).\\n \\n@@ -114,23 +132,12 @@ def _fetch_and_apply_az_mapping(df: pd.DataFrame) -> pd.DataFrame:\\n             'Failed to get AWS user identity. Using the latest mapping '\\n             f'file for user {aws_user_hash!r}.')\\n \\n-    az_mapping_path = common.get_catalog_path(\\n-        f'aws/az_mappings-{aws_user_hash}.csv')\\n-    if not os.path.exists(az_mapping_path):\\n-        az_mappings = None\\n-        if aws_user_hash != 'default':\\n-            # Fetch az mapping from AWS.\\n-            logger.info(f'{colorama.Style.DIM}Fetching availability zones '\\n-                        f'mapping for AWS...{colorama.Style.RESET_ALL}')\\n-            az_mappings = fetch_aws.fetch_availability_zone_mappings()\\n-        else:\\n-            # Returning the original dataframe directly, as no cloud\\n-            # identity can be fetched which suggests there are no\\n-            # credentials.\\n-            return df\\n-        az_mappings.to_csv(az_mapping_path, index=False)\\n-    else:\\n-        az_mappings = pd.read_csv(az_mapping_path)\\n+    az_mappings = _get_az_mappings(aws_user_hash)\\n+    if az_mappings is None:\\n+        # Returning the original dataframe directly, as no cloud\\n+        # identity can be fetched which suggests there are no\\n+        # credentials.\\n+        return df\\n     # Use inner join to drop rows with unknown AZ IDs, which are likely\\n     # because the user does not have access to that Region. Otherwise,\\n     # there will be rows with NaN in the AvailabilityZone column.\\n\",\"diff --git a/tests/conftest.py b/tests/conftest.py\\nindex fe26cfc7be0..7976bf10132 100644\\n--- a/tests/conftest.py\\n+++ b/tests/conftest.py\\n@@ -2,6 +2,8 @@\\n import tempfile\\n from typing import List\\n \\n+import pandas as pd\\n+\\n # Usage: use\\n #   @pytest.mark.slow\\n # to mark a test as slow and to skip by default.\\n@@ -194,6 +196,18 @@ def enable_all_clouds(monkeypatch):\\n         config_file_backup.name)\\n     monkeypatch.setenv('OCI_CONFIG', config_file_backup.name)\\n \\n+    az_mappings = pd.read_csv('tests/default_aws_az_mappings.csv')\\n+\\n+    def _get_az_mappings(_):\\n+        return az_mappings\\n+\\n+    monkeypatch.setattr(\\n+        'sky.clouds.service_catalog.aws_catalog._get_az_mappings',\\n+        _get_az_mappings)\\n+\\n+    monkeypatch.setattr('sky.backends.backend_utils.check_owner_identity',\\n+                        lambda _: None)\\n+\\n \\n @pytest.fixture\\n def aws_config_region(monkeypatch) -> str:\\n\",\"diff --git a/tests/default_aws_az_mappings.csv b/tests/default_aws_az_mappings.csv\\nnew file mode 100644\\nindex 00000000000..03b824acee2\\n--- /dev/null\\n+++ b/tests/default_aws_az_mappings.csv\\n@@ -0,0 +1,71 @@\\n+AvailabilityZoneName,AvailabilityZone\\n+eu-west-2a,euw2-az2\\n+eu-west-2b,euw2-az3\\n+eu-west-2c,euw2-az1\\n+ap-south-1a,aps1-az1\\n+ap-south-1b,aps1-az3\\n+ap-south-1c,aps1-az2\\n+us-east-1a,use1-az2\\n+us-east-1b,use1-az4\\n+us-east-1c,use1-az6\\n+us-east-1d,use1-az1\\n+us-east-1e,use1-az3\\n+us-east-1f,use1-az5\\n+ap-southeast-3a,apse3-az1\\n+ap-southeast-3b,apse3-az2\\n+ap-southeast-3c,apse3-az3\\n+ca-central-1a,cac1-az1\\n+ca-central-1b,cac1-az2\\n+ca-central-1d,cac1-az4\\n+us-east-2a,use2-az1\\n+us-east-2b,use2-az2\\n+us-east-2c,use2-az3\\n+eu-north-1a,eun1-az1\\n+eu-north-1b,eun1-az2\\n+eu-north-1c,eun1-az3\\n+eu-west-1a,euw1-az3\\n+eu-west-1b,euw1-az1\\n+eu-west-1c,euw1-az2\\n+eu-west-3a,euw3-az1\\n+eu-west-3b,euw3-az2\\n+eu-west-3c,euw3-az3\\n+eu-central-1a,euc1-az2\\n+eu-central-1b,euc1-az3\\n+eu-central-1c,euc1-az1\\n+ap-northeast-2a,apne2-az1\\n+ap-northeast-2b,apne2-az2\\n+ap-northeast-2c,apne2-az3\\n+ap-northeast-2d,apne2-az4\\n+me-south-1a,mes1-az1\\n+me-south-1b,mes1-az2\\n+me-south-1c,mes1-az3\\n+ap-northeast-3a,apne3-az3\\n+ap-northeast-3b,apne3-az1\\n+ap-northeast-3c,apne3-az2\\n+us-west-2a,usw2-az1\\n+us-west-2b,usw2-az2\\n+us-west-2c,usw2-az3\\n+us-west-2d,usw2-az4\\n+eu-south-1a,eus1-az1\\n+eu-south-1b,eus1-az2\\n+eu-south-1c,eus1-az3\\n+me-central-1a,mec1-az1\\n+me-central-1b,mec1-az2\\n+me-central-1c,mec1-az3\\n+ap-east-1a,ape1-az1\\n+ap-east-1b,ape1-az2\\n+ap-east-1c,ape1-az3\\n+af-south-1a,afs1-az1\\n+af-south-1b,afs1-az2\\n+af-south-1c,afs1-az3\\n+ap-southeast-1a,apse1-az2\\n+ap-southeast-1b,apse1-az1\\n+ap-southeast-1c,apse1-az3\\n+ap-northeast-1a,apne1-az4\\n+ap-northeast-1c,apne1-az1\\n+ap-northeast-1d,apne1-az2\\n+ap-southeast-2a,apse2-az1\\n+ap-southeast-2b,apse2-az3\\n+ap-southeast-2c,apse2-az2\\n+us-west-1a,usw1-az1\\n+us-west-1c,usw1-az3\\n\",\"diff --git a/tests/test_cli.py b/tests/test_cli.py\\nindex 602a5575385..c2a77064d98 100644\\n--- a/tests/test_cli.py\\n+++ b/tests/test_cli.py\\n@@ -76,9 +76,7 @@ def _capture_match_gpus_spec(file_path, gpus: str):\\n \\n         _capture_match_gpus_spec(f.name, 'V100:1')\\n         _capture_match_gpus_spec(f.name, 'v100:1')\\n-        _capture_match_gpus_spec(f.name, 'V100:0.5')\\n         _capture_match_gpus_spec(f.name, 'V100')\\n-        _capture_match_gpus_spec(f.name, 'V100:0.5')\\n \\n \\n def test_show_gpus():\\n\",\"diff --git a/tests/test_jobs.py b/tests/test_jobs.py\\nnew file mode 100644\\nindex 00000000000..8ef499bd9db\\n--- /dev/null\\n+++ b/tests/test_jobs.py\\n@@ -0,0 +1,123 @@\\n+import pytest\\n+\\n+import sky\\n+from sky import backends\\n+from sky import exceptions\\n+from sky import global_user_state\\n+from sky.utils import db_utils\\n+\\n+\\n+class TestExecutionOnExistingClusters:\\n+    \\\"\\\"\\\"Test operations on reserved clusters.\\\"\\\"\\\"\\n+\\n+    @pytest.fixture\\n+    def _mock_db_conn(self, monkeypatch, tmp_path):\\n+        tmp_path.mkdir(parents=True, exist_ok=True)\\n+        db_path = tmp_path / 'state_testing_optimizer_dryrun.db'\\n+        monkeypatch.setattr(\\n+            global_user_state, '_DB',\\n+            db_utils.SQLiteConn(str(db_path), global_user_state.create_table))\\n+\\n+    @pytest.fixture\\n+    def _mock_cluster_state(self, _mock_db_conn, enable_all_clouds):\\n+        assert 'state.db' not in global_user_state._DB.db_path\\n+\\n+        handle = backends.CloudVmRayResourceHandle(\\n+            cluster_name='test-cluster1',\\n+            cluster_yaml='/tmp/cluster1.yaml',\\n+            launched_nodes=2,\\n+            launched_resources=sky.Resources(sky.AWS(),\\n+                                             instance_type='p4d.24xlarge',\\n+                                             region='us-east-1',\\n+                                             zone='us-east-1a'),\\n+        )\\n+        global_user_state.add_or_update_cluster(\\n+            'test-cluster1',\\n+            handle,\\n+            requested_resources={handle.launched_resources},\\n+            ready=True)\\n+        handle = backends.CloudVmRayResourceHandle(\\n+            cluster_name='test-cluster2',\\n+            cluster_yaml='/tmp/cluster2.yaml',\\n+            launched_nodes=1,\\n+            launched_resources=sky.Resources(sky.GCP(),\\n+                                             instance_type='n1-highmem-64',\\n+                                             accelerators='V100:4',\\n+                                             region='us-west1',\\n+                                             zone='us-west1-a'),\\n+        )\\n+        global_user_state.add_or_update_cluster(\\n+            'test-cluster2',\\n+            handle,\\n+            requested_resources={handle.launched_resources},\\n+            ready=True)\\n+        handle = backends.CloudVmRayResourceHandle(\\n+            cluster_name='test-cluster3',\\n+            cluster_yaml='/tmp/cluster3.yaml',\\n+            launched_nodes=1,\\n+            launched_resources=sky.Resources(sky.Azure(),\\n+                                             instance_type='Standard_D4s_v3',\\n+                                             region='eastus'),\\n+        )\\n+        global_user_state.add_or_update_cluster(\\n+            'test-cluster3',\\n+            handle,\\n+            requested_resources={handle.launched_resources},\\n+            ready=False)\\n+\\n+    def test_launch_exec(self, _mock_cluster_state, monkeypatch):\\n+        task = sky.Task(run='echo hi')\\n+        task.set_resources(sky.Resources(accelerators='A100:8'))\\n+        sky.launch(task, cluster_name='test-cluster1', dryrun=True)\\n+        sky.exec(task, cluster_name='test-cluster1', dryrun=True)\\n+        task.set_resources(sky.Resources(accelerators='A100:3'))\\n+        sky.launch(task, cluster_name='test-cluster1', dryrun=True)\\n+        sky.exec(task, cluster_name='test-cluster1', dryrun=True)\\n+        task.set_resources(\\n+            sky.Resources(\\n+                sky.AWS(),\\n+                accelerators='A100:1',\\n+                region='us-east-1',\\n+            ))\\n+        sky.launch(task, cluster_name='test-cluster1', dryrun=True)\\n+        sky.exec(task, cluster_name='test-cluster1', dryrun=True)\\n+\\n+        task = sky.Task(run='echo hi')\\n+        task.set_resources(sky.Resources(accelerators='V100:4'))\\n+        sky.launch(task, cluster_name='test-cluster2', dryrun=True)\\n+        sky.exec(task, cluster_name='test-cluster2', dryrun=True)\\n+        task.set_resources(\\n+            sky.Resources(sky.GCP(), accelerators='V100:3', region='us-west1'))\\n+        sky.launch(task, cluster_name='test-cluster2', dryrun=True)\\n+        sky.exec(task, cluster_name='test-cluster2', dryrun=True)\\n+\\n+        task = sky.Task(run='echo hi')\\n+        sky.exec(task, cluster_name='test-cluster3', dryrun=True)\\n+\\n+    def _run_launch_exec_with_error(self, task, cluster_name):\\n+        with pytest.raises(exceptions.ResourcesMismatchError) as e:\\n+            sky.launch(task, cluster_name=cluster_name, dryrun=True)\\n+            assert 'do not match the existing cluster.' in str(e.value), str(\\n+                e.value)\\n+        with pytest.raises(exceptions.ResourcesMismatchError) as e:\\n+            sky.exec(task, cluster_name=cluster_name, dryrun=True)\\n+            assert 'do not match the existing cluster.' in str(e.value), str(\\n+                e.value)\\n+\\n+    def test_launch_exec_mismatch(self, _mock_cluster_state, monkeypatch):\\n+        task = sky.Task(run='echo hi')\\n+        # Accelerators mismatch\\n+        task.set_resources(sky.Resources(accelerators='V100:8'))\\n+        self._run_launch_exec_with_error(task, 'test-cluster1')\\n+        self._run_launch_exec_with_error(task, 'test-cluster2')\\n+\\n+        task.set_resources(sky.Resources(accelerators='A100:8'))\\n+        self._run_launch_exec_with_error(task, 'test-cluster2')\\n+        self._run_launch_exec_with_error(task, 'test-cluster3')\\n+\\n+        # Cloud mismatch\\n+        task.set_resources(sky.Resources(sky.AWS(), accelerators='V100'))\\n+        self._run_launch_exec_with_error(task, 'test-cluster2')\\n+\\n+        task.set_resources(sky.Resources(sky.GCP()))\\n+        self._run_launch_exec_with_error(task, 'test-cluster1')\\n\",\"diff --git a/tests/test_optimizer_dryruns.py b/tests/test_optimizer_dryruns.py\\nindex 7deb0718961..8bfa4944a54 100644\\n--- a/tests/test_optimizer_dryruns.py\\n+++ b/tests/test_optimizer_dryruns.py\\n@@ -367,7 +367,16 @@ def test_instance_type_matches_accelerators(monkeypatch):\\n                            sky.GCP(),\\n                            instance_type='n1-standard-2',\\n                            accelerators='V100')\\n-    # Partial use: Instance has 8 V100s, while the task needs 1 of them.\\n+\\n+    _test_resources_launch(monkeypatch,\\n+                           sky.GCP(),\\n+                           instance_type='n1-standard-8',\\n+                           accelerators='tpu-v3-8')\\n+    _test_resources_launch(monkeypatch,\\n+                           sky.GCP(),\\n+                           instance_type='a2-highgpu-1g',\\n+                           accelerators='a100')\\n+\\n     _test_resources_launch(monkeypatch,\\n                            sky.AWS(),\\n                            instance_type='p3.16xlarge',\\n@@ -627,3 +636,16 @@ def test_parse_valid_envs_yaml(monkeypatch):\\n           GOOD123: 123\\n         \\\"\\\"\\\")\\n     _test_parse_task_yaml(spec)\\n+\\n+\\n+def test_invalid_accelerators_regions(enable_all_clouds, monkeypatch):\\n+    task = sky.Task(run='echo hi')\\n+    task.set_resources(\\n+        sky.Resources(\\n+            sky.AWS(),\\n+            accelerators='A100:8',\\n+            region='us-west-1',\\n+        ))\\n+    with pytest.raises(exceptions.ResourcesUnavailableError) as e:\\n+        sky.launch(task, cluster_name='should-fail', dryrun=True)\\n+        assert 'No launchable resource found for' in str(e.value), str(e.value)\\n\",\"diff --git a/tests/test_cli.py b/tests/test_cli.py\\nindex c2a77064d98..4acc29d4e4b 100644\\n--- a/tests/test_cli.py\\n+++ b/tests/test_cli.py\\n@@ -5,7 +5,6 @@\\n \\n import sky\\n from sky import exceptions\\n-from sky import clouds\\n import sky.cli as cli\\n \\n CLOUDS_TO_TEST = ['aws', 'gcp', 'ibm', 'azure', 'lambda', 'scp', 'oci']\\n\",\"diff --git a/tests/test_jobs.py b/tests/test_jobs.py\\nindex 8ef499bd9db..d61a851c486 100644\\n--- a/tests/test_jobs.py\\n+++ b/tests/test_jobs.py\\n@@ -20,6 +20,13 @@ def _mock_db_conn(self, monkeypatch, tmp_path):\\n \\n     @pytest.fixture\\n     def _mock_cluster_state(self, _mock_db_conn, enable_all_clouds):\\n+        \\\"\\\"\\\"Add clusters to the global state.\\n+        \\n+        This fixture adss three clusters to the global state:\\n+        - test-cluster1: AWS, 2x p4d.24xlarge (8x A100)\\n+        - test-cluster2: GCP, 1x n1-highmem-64, 4x V100\\n+        - test-cluster3: Azure, 1x Standard_D4s_v3 (CPU only)\\n+        \\\"\\\"\\\"\\n         assert 'state.db' not in global_user_state._DB.db_path\\n \\n         handle = backends.CloudVmRayResourceHandle(\\n@@ -66,6 +73,11 @@ def _mock_cluster_state(self, _mock_db_conn, enable_all_clouds):\\n             ready=False)\\n \\n     def test_launch_exec(self, _mock_cluster_state, monkeypatch):\\n+        \\\"\\\"\\\"Test launch and exec on existing clusters.\\n+        \\n+        This test runs launch and exec with less demanding resources\\n+        than the existing clusters can pass the check.\\n+        \\\"\\\"\\\"\\n         task = sky.Task(run='echo hi')\\n         task.set_resources(sky.Resources(accelerators='A100:8'))\\n         sky.launch(task, cluster_name='test-cluster1', dryrun=True)\\n@@ -105,6 +117,7 @@ def _run_launch_exec_with_error(self, task, cluster_name):\\n                 e.value)\\n \\n     def test_launch_exec_mismatch(self, _mock_cluster_state, monkeypatch):\\n+        \\\"\\\"\\\"Test launch and exec on existing clusters with mismatched resources.\\\"\\\"\\\"\\n         task = sky.Task(run='echo hi')\\n         # Accelerators mismatch\\n         task.set_resources(sky.Resources(accelerators='V100:8'))\"]", "hints_text": ""}
