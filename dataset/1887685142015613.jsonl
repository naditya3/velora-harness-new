{"instance_id": "1887685142015613", "repo": "sdss/sdss_brain", "base_commit": "a57a4a828f98877f30cc575a7a722ccbe25b11ab", "problem_statement": "version mismatch handling should be more robust:\\nWhen passing in a filename to a tool without a release, the default is to use the release set in the config.  When the version in a filepath mismatches the config release, the tool currently loads the file but can't necessarily extract all the path parameters.  It should either resolve, fail cleanly, or issue a warning.  ", "FAIL_TO_PASS": ["tests/tools/test_apogee.py::TestAspcapStarWorkVersions::test_as_fileinput[DR16]", "tests/tools/test_eboss.py::TestEbossWorkFails::test_no_work_version_set", "tests/tools/test_apogee.py::TestAspcapStarWorkVersions::test_as_filename[WORK-r13]", "tests/tools/test_apogee.py::TestAspcapStarWorkVersions::test_as_fileinput[WORK-r12]", "tests/tools/test_apogee.py::TestAspcapStarWorkVersions::test_as_filename[WORK-r12]", "tests/tools/test_apogee.py::TestAspcapStarWorkVersions::test_as_filename[DR16]", "tests/tools/test_apogee.py::TestAspcapStarWorkVersions::test_as_fileinput[WORK-r13]"], "PASS_TO_PASS": ["tests/test_parsing.py::TestParsing::test_custom_regex[named-mangaid]", "tests/test_parsing.py::TestParsing::test_pattern_with_key_options[order-vals2]", "tests/test_parsing.py::TestParsing::test_custom_regex[named-plateifu]", "tests/test_parsing.py::TestParsing::test_keys_order[1901-8485-opts2-True]", "tests/test_mma.py::TestMMA::test_explicit_input[filename]", "tests/test_mma.py::TestMMA::test_get_full_path", "tests/test_mma.py::TestMMAFails::test_bad_parse_inputs[none-input", "tests/test_mma.py::TestMMAFails::test_bad_access_params[notdict-path_params", "tests/test_mma.py::TestMMA::test_explicit_input[objectid]", "tests/test_parsing.py::TestParsing::test_pattern_with_key_options[exclude-vals0]", "tests/test_parsing.py::TestParsing::test_keys_order[8485-1901-opts1-False]", "tests/test_mma.py::TestMMA::test_access_switch", "tests/test_parsing.py::TestParsing::test_keys_exclude[v1-8485-opts0-exp0]", "tests/test_parsing.py::TestParsing::test_parse_files[$TOYPATH/A/newfile-v1-8485-1901-LOG.txt]", "tests/test_config.py::TestConfig::test_release_fail", "tests/test_parsing.py::TestParsing::test_keys_exclude[8485-1901-opts1-exp1]", "tests/test_versions.py::TestMappingFails::test_bad_config", "tests/test_parsing.py::TestParsing::test_default_keys[8485-1901-None]", "tests/test_mma.py::TestMMA::test_local_input[objectid]", "tests/test_mma.py::TestMMA::test_local_input[filename]", "tests/test_mma.py::TestMMAFails::test_bad_access_params[badpath-must", "tests/test_parsing.py::TestParsing::test_default_keys[v1-8485-1901-LOG-v1-8485-1901-LOG]", "tests/test_parsing.py::TestParsing::test_parse_files[../../file/A/newfile-v1-8485-1901-LOG.txt]", "tests/test_versions.py::TestVersionMapping::test_mapping_exists", "tests/test_mma.py::TestMMAFails::test_bad_access_params[noname-must", "tests/test_parsing.py::TestParsing::test_custom_regex[simple]", "tests/test_parsing.py::TestParsing::test_keys_order[8485-1901-opts0-True]", "tests/test_mma.py::TestMMAFails::test_bad_parse_inputs[empty-no", "tests/test_parsing.py::TestParsing::test_keymap", "tests/test_config.py::TestConfig::test_set_release_fail", "tests/test_parsing.py::TestParsing::test_pattern_with_key_options[include-vals1]", "tests/test_parsing.py::TestParsing::test_keys_include[8485-1901-opts1-exp1]", "tests/test_mma.py::TestMMA::test_remote", "tests/test_mma.py::TestMMAMixin::test_noaccess", "tests/test_mma.py::TestMMAFails::test_fail_remote_filename", "tests/test_config.py::TestConfig::test_set_release", "tests/test_mma.py::TestMMAFails::test_bad_access_params[nonename-path_name", "tests/test_parsing.py::TestParsing::test_parse_files[/tmp/path/to/file/v1/newfile-v1-8485-1901-LOG.txt]", "tests/test_parsing.py::TestParsing::test_custom_regex[groups]", "tests/test_config.py::TestConfig::test_update_cfg", "tests/test_config.py::TestConfig::test_read_cfg", "tests/test_parsing.py::TestParsing::test_keys_include[v1-8485-opts0-exp0]"], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/sdss_sdss_brain:a57a4a828f98877f30cc575a7a722ccbe25b11ab", "patch": "[\"diff --git a/.github/workflows/pythonpublish.yml b/.github/workflows/pythonpublish.yml\\nindex e8fcb18..4c65d0f 100644\\n--- a/.github/workflows/pythonpublish.yml\\n+++ b/.github/workflows/pythonpublish.yml\\n@@ -22,10 +22,10 @@ jobs:\\n       run: |\\n         python -m pip install --upgrade pip\\n         pip install setuptools wheel twine\\n-    - name: Build and publish\\n-      env:\\n-        TWINE_USERNAME: ${{ secrets.PYPI_USERNAME }}\\n-        TWINE_PASSWORD: ${{ secrets.PYPI_PASSWORD }}\\n-      run: |\\n-        python setup.py sdist bdist_wheel --universal\\n-        twine upload dist/*\\n+    # - name: Build and publish\\n+    #   env:\\n+    #     TWINE_USERNAME: ${{ secrets.PYPI_USERNAME }}\\n+    #     TWINE_PASSWORD: ${{ secrets.PYPI_PASSWORD }}\\n+    #   run: |\\n+    #     python setup.py sdist bdist_wheel --universal\\n+    #     twine upload dist/*\\n\",\"diff --git a/CHANGELOG.rst b/CHANGELOG.rst\\nindex fc714df..827d271 100644\\n--- a/CHANGELOG.rst\\n+++ b/CHANGELOG.rst\\n@@ -5,6 +5,8 @@ Change Log\\n ==========\\n \\n * :release:`0.1.2 <unknown>`\\n+* :feature:`9` adds ability to specify work versions to access unreleased data products\\n+* :support:`7` issues a warning when a mismatch is found between extracted filename version and the release or work version\\n * :feature:`-` adds new convenience spectrum tools, ``Eboss``, ``MangaCube``, ``ApStar``, ``ApVisit``, and ``AspcapStar``\\n * :feature:`-` adds simple IO functions ``load_fits_file`` and ``load_from_url``\\n * :feature:`1` adds a base ``Spectrum`` class to handle spectral data\\n\",\"diff --git a/docs/sphinx/config.rst b/docs/sphinx/config.rst\\nindex b443d07..1018d5a 100644\\n--- a/docs/sphinx/config.rst\\n+++ b/docs/sphinx/config.rst\\n@@ -2,16 +2,16 @@\\n \\n .. _config:\\n \\n-Global Config\\n--------------\\n+About the Global Config\\n+-----------------------\\n \\n ``sdss_brain`` includes a global configuration class, ``Config``, which handles parameters used globally\\n by ``sdss_brain`` and potentially other SDSS packages.\\n \\n General custom configuration can be accomplished using the `sdss_brain.yml` YAML configuration file.  This file\\n can also be used to set custom user choices.  See the `sdsstools config <https://github.com/sdss/sdsstools#configuration>`_\\n-or the `Python template config <https://sdss-python-template.readthedocs.io/en/python-template-v2/#configuration-file-and-logging>`_ \\n-for more details on the custom configuration file.The ``Config`` class reads in this file and updates any \\n+or the `Python template config <https://sdss-python-template.readthedocs.io/en/python-template-v2/#configuration-file-and-logging>`_\\n+for more details on the custom configuration file.The ``Config`` class reads in this file and updates any\\n overlapping parameters with user values.  This way you can set a custom SDSS configuration only once.\\n \\n The ``Config`` class contains the following attributes:\\n@@ -21,20 +21,57 @@ The ``Config`` class contains the following attributes:\\n - **download**: If True, downloads any files accessed with `sdss_access`\\n - **ignore_db**: If True, ignores any database connections used with ``Brain``-based tools\\n \\n-Only valid releases are allowed when setting a new release.  Allowed releases are those returned by the \\n+Only valid releases are allowed when setting a new release.  Allowed releases are those returned by the\\n SDSS `tree` package, using the ``get_available_releases`` method.  Valid releases are typically any public\\n data releases (DRs) or official survey-specific internal releases, e.g interal MaNGA Product Launches (MPLs).\\n \\n Additionally, setting the release to ``work`` allows ``sdss_brain`` and ``sdss_access`` to access files not yet\\n within a release, specified in the current ``sdsswork.cfg`` Tree environment configuration.\\n \\n-To set a new release:\\n+To set a new global release:\\n ::\\n \\n     from sdss_brain.config import config\\n     config.set_release('DR14')\\n \\n+To set global \\\"working\\\" versions:\\n+::\\n+\\n+    # set the new work versions\\n+    from sdss_brain.config import config\\n+    config.set_work_versions({'drpver': 'v2_4_3', 'run2d': 'v5_10_0', 'apred': 'r12'})\\n+\\n+    # access the set work versions\\n+    config.work_versions\\n \\n+.. _config_file:\\n+\\n+The Custom Config File\\n+----------------------\\n+\\n+To customize the configuration for the ``Brain``, you can create a new YAML config file at\\n+`~/.config/sdss/sdss_brain.yml`.  This config file allows you to set custom configuration options that\\n+are loaded when the ``Brain`` config is instantiated.  The following entries are available:\\n+\\n+- **ignore_db**: If True, ignores any database connections used with ``Brain``-based tools\\n+- **download**: If True, downloads any data files accessed with `sdss_access`\\n+- **default_release**: Sets the default data release to use\\n+- **work_versions**: Sets the specified versions to use when accessing \\\"sdsswork\\\" files\\n+\\n+The following example config file instructs the ``Brain`` to always ignore database connections, to not\\n+download data files by default, to use DR15 as the default release, and to set the work versions for\\n+MaNGA, APOGEE, and EBOSS data to (v2_4_3, 2.2.1), r12, and v5_10_0, respectively.\\n+\\n+.. code-block:: yaml\\n+\\n+    ignore_db: True\\n+    download: False\\n+    default_release: DR15\\n+    work_versions:\\n+      drpver: v2_4_3\\n+      dapver: 2.2.1\\n+      apred: r12\\n+      run2d: v5_10_0\\n \\n \\n \\n\",\"diff --git a/docs/sphinx/index.rst b/docs/sphinx/index.rst\\nindex e12a1e7..00c6d74 100644\\n--- a/docs/sphinx/index.rst\\n+++ b/docs/sphinx/index.rst\\n@@ -22,6 +22,7 @@ Contents\\n \\n   Introduction to sdss_brain <intro>\\n   Convenience Tools <tools>\\n+  Accessing unreleased (\\\"work\\\") data <work>\\n   About the global configuration <config>\\n   How to map specific version numbers to Data Release ids <version>\\n   How to create and parse a custom objectid as valid data input <parsing>\\n\",\"diff --git a/docs/sphinx/intro.rst b/docs/sphinx/intro.rst\\nindex 886a23f..bad99bf 100644\\n--- a/docs/sphinx/intro.rst\\n+++ b/docs/sphinx/intro.rst\\n@@ -106,7 +106,7 @@ class, highlighting how to integrate the MMA into a new tool.\\n                 self.plateifu = plateifu_match.group(0)\\n                 self.plate, self.ifu = plateifu_match.groups(0)\\n             else:\\n-                data['filename']\\n+                data['filename'] = value\\n             return data\\n \\n         def _load_object_from_file(self, data=None):\\n\",\"diff --git a/docs/sphinx/tools.rst b/docs/sphinx/tools.rst\\nindex cd747d5..ed02d0c 100644\\n--- a/docs/sphinx/tools.rst\\n+++ b/docs/sphinx/tools.rst\\n@@ -110,9 +110,10 @@ that we may not have locally.\\n Context Managers\\n ^^^^^^^^^^^^^^^^\\n \\n-The ``Brain`` and all subclasses open FITS data and make it directly accessible via the ``data`` attribute.\\n-Each tool or ``Brain`` subclass comes with a destructor method that should safely close any open files,\\n-database connections, or remote request sessions.  Alternatively you can use each tool as a contextmanager.\\n+The ``Brain`` and all subclasses act as open data handlers.  For example, they open FITS data and make it\\n+directly accessible via the ``data`` attribute. Each tool or ``Brain`` subclass comes with a\\n+destructor method that should safely close any open files, database connections, or remote request\\n+sessions.  Alternatively you can use each tool as a contextmanager to safely access underlying data.\\n ::\\n \\n     with Eboss(s, release='DR14') as e:\\n\",\"diff --git a/docs/sphinx/work.rst b/docs/sphinx/work.rst\\nnew file mode 100644\\nindex 0000000..ba23d69\\n--- /dev/null\\n+++ b/docs/sphinx/work.rst\\n@@ -0,0 +1,145 @@\\n+\\n+.. _work:\\n+\\n+Setting Work Versions\\n+---------------------\\n+\\n+``sdss_brain`` can work with data files not yet explicitly released in a public or internal data release\\n+by using what are called \\\"work\\\" versions, attached to a \\\"work\\\" release.  \\\"Work\\\" versions are survey\\n+specific version numbers needed to identify file paths typically listed under the SAS \\\"sdsswork\\\" directory\\n+or module, or the equivalent survey-specific work directories, e.g. \\\"ebosswork\\\", \\\"apogeework\\\", \\\"mangawork\\\".\\n+For example, work versions might be `run2d = v5_10_0` for EBOSS data, `apred = r12` for APOGEE data,\\n+or `drpver = v2_4_3, dapver = 2.2.1` for MaNGA data.\\n+\\n+Defining Work Versions\\n+^^^^^^^^^^^^^^^^^^^^^^\\n+\\n+Specifying ``release=\\\"WORK\\\"`` and these versions tells the ``Brain`` which files to look for when\\n+operating under a work directory.  Work versions take a dictionary format with ``key:value`` set to the\\n+``version_name:version_number``, where ``version_name`` is a valid version name normally as specified by\\n+the ``sdss_access`` path template keyword argument.  ``version_number`` is a valid version number.  There\\n+are several ways to set valid work versions.\\n+\\n+By the config class:\\n+::\\n+\\n+    >>> # set the new work versions\\n+    >>> from sdss_brain.config import config\\n+    >>> config.set_work_versions({'drpver': 'v2_4_3', 'run2d': 'v5_10_0', 'apred': 'r12'})\\n+\\n+or by using the configuration file to set them permanently.  See :ref:`config_file` for an example of how\\n+to set the work versions.  You can also do so individually on a tool.\\n+::\\n+\\n+    >>> from sdss_brain.tools import Eboss\\n+    >>> e=Eboss('3606-55182-0537', version={'run2d': 'v5_10_0'})\\n+\\n+Version Order Precedence\\n+^^^^^^^^^^^^^^^^^^^^^^^^\\n+\\n+The order of precendence the ``Brain`` uses when deciding which work versions to use in a given tool is\\n+**tool > setting the config > using the custom config file**.  Specifying versions explicitly on a\\n+tool takes precedence over using the config `~sdss_brain.config.Config.set_work_versions` method which takes\\n+precedence over any values found in the custom ``sdss_brain.yml`` configuration file.\\n+\\n+\\n+Setting the Work Release\\n+^^^^^^^^^^^^^^^^^^^^^^^^\\n+\\n+Additionally to \\\"work\\\" versions, the global, or tool, ``release`` attribute must be set to **\\\"WORK\\\"** rather\\n+than a data release ID.  You can set the work release globally.\\n+::\\n+\\n+    >>> from sdss_brain.config\\n+    >>> config.set_release('work')\\n+\\n+Or individually on each tools.\\n+::\\n+\\n+    >>> from sdss_brain.tools import Eboss\\n+    >>> e=Eboss('3606-55182-0537', release='WORK')\\n+\\n+Example Access of \\\"Work\\\" Data\\n+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n+\\n+Here is an example highlighting how to access different work versions for an EBOSS ``spec-lite`` file.  First\\n+we set our default work versions using the config class, and set our release to \\\"work\\\".\\n+::\\n+\\n+    >>> # set the new work versions\\n+    >>> from sdss_brain.config import config\\n+    >>> config.set_work_versions({'drpver': 'v2_4_3', 'run2d': 'v5_10_0', 'apred': 'r12'})\\n+    >>> config.work_versions\\n+    {'drpver': 'v2_4_3', 'dapver': '2.2.1', 'apred': 'r12', 'run2d': 'v5_10_0'}\\n+\\n+    >>> # set the global release\\n+    config.set_release(\\\"work\\\")\\n+\\n+Now we import the `~sdss_brain.tools.spectra.Eboss` spectrum tool, and load some data.  We can see the full\\n+file path is set to use the ``ebosswork`` directory, with ``run2d`` version set to `v5_10_0`.\\n+::\\n+\\n+    >>> from sdss_brain.tools import Eboss\\n+    >>> e = Eboss('3606-55182-0537')\\n+    >>> e\\n+    <Eboss objectid='3606-55182-0537', mode='local', data_origin='file', lite=True>\\n+\\n+    >>> # check the filename path\\n+    >>> e.get_full_path()\\n+    '/Users/Brian/Work/sdss/sas/ebosswork/eboss/spectro/redux/v5_10_0/spectra/lite/3606/spec-3606-55182-0537.fits'\\n+\\n+    >>> # check the version number\\n+    >>> e.run2d\\n+    'v5_10_0'\\n+\\n+We can explicitly change the work version accessed by specifying the ``version`` keyword as input.  This lets\\n+us load a different work file without changing the default work version set. Let's load the same file but for\\n+`run2d = v5_13_0`.\\n+::\\n+\\n+    >>> from sdss_brain.tools import Eboss\\n+    >>> e = Eboss('3606-55182-0537', version={'run2d': 'v5_13_0')\\n+    >>> e\\n+    <Eboss objectid='3606-55182-0537', mode='remote', data_origin='api', lite=True>\\n+\\n+    >>> # check the filename path\\n+    >>> e.get_full_path()\\n+    '/Users/Brian/Work/sdss/sas/ebosswork/eboss/spectro/redux/v5_13_0/spectra/lite/3606/spec-3606-55182-0537.fits'\\n+\\n+    >>> # check the version number\\n+    >>> e.run2d\\n+    'v5_13_0'\\n+\\n+.. note::\\n+    Even though the object is instantiated in \\\"remote\\\" mode with ``data_origin`` set to API, you can still\\n+    construct a valid file path using `get_full_path` which uses ``sdss_access`` under the hood which\\n+    specifies what would the file location be.  Checking ``e.filename`` in the above will verify that the\\n+    file does not actually exist locally.  You can always download the file with ``e.download()``.\\n+\\n+Work Authentication\\n+^^^^^^^^^^^^^^^^^^^\\n+\\n+Accessing unreleased \\\"work\\\" data requires proper SDSS authentication.  For remote access with ``sdss_access``,\\n+``requests``, ``httpx`` or any HTTP request library, this uses the ``~/.netrc`` file.  Any attempt to access\\n+data without a properly set ``.netrc`` file will result in an error.\\n+::\\n+\\n+    >>> from sdss_brain.tools import Eboss\\n+    >>> e = Eboss('3606-55182-0537', version={'run2d': 'v5_13_0')\\n+    HTTPStatusError: 401 Client Error: Unauthorized for url: https://data.sdss.org/sas/ebosswork/eboss/spectro/redux/v5_13_0/spectra/lite/3606/spec-3606-55182-0537.fits\\n+    For more information check: https://httpstatuses.com/401\\n+\\n+SDSS uses ``.netrc`` authentication to access data content on many domains. To set this up, create and\\n+edit a file in your home directory ocalled ``.netrc`` and copy these lines inside::\\n+\\n+    machine api.sdss.org\\n+       login <username>\\n+       password <password>\\n+\\n+    machine data.sdss.org\\n+       login <username>\\n+       password <password>\\n+\\n+Replace ``<username>`` and ``<password>`` with your login credentials. The default SDSS username and\\n+password is also acceptable for anonymous access.  **Finally, run** ``chmod 600 ~/.netrc`` **to make\\n+the file only accessible to your user.**\\n\",\"diff --git a/python/sdss_brain/core.py b/python/sdss_brain/core.py\\nindex d6adbf6..e368061 100644\\n--- a/python/sdss_brain/core.py\\n+++ b/python/sdss_brain/core.py\\n@@ -13,6 +13,8 @@\\n \\n from __future__ import print_function, division, absolute_import\\n import abc\\n+from sdss_brain.config import config\\n+from sdss_brain.exceptions import BrainError\\n from sdss_brain.mixins.mma import MMAccess, MMAMixIn\\n from astropy.io import fits\\n \\n@@ -21,10 +23,12 @@ class Base(abc.ABC):\\n     ''' abstract base class for tools '''\\n \\n     def __new__(cls, *args, **kwargs):\\n+        # set the correct MMA class\\n         if MMAccess in cls.mro():\\n             cls._mma = MMAccess\\n         else:\\n             cls._mma = MMAMixIn\\n+\\n         return super().__new__(cls)\\n \\n     @abc.abstractmethod\\n@@ -84,18 +88,37 @@ class HindBrain(Base):\\n     '''\\n     _db = None\\n     mapped_version = None\\n+    data_origin = None\\n+\\n+    def __new__(cls, *args, **kwargs):\\n+        # set any work versions\\n+        cls.set_work_version(config.work_versions)\\n+        return super().__new__(cls)\\n \\n     def __init__(self, data_input: str = None, filename: str = None,\\n                  objectid: str = None, mode: str = None, data: object = None,\\n                  release: str = None, download: bool = None,\\n-                 ignore_db: bool = None, use_db: bool = None) -> None:\\n+                 ignore_db: bool = None, use_db: bool = None, version: str = None) -> None:\\n+\\n+        # set a version for sdsswork data\\n+        checked_release = release or config.release\\n+        if version:\\n+            self.set_work_version(version)\\n+            if checked_release.lower() != 'work':\\n+                raise BrainError('version is only used for \\\"work\\\" data. '\\n+                                 'Please set the input or config release to \\\"WORK\\\"')\\n+        else:\\n+            if not self._version and checked_release.lower() == 'work':\\n+                raise BrainError('You are using a \\\"work\\\" release but have no work versions set! '\\n+                                 'Try setting a global \\\"work_version\\\" dict or specify a \\\"version\\\" input!')\\n \\n-        self.data = data\\n+        # initialize the MMA\\n         self._mma.__init__(self, data_input=data_input, filename=filename,\\n                            objectid=objectid, mode=mode,\\n                            release=release, download=download,\\n                            ignore_db=ignore_db, use_db=use_db or self._db)\\n \\n+        self.data = data\\n         if self.data_origin == 'file':\\n             self._load_object_from_file(data=data)\\n         elif self.data_origin == 'db':\\n@@ -131,6 +154,17 @@ class HindBrain(Base):\\n         self._close()\\n         return True\\n \\n+    @classmethod\\n+    def set_work_version(cls, value: dict):\\n+        ''' Set the work version for the given class '''\\n+        if type(value) != dict:\\n+            raise ValueError(f'input verion must be a dictionary')\\n+\\n+        # update any existing work versions with the new values\\n+        wv = config.work_versions.copy()\\n+        wv.update(value)\\n+        cls._version = wv\\n+\\n \\n class Brain(HindBrain, MMAccess):\\n     \\\"\\\"\\\" The hind Brain with support for ``sdss_access``\\n\",\"diff --git a/python/sdss_brain/etc/sdss_brain.yml b/python/sdss_brain/etc/sdss_brain.yml\\nindex 63f3530..45ee612 100644\\n--- a/python/sdss_brain/etc/sdss_brain.yml\\n+++ b/python/sdss_brain/etc/sdss_brain.yml\\n@@ -2,6 +2,7 @@\\n \\n ignore_db: False\\n download: False\\n+default_release: null\\n \\n mapped_versions:\\n   manga:\\n\",\"diff --git a/python/sdss_brain/helpers/decorators.py b/python/sdss_brain/helpers/decorators.py\\nindex 844fd30..cfafb77 100644\\n--- a/python/sdss_brain/helpers/decorators.py\\n+++ b/python/sdss_brain/helpers/decorators.py\\n@@ -86,9 +86,9 @@ def create_mapped_properties(kls: Type[T], mapped_version: str):\\n         # loop over all named values found\\n         for attr in attrkey.split(','):\\n             # create read-only property that extracts the correct version number\\n-            # for a given release\\n+            # for a given release or returns a valid work version\\n             setattr(kls, attr, property(lambda self: get_mapped_version(\\n-                kls.mapped_version, release=self.release, key=attr)))\\n+                kls.mapped_version, release=self.release, key=attr) or self._version.get(attr, None)))\\n \\n \\n @register\\n\",\"diff --git a/python/sdss_brain/helpers/io.py b/python/sdss_brain/helpers/io.py\\nindex b87095a..c8d8585 100644\\n--- a/python/sdss_brain/helpers/io.py\\n+++ b/python/sdss_brain/helpers/io.py\\n@@ -61,6 +61,9 @@ def get_mapped_version(name: str, release: str = None, key: str = None) -> Union\\n         >>> get_mapped_version('manga', release='DR16', key='drpver')\\n             'v2_4_3'\\n     '''\\n+    # if release is a work release, return nothing\\n+    if release.lower() == 'work':\\n+        return None\\n \\n     # get the mapped_versions attribute from the configuration\\n     mapped_versions = config._custom_config.get('mapped_versions', None)\\n@@ -80,7 +83,8 @@ def get_mapped_version(name: str, release: str = None, key: str = None) -> Union\\n     release = release or config.release\\n     version = versions.get(release, None)\\n     if not version:\\n-        raise ValueError(f'no version found for release {release} in {name}')\\n+        raise ValueError(f'no mapped_version found for release {release} in {name}. '\\n+                         'Check the sdss_brain.yml config file.')\\n \\n     # check for a specific key in the version dictionary\\n     if key and type(version) == dict:\\n\",\"diff --git a/python/sdss_brain/helpers/parsing.py b/python/sdss_brain/helpers/parsing.py\\nindex b1a236d..5ce1982 100644\\n--- a/python/sdss_brain/helpers/parsing.py\\n+++ b/python/sdss_brain/helpers/parsing.py\\n@@ -14,6 +14,7 @@\\n from __future__ import print_function, division, absolute_import\\n import re\\n import pathlib\\n+import warnings\\n from typing import Match, Pattern, Union\\n from itertools import groupby\\n from sdss_brain import log\\n@@ -183,7 +184,7 @@ def parse_data_input(value: str, regex: str = None, keys: list = None, keymap: d\\n \\n     # if no match, assume value is a filename and return nothing\\n     if not pattern_match:\\n-        log.warning('No pattern match found.  Defaulting to input value as a filename.')\\n+        warnings.warn('No pattern match found.  Defaulting to input value as a filename.')\\n         if inputs:\\n             return {'filename': value, 'parsed_inputs': input_patts}\\n         return {'filename': value}\\n\",\"diff --git a/python/sdss_brain/mixins/access.py b/python/sdss_brain/mixins/access.py\\nindex 15960be..5692033 100644\\n--- a/python/sdss_brain/mixins/access.py\\n+++ b/python/sdss_brain/mixins/access.py\\n@@ -14,6 +14,7 @@\\n from __future__ import print_function, division, absolute_import\\n import abc\\n import time\\n+import warnings\\n from functools import wraps\\n from typing import Type\\n \\n@@ -60,7 +61,11 @@ def set_access(func):\\n     def wrapper(*args, **kwargs):\\n         inst = args[0]\\n         isset = inst._access is not None\\n-        diffrelease = inst.release.lower() != inst._access.release if isset else None\\n+        # see if the instance release is different than the access release\\n+        if 'work' in inst.release.lower():\\n+            diffrelease = 'sdsswork' != inst._access.release if isset else None\\n+        else:\\n+            diffrelease = inst.release.lower() != inst._access.release if isset else None\\n         if not isset or diffrelease:\\n             inst._access = create_new_access(inst.release)\\n         return func(*args, **kwargs)\\n@@ -85,9 +90,9 @@ def check_access_params(func):\\n         assert getattr(inst, 'path_params'), 'the path_params attribute cannot be None'\\n         assert type(inst.path_params) == dict, 'the path_params attribute must be a dictionary'\\n         if inst.filename is None and not all(inst.path_params.values()):\\n-            log.warning('Not all path_params are set.  Check how path_params are set '\\n-                        'or for a mismatch between path_params and any extracted parameters '\\n-                        'from _parse_input.  Ensuring any None path_params are set as strings')\\n+            warnings.warn('Not all path_params are set.  Check how path_params are set '\\n+                          'or for a mismatch between path_params and any extracted parameters '\\n+                          'from _parse_input.  Ensuring any None path_params are set as strings')\\n             inst.path_params = dict(zip(inst.path_params.keys(), map(str, inst.path_params.values())))\\n         return func(*args, **kwargs)\\n     return wrapper\\n@@ -189,13 +194,13 @@ class AccessMixIn(abc.ABC):\\n             else:\\n                 fullpath = self.access.full(self.path_name, **self.path_params)\\n         except TypeError as ee:\\n-            log.warning(msg + 'Error: {0}'.format(str(ee)), BrainUserWarning)\\n+            warnings.warn(msg + 'Error: {0}'.format(str(ee)), BrainUserWarning)\\n             raise BrainError(f'Bad input type for sdss_access: {ee}') from ee\\n         except Exception as ee:\\n-            log.warning(msg + 'Error: {0}'.format(str(ee)), BrainUserWarning)\\n+            warnings.warn(msg + 'Error: {0}'.format(str(ee)), BrainUserWarning)\\n         return fullpath\\n \\n-    def _setup_access(self, params: dict = None) -> None:\\n+    def _setup_access(self, params: dict = None, origin: str = None) -> None:\\n         ''' Set up the initial access parameters\\n \\n         Sets up an initial default path_params dictionary.  Given a provided `path_name`\\n@@ -207,8 +212,12 @@ class AccessMixIn(abc.ABC):\\n         ----------\\n             params : dict\\n                 A dictionary of access path params\\n+            origin : str\\n+                Indicates the origin of the content calling this method. Either \\\"file\\\" or \\\"object\\\"\\n         '''\\n \\n+        assert origin in [None, 'file', 'object'], 'origin can only be file or object'\\n+\\n         # do nothing if no path_name set\\n         if not hasattr(self, 'path_name') or not self.path_name:\\n             return\\n@@ -217,21 +226,47 @@ class AccessMixIn(abc.ABC):\\n         keys = self.access.lookup_keys(self.path_name)\\n         log.debug(f\\\"setting up initial access keys for {keys} for {self.path_name}\\\")\\n         for k in keys:\\n-            # skip if a class attribute already exists\\n-            if hasattr(self.__class__, k):\\n-                continue\\n+            # look up a possible work version\\n+            work_ver = self._version.get(k, None)\\n+            vmsg = ('Version extracted from file is different than your preset \\\"work\\\" '\\n+                    f'version for {k}. Consider updating the configured work version or '\\n+                    'specifying an input version.')\\n \\n             # look for a default value\\n             default = self._path_defaults.get(k, None) if hasattr(\\n                 self, '_path_defaults') else None\\n \\n-            # set attributes on the instance\\n+            # set the work version as default if no default found\\n+            if not default and work_ver and origin == 'object':\\n+                default = work_ver\\n+\\n+            # get the attribute value to set\\n             if params:\\n                 if type(params) != dict:\\n                     raise TypeError('the path_params attribute must be a dictionary')\\n-                setattr(self, k, params.get(k, default))\\n+\\n+                # check if work_ver should supersede the path_param\\n+                if origin == 'object' and work_ver:\\n+                    params[k] = work_ver\\n+\\n+                attr_value = params.get(k, default)\\n             else:\\n-                setattr(self, k, default)\\n+                attr_value = default\\n+\\n+            # skip if a class attribute already exists\\n+            if hasattr(self.__class__, k):\\n+                # but first check the work version and issue a warning if there mismatch is found\\n+                if work_ver and origin == 'file' and work_ver != attr_value:\\n+                    warnings.warn(vmsg)\\n+                continue\\n+\\n+            # set attributes on the instance\\n+            setattr(self, k, attr_value)\\n+\\n+            # issue a warning if the preset work version mismatches from the one\\n+            # extracted from the file\\n+            if origin == 'file' and work_ver and work_ver != getattr(self, k, None):\\n+                warnings.warn(vmsg)\\n \\n         # create a default path params dictionary\\n         self.path_params = {k: getattr(self, k) for k in keys}\\n\",\"diff --git a/python/sdss_brain/mixins/mma.py b/python/sdss_brain/mixins/mma.py\\nindex 5c7adf8..a098c33 100644\\n--- a/python/sdss_brain/mixins/mma.py\\n+++ b/python/sdss_brain/mixins/mma.py\\n@@ -17,6 +17,7 @@ import abc\\n import six\\n import pathlib\\n import os\\n+import warnings\\n \\n from sdss_brain import log\\n from sdss_brain.mixins.access import AccessMixIn\\n@@ -204,8 +205,14 @@ class MMAMixIn(abc.ABC):\\n             raise BrainError('no inputs defined. filename and objectid are both None')\\n \\n         # convert filename to a pathlib.Path and resolve a relative name\\n+        # not using pathlib.resolve to preserve symlinks\\n         if self.filename:\\n-            self.filename = pathlib.Path(self.filename).resolve()\\n+            self.filename = pathlib.Path(os.path.abspath(self.filename))\\n+            # issue a warning if the release is not indicated in the filename; possible mismatch\\n+            if self.release.lower() not in self.filename.as_posix():\\n+                warnings.warn('Your filename may not match the release indicated.  Path parameters '\\n+                              'may not be extracted properly.  Try setting the release to match the '\\n+                              'known file version.')\\n \\n         # attempt to update the access path parameters from the filename or parsed data input\\n         self._update_access_params(params=parsed_input)\\n@@ -267,14 +274,14 @@ class MMAMixIn(abc.ABC):\\n                 # attempt to extract the path_params from the filename\\n                 params = self.access.extract(self.path_name, self.filename)\\n                 if params:\\n-                    self._setup_access(params)\\n+                    self._setup_access(params, origin='file')\\n             elif self.objectid:\\n                 # set attributes from extracted parse_input\\n                 self._set_parsed_attributes(params)\\n                 # run the set_access_path_params method\\n                 self._set_access_path_params()\\n                 # set attributes from the path_params\\n-                self._setup_access(self.path_params)\\n+                self._setup_access(self.path_params, origin='object')\\n         elif not self.is_access_mixedin and params:\\n             # for non-access, set attributes from extracted parse_input\\n             self._set_parsed_attributes(params)\\n@@ -300,6 +307,11 @@ class MMAMixIn(abc.ABC):\\n             if hasattr(self.__class__, key):\\n                 continue\\n \\n+            # if a work version is set for the given key, and no value is set, then\\n+            # use the work version\\n+            work_ver = self._version.get(key, None)\\n+            val = work_ver if work_ver and val is None else val\\n+\\n             setattr(self, key, val)\\n \\n \\n\",\"diff --git a/python/sdss_brain/tools/spectra.py b/python/sdss_brain/tools/spectra.py\\nindex 6dc7406..a5ab607 100644\\n--- a/python/sdss_brain/tools/spectra.py\\n+++ b/python/sdss_brain/tools/spectra.py\\n@@ -13,6 +13,8 @@\\n \\n from __future__ import print_function, division, absolute_import\\n \\n+import warnings\\n+\\n try:\\n     import matplotlib.pyplot as plt\\n except ImportError:\\n@@ -21,7 +23,6 @@ from astropy.io.registry import IORegistryError\\n from specutils import Spectrum1D\\n from typing import Type\\n \\n-from sdss_brain import log\\n from sdss_brain.core import Brain\\n from sdss_brain.exceptions import BrainNotImplemented, BrainMissingDependency\\n from sdss_brain.helpers import (sdss_loader, get_mapped_version, load_fits_file, parse_data_input,\\n@@ -63,23 +64,75 @@ class Spectrum(Brain):\\n             # check robustness of this to self.data/self.filename when specutils 1.1.1 is released\\n             self.spectrum = Spectrum1D.read(self.data, format=self.specutils_format)\\n         except IORegistryError:\\n-            log.warning('Could not load Spectrum1D for format '\\n-                        f'{self.specutils_format}, {self.filename}')\\n-\\n-    def plot(self, ax=None, x_label: str = 'Wavelength', y_label: str = 'Flux', title: str = None,\\n-             **kwargs):\\n-        ''' A simple quick matplotlib plot of the spectrum'''\\n+            warnings.warn('Could not load Spectrum1D for format '\\n+                          f'{self.specutils_format}, {self.filename}')\\n+\\n+    def plot(self, *args, ax=None, x_label: str = 'Wavelength', y_label: str = 'Flux',\\n+             title: str = None, **kwargs):\\n+        \\\"\\\"\\\" A simple quick matplotlib plot of the spectrum\\n+\\n+        Create a quickplot matplotlib line profile plot for spectra\\n+\\n+        Parameters\\n+        ----------\\n+        args : int|list, optional\\n+            for multi-dimensional spectra, the index to plot, by default None\\n+        ax : object, optional\\n+            An existing matplotlib Axes object by default None\\n+        x_label : str, optional\\n+            The x-axis plot label, by default 'Wavelength'\\n+        y_label : str, optional\\n+            The y-axis plot label, by default 'Flux'\\n+        title : str, optional\\n+            The plot title, by default None\\n+\\n+        Returns\\n+        -------\\n+        matplotlib.plt.Axes\\n+            The matplotlib Axes object\\n+\\n+        Raises\\n+        ------\\n+        BrainMissingDependency\\n+            when matplotlib is not installed\\n+        \\\"\\\"\\\"\\n         if not self.spectrum:\\n             return\\n \\n         if not plt:\\n             raise BrainMissingDependency(\\\"Package matplotlib not installed.\\\")\\n \\n+        if self.spectrum.flux.ndim > 1:\\n+            index = args\\n+            if not index:\\n+                raise ValueError('The spectrum is n-dimensional.  You must specify a spectrum '\\n+                                 'index to plot.')\\n+\\n+            if not all([type(i) == int for i in index]):\\n+                raise ValueError('Input spectrum indices must be integers')\\n+\\n+            min_index = self.spectrum.flux.ndim - 1\\n+            index = index if isinstance(index, (tuple, list)) else [index] if type(index) == int else index\\n+            if len(index) < min_index:\\n+                raise ValueError(f'The spectrum has dimension={self.spectrum.flux.ndim}. '\\n+                                 f'You must specify a minimum of {min_index} indices')\\n+\\n+            if min_index == 1:\\n+                ii = index[0]\\n+                ydata = self.spectrum.flux[ii]\\n+            elif min_index == 2:\\n+                ii, jj = index\\n+                ydata = self.spectrum.flux[ii, jj]\\n+            else:\\n+                raise ValueError('plot cannot currently support spectral dimensions higher than 3')\\n+        else:\\n+            ydata = self.spectrum.flux\\n+\\n         if not ax:\\n             ax = plt.gca()\\n \\n         title = title or f'Object: {self.objectid or self.filename.stem}'\\n-        ax.plot(self.spectrum.wavelength, self.spectrum.flux, **kwargs)\\n+        ax.plot(self.spectrum.wavelength, ydata, **kwargs)\\n         ax.set_ylabel(f'{y_label} [{self.spectrum.flux.unit.to_string(format=\\\"latex_inline\\\")}]')\\n         ax.set_xlabel(f'{x_label} [{self.spectrum.wavelength.unit.to_string(format=\\\"latex_inline\\\")}]')\\n         ax.set_title(title)\\n@@ -142,8 +195,8 @@ class AspcapStar(Spectrum):\\n \\n     def _set_access_path_params(self):\\n         # extract the apred version id based on the data release\\n-        apred = get_mapped_version(self.mapped_version, release=self.release)\\n+        apred = get_mapped_version(self.mapped_version, release=self.release, key='apred')\\n \\n         # set the path params using the instance attributes extracted from _parse_input\\n         self.path_params = {'telescope': self.telescope, 'apred': apred,\\n-                            'field': self.field, 'obj': self.objectid, 'aspcap': self.aspcap}\\n+                            'field': self.field, 'obj': self.obj, 'aspcap': self.aspcap}\\n\"]", "test_patch": "[\"diff --git a/.github/workflows/release.yml b/.github/workflows/release.yml\\nnew file mode 100644\\nindex 0000000..9a90c61\\n--- /dev/null\\n+++ b/.github/workflows/release.yml\\n@@ -0,0 +1,49 @@\\n+on:\\n+    push:\\n+        # Sequence of patterns matched against refs/tags\\n+        tags:\\n+            - \\\"[0-9]+.[0-9]+.[0-9]+\\\"  # Exclude pre-releases\\n+\\n+name: Create Release\\n+\\n+jobs:\\n+    build:\\n+\\n+        runs-on: ubuntu-latest\\n+\\n+        steps:\\n+\\n+            - name: Checkout code\\n+              uses: actions/checkout@v2\\n+\\n+            - name: Create Release\\n+              id: create_release\\n+              uses: actions/create-release@v1\\n+              env:\\n+                  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # This token is provided by Actions, you do not need to create your own token\\n+              with:\\n+                  tag_name: ${{ github.ref }}\\n+                  release_name: Brain ${{ github.ref }}\\n+                  body:\\n+                  draft: true\\n+                  prerelease: false\\n+\\n+            - name: Set up Python\\n+              uses: actions/setup-python@v2\\n+              with:\\n+                  python-version: 3.7\\n+\\n+            - name: Install dependencies\\n+              run: |\\n+                python -m pip install --upgrade pip\\n+                pip install setuptools wheel twine\\n+\\n+            - name: Build package\\n+              run: |\\n+                python setup.py sdist bdist_wheel --universal\\n+\\n+            - name: Publish to PyPI\\n+              uses: pypa/gh-action-pypi-publish@v1\\n+              with:\\n+                  user: __token__\\n+                  password: ${{ secrets.pypi_password }}\\n\",\"diff --git a/.github/workflows/sphinxbuild.yml b/.github/workflows/sphinxbuild.yml\\ndeleted file mode 100644\\nindex 4177d12..0000000\\n--- a/.github/workflows/sphinxbuild.yml\\n+++ /dev/null\\n@@ -1,34 +0,0 @@\\n-# This is a basic workflow to help you get started with Actions\\n-\\n-name: Build Sphinx Documentation\\n-\\n-# Controls when the action will run. Triggers the workflow on push or pull request\\n-# events but only for the master branch\\n-on:\\n-  push:\\n-    branches: [ master, spectrum ]\\n-  pull_request:\\n-    branches: [ master ]\\n-\\n-# A workflow run is made up of one or more jobs that can run sequentially or in parallel\\n-jobs:\\n-  # This workflow contains a single job called \\\"build\\\"\\n-  build:\\n-    # The type of runner that the job will run on\\n-    runs-on: ubuntu-latest\\n-\\n-    # Steps represent a sequence of tasks that will be executed as part of the job\\n-    steps:\\n-    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it\\n-    - uses: actions/checkout@v2\\n-\\n-    # Run a sphinx build test\\n-    - name: Sphinx Build\\n-      uses: ammaraskar/sphinx-action@0.4\\n-      with:\\n-        # The folder containing your sphinx docs.\\n-        docs-folder: \\\"docs/sphinx/\\\"  # default is docs/\\n-        # The command used to build your documentation.\\n-        build-command: make html  # optional, default is make html\\n-        # Pre-build command\\n-        pre-build-command: \\\"apt-get update -y && apt-get install -y gcc && pip install .[docs]\\\"\\n\",\"diff --git a/python/sdss_brain/config.py b/python/sdss_brain/config.py\\nindex 707b549..25d9f1a 100644\\n--- a/python/sdss_brain/config.py\\n+++ b/python/sdss_brain/config.py\\n@@ -24,14 +24,20 @@ class Config(object):\\n         self._release = None\\n         self.download = False\\n         self.ignore_db = False\\n+        self.work_versions = None\\n+\\n+        # load default config parameters\\n+        self._load_defaults()\\n \\n         # get allowed releases from the Tree\\n         self._allowed_releases = tree.get_available_releases()\\n-        # set latest release\\n-        self.release = self._get_latest_release()\\n \\n-        # load default config parameters\\n-        self._load_defaults()\\n+        # set a default release or get the latest one\\n+        default_release = self._custom_config.get('default_release', None)\\n+        self.release = default_release or self._get_latest_release()\\n+\\n+        # set any work versions from the config\\n+        self.set_work_versions()\\n \\n     def __repr__(self):\\n         return f'<SDSSConfig(release={self.release}, mode={self.mode})>'\\n@@ -54,8 +60,8 @@ class Config(object):\\n     def release(self, value: str) -> None:\\n         value = value.upper()\\n         if value not in self._allowed_releases:\\n-            raise BrainError('trying to set an invalid release version. Valid releases are: {0}'\\n-                             .format(', '.join(self._allowed_releases)))\\n+            raise BrainError(f'trying to set an invalid release version {value}. '\\n+                             f'Valid releases are: {\\\", \\\".join(self._allowed_releases)}')\\n \\n         # replant the tree\\n         if value.lower() == 'work':\\n@@ -98,6 +104,34 @@ class Config(object):\\n \\n         self._custom_config = cfg_params\\n \\n+    def set_work_versions(self, values: dict = {}):\\n+        \\\"\\\"\\\" Set the versions used for sdsswork\\n+\\n+        Sets the versions used by sdswork globally into the config.\\n+        Input is a valid dictionary containing version names and numbers as\\n+        key value pairs, e.g. `{'drpver':'v2_4_3', 'run2d':'v1_1_1', 'apred':'r12'}`.\\n+        Optionally can set them permanently in the custom configuration YAML file.\\n+\\n+        The input dictionary is merged with any values specified from the custom config.\\n+\\n+        Parameters\\n+        ----------\\n+        values : dict, optional\\n+            Dictionary of version names:numbers needed in paths, by default {}\\n+\\n+        Raises\\n+        ------\\n+        ValueError\\n+            when the input is not a dictionary\\n+        \\\"\\\"\\\"\\n+\\n+        if type(values) != dict:\\n+            raise ValueError('input versions must be a dict')\\n+\\n+        cfg_work = self._custom_config.get('work_versions', {})\\n+        cfg_work.update(values)\\n+        self.work_versions = cfg_work\\n+\\n \\n config = Config()\\n \\n\",\"diff --git a/setup.cfg b/setup.cfg\\nindex df0321b..84c4d7e 100644\\n--- a/setup.cfg\\n+++ b/setup.cfg\\n@@ -108,6 +108,7 @@ max-line-length = 99\\n addopts = --cov sdss_brain --cov-report html -W ignore\\n markers =\\n \\tdatasource: marks tests as needing data from a given source\\n+\\tuse_data: marks test to load a specific test data\\n \\n [coverage:run]\\n branch = true\\n\",\"diff --git a/tests/conftest.py b/tests/conftest.py\\nindex bb8d2b7..e8f26f2 100644\\n--- a/tests/conftest.py\\n+++ b/tests/conftest.py\\n@@ -3,6 +3,7 @@\\n #\\n # conftest.py\\n \\n+import copy\\n import pytest\\n import os\\n import six\\n@@ -42,7 +43,7 @@ def check_path(item):\\n         path = item\\n     else:\\n         dataobj = check_class(item)\\n-        path = dataobj.get_full_path()\\n+        path = dataobj.filename or dataobj.get_full_path()\\n \\n     if not os.path.exists(path):\\n         pytest.skip('No local file found.')\\n@@ -158,6 +159,7 @@ class ToyNoAccess(mma.MMAMixIn):\\n class Toy(MockMMA):\\n     ''' toy object to utilize in tests '''\\n     path_name = 'toy'\\n+    _version = {}\\n \\n     def _parse_input(self, value):\\n         data = {'filename': None, 'objectid': None}\\n@@ -228,12 +230,61 @@ def get_object(name):\\n     return objects.get(name, None)\\n \\n \\n-def get_path(name):\\n+def create_work_version(work, data):\\n+    \\\"\\\"\\\" create object data using an input work_version\\\"\\\"\\\"\\n+    new = copy.deepcopy(data)\\n+    workc = copy.deepcopy(work)\\n+    key = list(workc.keys())[0]\\n+    new['path'] = new['path'].replace(new['params'][key], workc[key])\\n+    new['version_info'] = dict(zip(('name', 'number'), list(workc.items())[0]))\\n+    new['version'].update(workc)\\n+    new['params'].update(workc)\\n+    new['release'] = 'WORK'\\n+    return new\\n+\\n+\\n+def create_releases(name):\\n+    \\\"\\\"\\\" extract an entry from the objects.yaml and reorganize by release \\\"\\\"\\\"\\n+    data = get_object(name)\\n+    if not data:\\n+        return None\\n+\\n+    data = copy.deepcopy(data)\\n+\\n+    # pop out the works\\n+    works = data.pop('work_version', None)\\n+\\n+    # create a dictionary of the object parameters with release as the key\\n+    dd = {}\\n+    dd[data.get('release', 'DR15')] = data\\n+\\n+    if works:\\n+        # add any other work objects found\\n+        for work in works:\\n+            work_object = create_work_version(work, data)\\n+            dd[f\\\"WORK-{work_object['version_info']['number']}\\\"] = work_object\\n+\\n+    # expand the path envvars\\n+    for k, v in dd.items():\\n+        release = 'WORK' if 'WORK' in k else k\\n+        tree.replant_tree(release.lower())\\n+        dd[k]['path'] = os.path.expandvars(v.get('path', ''))\\n+\\n+    return dd\\n+\\n+\\n+# create a global dictionary of releases\\n+object_data = {}\\n+for name, data in objects.items():\\n+    object_data[name] = create_releases(name)\\n+\\n+\\n+def get_path(name, work=None):\\n     ''' Function to return a path name '''\\n     path = None\\n     data = get_object(name)\\n     if data:\\n-        release = data.get('release', 'DR15')\\n+        release = 'WORK' if work else data.get('release', 'DR15')\\n         tree.replant_tree(release.lower())\\n         path = os.path.expandvars(data.get('path', ''))\\n     return path\\n\",\"diff --git a/tests/data/objects.yaml b/tests/data/objects.yaml\\nindex 8a6c16c..9e7fc18 100644\\n--- a/tests/data/objects.yaml\\n+++ b/tests/data/objects.yaml\\n@@ -2,4 +2,47 @@\\n cube:\\n   objectid: 8485-1901\\n   release: DR15\\n+  version: {drpver: v2_4_3}\\n   path: $MANGA_SPECTRO_REDUX/v2_4_3/8485/stack/manga-8485-1901-LOGCUBE.fits.gz\\n+  params: {plate: '8485', ifu: '1901', wave: LOG, drpver: v2_4_3}\\n+  work_version:\\n+    - {drpver: v2_4_3}\\n+    - {drpver: v2_7_1}\\n+eboss:\\n+  objectid: 3606-55182-0537\\n+  release: DR14\\n+  version: {run2d: v5_10_0}\\n+  path: $BOSS_SPECTRO_REDUX/v5_10_0/spectra/lite/3606/spec-3606-55182-0537.fits\\n+  params: {run2d: v5_10_0, plateid: '3606', mjd: '55182', fiberid: '0537'}\\n+  work_version:\\n+    - {run2d: v5_13_0}\\n+    - {run2d: v5_10_0}\\n+apstar:\\n+  objectid: apo25m--006+02--2M17480803-2235257\\n+  release: DR16\\n+  version: {apred: r12}\\n+  path: $APOGEE_REDUX/r12/stars/apo25m/006+02/apStar-r12-2M17480803-2235257.fits\\n+  params: {prefix: ap, field: 006+02, obj: 2M17480803-2235257, telescope: apo25m, apred: r12, apstar: stars}\\n+  work_version:\\n+    - {apred: r12}\\n+    - {apred: r13}\\n+apvisit:\\n+  objectid: apo25m--159+39_MGA--10001--57372--001\\n+  release: DR16\\n+  version: {apred: r12}\\n+  path: $APOGEE_REDUX/r12/visit/apo25m/159+39_MGA/10001/57372/apVisit-r12-10001-57372-001.fits\\n+  params: {plate: '10001', mjd: '57372', fiber: '001', field: 159+39_MGA, telescope: apo25m, apred: r12, prefix: ap}\\n+  work_version:\\n+    - {apred: r12}\\n+    - {apred: r13}\\n+aspcap:\\n+  objectid: l33--apo25m--159+39_MGA--2M08463782+5729103\\n+  release: DR16\\n+  version: {apred: r12}\\n+  path: $APOGEE_ASPCAP/r12/l33/apo25m/159+39_MGA/aspcapStar-r12-2M08463782+5729103.fits\\n+  params: {aspcap: l33, field: 159+39_MGA, obj: 2M08463782+5729103, telescope: apo25m, apred: r12}\\n+  work_version:\\n+    - {apred: r12}\\n+    - {apred: r13}\\n+\\n+\\n\",\"diff --git a/tests/test_config.py b/tests/test_config.py\\nindex 3e9d77f..6adc07f 100644\\n--- a/tests/test_config.py\\n+++ b/tests/test_config.py\\n@@ -1,6 +1,6 @@\\n # !/usr/bin/env python\\n # -*- coding: utf-8 -*-\\n-# \\n+#\\n # Filename: test_config.py\\n # Project: tests\\n # Author: Brian Cherinka\\n@@ -26,22 +26,23 @@ def mockedcfg(monkeypatch):\\n     ''' fixture to return a mocked Config with modified cfg_params '''\\n     monkeypatch.setitem(cfg_params, 'ignore_db', True)\\n     monkeypatch.setitem(cfg_params, 'download', True)\\n+    monkeypatch.setitem(cfg_params, 'work_versions', {})\\n     config = Config()\\n     yield config\\n     config = None\\n \\n \\n class TestConfig(object):\\n-    \\n+\\n     def test_release_fail(self):\\n         with pytest.raises(BrainError) as cm:\\n             config.release = 'DR4'\\n-        assert 'trying to set an invalid release version.' in str(cm.value)\\n-    \\n+        assert 'trying to set an invalid release version' in str(cm.value)\\n+\\n     def test_set_release_fail(self):\\n         with pytest.raises(BrainError) as cm:\\n             config.set_release('DR4')\\n-        assert 'trying to set an invalid release version.' in str(cm.value)\\n+        assert 'trying to set an invalid release version' in str(cm.value)\\n \\n     def test_set_release(self):\\n         old = 'DR16'\\n@@ -62,6 +63,11 @@ class TestConfig(object):\\n     def test_update_cfg(self, mockedcfg):\\n         assert config.ignore_db is False\\n         assert mockedcfg.ignore_db is True\\n-        \\n+\\n         assert config.download is False\\n         assert mockedcfg.download is True\\n+\\n+    def test_set_work_versions(self, mockedcfg):\\n+        exp = {'drpver': 'v2_4_3', 'apred': 'r12'}\\n+        config.set_work_versions(exp)\\n+        assert config.work_versions == exp\\n\",\"diff --git a/tests/test_params.py b/tests/test_params.py\\nindex a18e31a..584f239 100644\\n--- a/tests/test_params.py\\n+++ b/tests/test_params.py\\n@@ -26,6 +26,7 @@ from sdss_brain.helpers import get_mapped_version, parse_data_input, parser_load\\n \\n #\\n # These tests for proper parameter extraction and instance attribute application\\n+# for different definitions of the _parse_input method\\n #\\n \\n cube_file = '/Users/Brian/Work/sdss/sas/dr15/manga/spectro/redux/v2_4_3/8485/stack/manga-8485-1901-LOGCUBE.fits.gz'\\n@@ -161,6 +162,7 @@ def asserts(cube):\\n     assert hasattr(cube, 'wave') and cube.wave == params['wave']\\n     assert hasattr(cube, 'drpver') and cube.drpver == params['drpver']\\n     assert hasattr(cube, 'path_params') and cube.path_params == params\\n+    assert getattr(cube, 'drpver') == cube.path_params['drpver']\\n \\n \\n @pytest.mark.parametrize('name',\\n\",\"diff --git a/tests/test_versions.py b/tests/test_versions.py\\nindex 2f314f1..3ee566f 100644\\n--- a/tests/test_versions.py\\n+++ b/tests/test_versions.py\\n@@ -70,5 +70,5 @@ class TestMappingFails(object):\\n             get_mapped_version(self.name, release=self.release)\\n \\n     def test_bad_release(self):\\n-        with pytest.raises(ValueError, match='no version found for release'):\\n+        with pytest.raises(ValueError, match='no mapped_version found for release'):\\n             get_mapped_version(self.name, release='badrelease')\\n\",\"diff --git a/tests/tools/__init__.py b/tests/tools/__init__.py\\nnew file mode 100644\\nindex 0000000..e0e44ab\\n--- /dev/null\\n+++ b/tests/tools/__init__.py\\n@@ -0,0 +1,14 @@\\n+# !/usr/bin/env python\\n+# -*- coding: utf-8 -*-\\n+#\\n+# Filename: __init__.py\\n+# Project: tools\\n+# Author: Brian Cherinka\\n+# Created: Thursday, 15th October 2020 3:31:32 pm\\n+# License: BSD 3-clause \\\"New\\\" or \\\"Revised\\\" License\\n+# Copyright (c) 2020 Brian Cherinka\\n+# Last Modified: Thursday, 15th October 2020 3:31:32 pm\\n+# Modified By: Brian Cherinka\\n+\\n+\\n+from __future__ import print_function, division, absolute_import\\n\",\"diff --git a/tests/tools/conftest.py b/tests/tools/conftest.py\\nnew file mode 100644\\nindex 0000000..04cdc03\\n--- /dev/null\\n+++ b/tests/tools/conftest.py\\n@@ -0,0 +1,158 @@\\n+# !/usr/bin/env python\\n+# -*- coding: utf-8 -*-\\n+#\\n+# Filename: conftest.py\\n+# Project: tools\\n+# Author: Brian Cherinka\\n+# Created: Thursday, 15th October 2020 3:31:39 pm\\n+# License: BSD 3-clause \\\"New\\\" or \\\"Revised\\\" License\\n+# Copyright (c) 2020 Brian Cherinka\\n+# Last Modified: Thursday, 15th October 2020 3:31:39 pm\\n+# Modified By: Brian Cherinka\\n+\\n+\\n+from __future__ import print_function, division, absolute_import\\n+import pytest\\n+import pathlib\\n+from sdss_brain.config import config\\n+from tests.conftest import object_data, check_path\\n+\\n+\\n+@pytest.fixture()\\n+def use_test_data(request):\\n+    marker = request.node.get_closest_marker(\\\"use_test_data\\\")\\n+\\n+    if marker is None:\\n+        # Handle missing marker in some way...\\n+        name = None\\n+    else:\\n+        name = marker.args[0]\\n+\\n+    data = object_data.get(name, None)\\n+\\n+    # get keywords\\n+    skip = marker.kwargs.get('skip_missing', None)\\n+    fake = marker.kwargs.get('fake_missing', None)\\n+\\n+    # construct the path\\n+    release = request.getfixturevalue('release')\\n+    path = pathlib.Path(data[release]['path'])\\n+    exists = path.is_file()\\n+\\n+    # skip the data\\n+    if skip:\\n+        check_path(str(path))\\n+\\n+    # fake the data\\n+    if fake and not exists:\\n+        path.parent.mkdir(parents=True, exist_ok=True)\\n+        path.write_text('fake file')\\n+\\n+    # Do something with the data\\n+    yield data\\n+\\n+    # clean up the fake file\\n+    if fake and not exists:\\n+        path.unlink()\\n+\\n+\\n+@pytest.fixture()\\n+def expdata(release, use_test_data):\\n+    data = use_test_data.get(release, None)\\n+    new = data.copy()\\n+    yield new\\n+\\n+\\n+def get_mocked(kls):\\n+    ''' get a mocked tools class '''\\n+    class Mocked(kls):\\n+        def _load_spectrum(self):\\n+            pass\\n+\\n+        def _load_object_from_file(self, data):\\n+            pass\\n+\\n+        def _load_object_from_file(self, data):\\n+            pass\\n+\\n+        def _load_object_from_api(self):\\n+            pass\\n+\\n+    return Mocked\\n+\\n+\\n+class WorkTests(object):\\n+    \\\"\\\"\\\" Class that tests that the class attributes and path_params\\n+\\n+    This class tests that a Brain sub-class sets instance attributes and path_params\\n+    properly and that they are consistent with each other.  This works for a given release\\n+    or for work versions.\\n+    \\\"\\\"\\\"\\n+    version = None\\n+    mock = None\\n+\\n+    def assert_file(self, inst, path):\\n+        assert inst.filename is not None\\n+        assert inst.objectid is None\\n+        assert str(inst.filename) == path\\n+\\n+    def assert_objectid(self, inst, oid):\\n+        assert inst.objectid is not None\\n+        assert str(inst.objectid) == oid\\n+\\n+    def assert_params(self, inst, data):\\n+        assert inst.release == data['release']\\n+        assert inst.path_params == data['params']\\n+        assert getattr(inst, self.version) == inst.path_params[self.version]\\n+        for param, val in inst.path_params.items():\\n+            assert getattr(inst, param) == val\\n+\\n+    def test_as_filename(self, monkeypatch, expdata):\\n+        \\\"\\\"\\\" tests explicit filename input \\\"\\\"\\\"\\n+        monkeypatch.setattr(config, 'work_versions', {self.version: 'v1_1_1'})\\n+        version = expdata['version'] if 'WORK' in expdata['release'] else None\\n+        inst = self.mock(filename=expdata['path'], release=expdata['release'], version=version)\\n+        self.assert_file(inst, expdata['path'])\\n+        self.assert_params(inst, expdata)\\n+\\n+    #@pytest.mark.parametrize('noversion', [(True), (False)], ids=['noversion', 'explicit_version'])\\n+    def test_as_fileinput(self, monkeypatch, expdata):#, noversion):\\n+        \\\"\\\"\\\" tests filename as data input \\\"\\\"\\\"\\n+        monkeypatch.setattr(config, 'work_versions', {self.version: 'v1_1_1'})\\n+        version = expdata['version'] if 'WORK' in expdata['release'] else None\\n+        #version = None if noversion else version\\n+        inst = self.mock(expdata['path'], release=expdata['release'], version=version)\\n+        self.assert_file(inst, expdata['path'])\\n+        self.assert_params(inst, expdata)\\n+\\n+    def test_fileinput_workver_warning(self, monkeypatch, expdata):\\n+        \\\"\\\"\\\" temporary tests to check mismatch between filename version and work version\\n+\\n+        When filename input is different version than work_version and no explicit version\\n+        is set, tool loads the file correctly but path params are incorrect\\n+\\n+        if ever fixed then update the test and above test\\n+        \\\"\\\"\\\"\\n+        monkeypatch.setattr(config, 'work_versions', {self.version: 'v1_1_1'})\\n+        if expdata['release'] != 'WORK':\\n+            pytest.skip('skipping non-work releases')\\n+\\n+        if 'aspcap' in expdata['params']:\\n+            pytest.xfail('manually defined ascap fails this test due to setting correct versions')\\n+\\n+        with pytest.warns(UserWarning) as record:\\n+            inst = self.mock(expdata['path'], release=expdata['release'])\\n+\\n+        assert ('Version extracted from file is different '\\n+                'than your preset \\\"work\\\" version') in str(record[0].message)\\n+        self.assert_file(inst, expdata['path'])\\n+\\n+        assert getattr(inst, self.version) not in inst.filename.as_posix()\\n+\\n+    def test_as_objectid(self, expdata):\\n+        \\\"\\\"\\\" tests object id as data input \\\"\\\"\\\"\\n+        s = expdata['objectid']\\n+        version = expdata['version'] if 'WORK' in expdata['release'] else None\\n+        inst = self.mock(s, release=expdata['release'], version=version)\\n+        self.assert_objectid(inst, s)\\n+        self.assert_params(inst, expdata)\\n\",\"diff --git a/tests/tools/test_apogee.py b/tests/tools/test_apogee.py\\nnew file mode 100644\\nindex 0000000..99bbd50\\n--- /dev/null\\n+++ b/tests/tools/test_apogee.py\\n@@ -0,0 +1,44 @@\\n+# !/usr/bin/env python\\n+# -*- coding: utf-8 -*-\\n+#\\n+# Filename: test_apogee.py\\n+# Project: tools\\n+# Author: Brian Cherinka\\n+# Created: Thursday, 15th October 2020 10:25:18 pm\\n+# License: BSD 3-clause \\\"New\\\" or \\\"Revised\\\" License\\n+# Copyright (c) 2020 Brian Cherinka\\n+# Last Modified: Thursday, 15th October 2020 10:25:18 pm\\n+# Modified By: Brian Cherinka\\n+\\n+\\n+from __future__ import print_function, division, absolute_import\\n+import pytest\\n+from sdss_brain.tools.spectra import ApStar, ApVisit, AspcapStar\\n+from .conftest import WorkTests, get_mocked\\n+from tests.conftest import object_data\\n+\\n+\\n+releases = object_data.get('apstar').keys()\\n+\\n+\\n+@pytest.fixture(scope='class', params=releases)\\n+def release(request):\\n+    yield request.param\\n+\\n+\\n+@pytest.mark.use_test_data('apstar', fake_missing=True)\\n+class TestApStarWorkVersions(WorkTests):\\n+    mock = get_mocked(ApStar)\\n+    version = 'apred'\\n+\\n+\\n+@pytest.mark.use_test_data('apvisit', fake_missing=True)\\n+class TestApVisitWorkVersions(WorkTests):\\n+    mock = get_mocked(ApVisit)\\n+    version = 'apred'\\n+\\n+\\n+@pytest.mark.use_test_data('aspcap', fake_missing=True)\\n+class TestAspcapStarWorkVersions(WorkTests):\\n+    mock = get_mocked(AspcapStar)\\n+    version = 'apred'\\n\",\"diff --git a/tests/tools/test_eboss.py b/tests/tools/test_eboss.py\\nnew file mode 100644\\nindex 0000000..1bf45c1\\n--- /dev/null\\n+++ b/tests/tools/test_eboss.py\\n@@ -0,0 +1,55 @@\\n+# !/usr/bin/env python\\n+# -*- coding: utf-8 -*-\\n+#\\n+# Filename: test_eboss.py\\n+# Project: tools\\n+# Author: Brian Cherinka\\n+# Created: Thursday, 15th October 2020 3:32:23 pm\\n+# License: BSD 3-clause \\\"New\\\" or \\\"Revised\\\" License\\n+# Copyright (c) 2020 Brian Cherinka\\n+# Last Modified: Thursday, 15th October 2020 3:32:23 pm\\n+# Modified By: Brian Cherinka\\n+\\n+\\n+from __future__ import print_function, division, absolute_import\\n+import pytest\\n+from sdss_brain.tools.spectra import Eboss\\n+from sdss_brain.config import config\\n+from sdss_brain.exceptions import BrainError\\n+from .conftest import WorkTests, get_mocked\\n+from tests.conftest import object_data\\n+\\n+\\n+releases = object_data.get('eboss').keys()\\n+\\n+\\n+@pytest.fixture(params=releases)\\n+def release(request):\\n+    yield request.param\\n+\\n+\\n+@pytest.mark.use_test_data('eboss', fake_missing=True)\\n+class TestEbossWorkVersions(WorkTests):\\n+    mock = get_mocked(Eboss)\\n+    version = 'run2d'\\n+\\n+    def test_set_work_version(self, monkeypatch):\\n+        monkeypatch.setattr(config, 'work_versions', {})\\n+        monkeypatch.setattr(Eboss, '_version', None)\\n+        assert config.work_versions == {}\\n+        assert getattr(Eboss, '_version') is None\\n+        ver = {'run2d': 'v5_10_0'}\\n+        Eboss.set_work_version(ver)\\n+        assert Eboss._version == {'run2d': 'v5_10_0'}\\n+\\n+\\n+class TestEbossWorkFails(object):\\n+\\n+    def test_no_work_version_set(self, monkeypatch):\\n+        monkeypatch.setattr(config, 'work_versions', {})\\n+        with pytest.raises(BrainError, match='You are using a \\\"work\\\" release but have no work versions set!*'):\\n+            Eboss('3606-55182-0537', release='WORK')\\n+\\n+    def test_release_version_set(self):\\n+        with pytest.raises(BrainError, match='version is only used for \\\"work\\\" data.'):\\n+            Eboss('3606-55182-0537', release='DR14', version={'run2d': 'v5_10_0'})\\n\",\"diff --git a/tests/tools/test_manga.py b/tests/tools/test_manga.py\\nnew file mode 100644\\nindex 0000000..160a759\\n--- /dev/null\\n+++ b/tests/tools/test_manga.py\\n@@ -0,0 +1,34 @@\\n+# !/usr/bin/env python\\n+# -*- coding: utf-8 -*-\\n+#\\n+# Filename: test_manga.py\\n+# Project: tools\\n+# Author: Brian Cherinka\\n+# Created: Thursday, 15th October 2020 5:07:11 pm\\n+# License: BSD 3-clause \\\"New\\\" or \\\"Revised\\\" License\\n+# Copyright (c) 2020 Brian Cherinka\\n+# Last Modified: Thursday, 15th October 2020 5:07:11 pm\\n+# Modified By: Brian Cherinka\\n+\\n+\\n+from __future__ import print_function, division, absolute_import\\n+import pytest\\n+from sdss_brain.tools.cubes import MangaCube\\n+from .conftest import WorkTests, get_mocked\\n+from tests.conftest import object_data\\n+\\n+\\n+releases = object_data.get('cube').keys()\\n+\\n+\\n+@pytest.fixture(scope='class', params=releases)\\n+def release(request):\\n+    yield request.param\\n+\\n+\\n+@pytest.mark.use_test_data('cube', fake_missing=True)\\n+class TestMangaWorkVerions(WorkTests):\\n+    mock = get_mocked(MangaCube)\\n+    version = 'drpver'\\n+\\n+\"]", "hints_text": ""}
