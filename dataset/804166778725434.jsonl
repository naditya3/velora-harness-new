{"instance_id": "804166778725434", "repo": "arminwitte/binarybeech", "base_commit": "1415c5b62fea370757a6369d6481d27112127800", "problem_statement": "Implement AdaBoost:\\n", "FAIL_TO_PASS": ["tests/test_math.py::test_gini_impurity_weighted", "tests/test_math.py::test_shannon_entropy_weighted", "tests/test_math.py::test_misclassification_cost_weighted", "tests/test_math.py::test_mean_squared_error_weighted", "tests/test_math.py::test_unique_weighted"], "PASS_TO_PASS": ["tests/test_math.py::test_shannon_entropy_histogram", "tests/test_minimizer.py::test_scalarsimulatedannealing_choice", "tests/test_math.py::test_proximity_matrix", "tests/test_minimizer.py::test_scalarsimulatedannealing", "tests/test_minimizer.py::test_minimize", "tests/test_datamanager.py::test_datamanager_info", "tests/test_tree.py::test_tree_parent", "tests/test_minimizer.py::test_brentsscalarminimizer", "tests/test_tree.py::test_tree_to_json", "tests/test_utils.py::test_model_missings", "tests/test_trainingdata.py::test_training_data_split", "tests/test_tree.py::test_node", "tests/test_trainingdata.py::test_training_data", "tests/test_tree.py::test_tree", "tests/test_math.py::test_distance_matrix", "tests/test_reporter.py::test_reporter", "tests/test_math.py::test_valley"], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/arminwitte_binarybeech:1415c5b62fea370757a6369d6481d27112127800", "patch": "", "test_patch": "[\"diff --git a/tests/test_adaboost.py b/tests/test_adaboost.py\\nnew file mode 100644\\nindex 0000000..e47d7d4\\n--- /dev/null\\n+++ b/tests/test_adaboost.py\\n@@ -0,0 +1,27 @@\\n+import numpy as np\\n+import pandas as pd\\n+\\n+from binarybeech.binarybeech import AdaBoostTree\\n+from binarybeech.tree import Tree\\n+\\n+\\n+def test_adaboost_iris():\\n+    df_iris = pd.read_csv(\\\"data/iris.csv\\\")\\n+    c = AdaBoostTree(df=df_iris, y_name=\\\"species\\\", method=\\\"classification\\\")\\n+    c.train(100)\\n+    p = c.predict(df_iris)\\n+    val = c.validate()\\n+    acc = val[\\\"accuracy\\\"]\\n+    np.testing.assert_array_equal(p[:10], [\\\"setosa\\\"] * 10)\\n+    assert acc <= 1.0 and acc > 0.98\\n+\\n+\\n+def test_adaboost_titanic():\\n+    df_titanic = pd.read_csv(\\\"data/titanic.csv\\\")\\n+    c = AdaBoostTree(df=df_titanic, y_name=\\\"Survived\\\", method=\\\"classification\\\")\\n+    c.train(100)\\n+    p = c.predict(df_titanic)\\n+    val = c.validate()\\n+    acc = val[\\\"accuracy\\\"]\\n+    np.testing.assert_allclose(p[:10], [0, 1, 1, 1, 0, 0, 0, 0, 1, 1])\\n+    assert acc < 1.0 and acc > 0.80\\n\",\"diff --git a/tests/test_housing.py b/tests/test_housing.py\\nindex 1efa2c5..997b6e2 100644\\n--- a/tests/test_housing.py\\n+++ b/tests/test_housing.py\\n@@ -70,16 +70,16 @@ def test_housing_gradientboostedtree():\\n     np.testing.assert_allclose(\\n         p[:10],\\n         [\\n-            8592267.945129,\\n-            10237830.012832,\\n-            9640255.985793,\\n-            10180136.420183,\\n-            8935277.254079,\\n-            9116677.826144,\\n-            10391172.19137,\\n-            7823996.050055,\\n-            9012873.652479,\\n-            7790072.066678,\\n+            8801218.895703,\\n+            10775516.637133,\\n+            10085858.184785,\\n+            9840551.810912,\\n+            8338360.153133,\\n+            8876988.814029,\\n+            11119599.903721,\\n+            9731685.064304,\\n+            8656771.468612,\\n+            8211774.820057,\\n         ],\\n         # rtol=1e-2,\\n     )\\n\",\"diff --git a/tests/test_iris.py b/tests/test_iris.py\\nindex ce82200..ce8eaa0 100644\\n--- a/tests/test_iris.py\\n+++ b/tests/test_iris.py\\n@@ -36,45 +36,58 @@ def test_iris_randomforest():\\n     acc = val[\\\"accuracy\\\"]\\n     np.testing.assert_array_equal(p[:10], [\\\"setosa\\\"] * 10)\\n     assert acc <= 1.0 and acc > 0.9\\n-    \\n+\\n \\n def test_iris_from_dict():\\n     df_iris = pd.read_csv(\\\"data/iris.csv\\\")\\n     c = CART(df=df_iris, y_name=\\\"species\\\", method=\\\"classification\\\")\\n     c.create_tree()\\n-    \\n+\\n     tree_dict = c.tree.to_dict()\\n     assert isinstance(tree_dict, dict)\\n-    \\n+\\n     tree = Tree.from_dict(tree_dict)\\n     assert isinstance(tree, Tree)\\n     assert len(tree.nodes()) == 21\\n     assert tree.leaf_count() == 11\\n-        \\n-    \\n+\\n     c.tree = tree\\n     p = c.predict(df_iris)\\n     val = c.validate()\\n     acc = val[\\\"accuracy\\\"]\\n     np.testing.assert_array_equal(p[:10], [\\\"setosa\\\"] * 10)\\n     assert acc <= 1.0 and acc > 0.95\\n-    \\n+\\n+\\n def test_iris_from_json():\\n     df_iris = pd.read_csv(\\\"data/iris.csv\\\")\\n     c = CART(df=df_iris, y_name=\\\"species\\\", method=\\\"classification\\\", seed=42)\\n     c.train()\\n-    \\n+\\n     tree_json = c.tree.to_json()\\n     assert isinstance(tree_json, str)\\n-    \\n+\\n     tree = Tree.from_json(string=tree_json)\\n     assert isinstance(tree, Tree)\\n     assert len(tree.nodes()) == 5\\n     assert tree.leaf_count() == 3\\n-    \\n+\\n     c.tree = tree\\n     p = c.predict(df_iris)\\n     val = c.validate()\\n     acc = val[\\\"accuracy\\\"]\\n     np.testing.assert_array_equal(p[:10], [\\\"setosa\\\"] * 10)\\n-    assert acc <= 1.0 and acc > 0.95\\n\\\\ No newline at end of file\\n+    assert acc <= 1.0 and acc > 0.95\\n+\\n+\\n+def test_iris_cart_create_weighted():\\n+    df_iris = pd.read_csv(\\\"data/iris.csv\\\")\\n+    df_iris[\\\"__weights__\\\"] = 1\\n+    df_iris[df_iris[\\\"species\\\"] == \\\"versicolor\\\"][\\\"__weights__\\\"] = 3\\n+    c = CART(df=df_iris, y_name=\\\"species\\\", method=\\\"classification\\\")\\n+    c.create_tree()\\n+    p = c.predict(df_iris)\\n+    val = c.validate()\\n+    acc = val[\\\"accuracy\\\"]\\n+    np.testing.assert_array_equal(p[:10], [\\\"setosa\\\"] * 10)\\n+    assert acc <= 1.0 and acc > 0.95\\n\",\"diff --git a/tests/test_math.py b/tests/test_math.py\\nindex e9c708e..0eb88a7 100644\\n--- a/tests/test_math.py\\n+++ b/tests/test_math.py\\n@@ -42,3 +42,45 @@ def test_shannon_entropy_histogram():\\n     H = math.shannon_entropy_histogram(x)\\n \\n     assert H == -15642.544876423011\\n+\\n+\\n+def test_unique_weighted():\\n+    x = [\\\"A\\\"] * 5 + [\\\"B\\\"] * 4 + [\\\"C\\\"] * 3 + [\\\"A\\\"] * 2 + [\\\"B\\\"] * 1\\n+    w = np.linspace(0, 1, num=len(x))\\n+    unique, share = math.unique_weighted(x, w)\\n+    np.testing.assert_array_equal(unique, [\\\"A\\\", \\\"B\\\", \\\"C\\\"])\\n+    print(share)\\n+    np.testing.assert_allclose(share, [0.33333333, 0.38095238, 0.28571429])\\n+\\n+\\n+def test_gini_impurity_weighted():\\n+    x = [\\\"A\\\"] * 5 + [\\\"B\\\"] * 4 + [\\\"C\\\"] * 3 + [\\\"A\\\"] * 2 + [\\\"B\\\"] * 1\\n+    w = np.linspace(0, 1, num=len(x))\\n+    loss = math.gini_impurity_weighted(x, w)\\n+    print(loss)\\n+    np.testing.assert_allclose(loss, [0.6621315192743764])\\n+\\n+\\n+def test_shannon_entropy_weighted():\\n+    x = [\\\"A\\\"] * 5 + [\\\"B\\\"] * 4 + [\\\"C\\\"] * 3 + [\\\"A\\\"] * 2 + [\\\"B\\\"] * 1\\n+    w = np.linspace(0, 1, num=len(x))\\n+    loss = math.shannon_entropy_weighted(x, w)\\n+    # print(\\\"shannon\\\", loss)\\n+    np.testing.assert_allclose(loss, [1.575114591410657])\\n+\\n+\\n+def test_misclassification_cost_weighted():\\n+    x = [\\\"A\\\"] * 5 + [\\\"B\\\"] * 4 + [\\\"C\\\"] * 3 + [\\\"A\\\"] * 2 + [\\\"B\\\"] * 1\\n+    w = np.linspace(0, 1, num=len(x))\\n+    loss = math.misclassification_cost_weighted(x, w)\\n+    print(\\\"miss\\\", loss)\\n+    np.testing.assert_allclose(loss, [0.6190476190476191])\\n+\\n+\\n+def test_mean_squared_error_weighted():\\n+    x = np.linspace(0, 1, 50)\\n+    y = np.linspace(0.1, 1.2, 50)\\n+    w = np.linspace(0.5, 5, 50)\\n+    mse = math.mean_squared_error_weighted(x, y, w)\\n+    print(\\\"mse\\\", mse)\\n+    np.testing.assert_allclose(mse, [0.2833752029341517])\\n\",\"diff --git a/tests/test_reporter.py b/tests/test_reporter.py\\nindex 6b2895b..69bd92e 100644\\n--- a/tests/test_reporter.py\\n+++ b/tests/test_reporter.py\\n@@ -1,8 +1,18 @@\\n-from binarybeech.reporter import Reporter\\n+from binarybeech.reporter import Reporter, reporter\\n+\\n+\\n+def test_reporter_class():\\n+    reporter = Reporter()    \\n+    reporter.reset([\\\"col1\\\", \\\"col2\\\"])\\n+    for i in range(10):\\n+        reporter[\\\"col1\\\"] = i\\n+        reporter[\\\"col2\\\"] = i**2\\n+        reporter.print()\\n+    assert 0 == 0\\n \\n \\n def test_reporter():\\n-    reporter = Reporter([\\\"col1\\\", \\\"col2\\\"])\\n+    reporter.reset([\\\"col1\\\", \\\"col2\\\"])\\n     for i in range(10):\\n         reporter[\\\"col1\\\"] = i\\n         reporter[\\\"col2\\\"] = i**2\\n\",\"diff --git a/tests/test_titanic.py b/tests/test_titanic.py\\nindex 75ac357..cd2f813 100644\\n--- a/tests/test_titanic.py\\n+++ b/tests/test_titanic.py\\n@@ -11,7 +11,7 @@ def test_titanic_cart_create():\\n     p = c.predict(df_titanic)\\n     val = c.validate()\\n     acc = val[\\\"accuracy\\\"]\\n-    np.testing.assert_allclose(p[:10], [0, 1, 0, 1, 0, 0, 0, 0, 1, 1])\\n+    np.testing.assert_allclose(p[:10], [0, 1, 1, 1, 0, 0, 0, 0, 1, 1])\\n     assert acc < 1.0 and acc > 0.78\\n \\n \\n\",\"diff --git a/tests/test_titanic_update.py b/tests/test_titanic_update.py\\nindex 3c39962..3994594 100644\\n--- a/tests/test_titanic_update.py\\n+++ b/tests/test_titanic_update.py\\n@@ -1,7 +1,7 @@\\n import numpy as np\\n import pandas as pd\\n \\n-from binarybeech.binarybeech import CART, GradientBoostedTree, RandomForest\\n+from binarybeech.binarybeech import GradientBoostedTree\\n \\n \\n def test_titanic_update_elastic():\\n@@ -32,6 +32,7 @@ def test_titanic_update_elastic():\\n     )\\n     assert acc < 1.0 and acc > 0.8\\n \\n+\\n def test_titanic_update_gamma():\\n     df_titanic = pd.read_csv(\\\"data/titanic.csv\\\").sample(\\n         frac=1.0, replace=False, random_state=42\\n\",\"diff --git a/tests/test_tree.py b/tests/test_tree.py\\nindex fedcd40..0397d45 100644\\n--- a/tests/test_tree.py\\n+++ b/tests/test_tree.py\\n@@ -19,6 +19,7 @@ def test_tree():\\n     assert t.traverse({\\\"var\\\": 0.0}).value == 1\\n     assert t.traverse({\\\"var\\\": 1.0}).value == 2\\n \\n+\\n def test_tree_parent():\\n     n1 = Node(value=1)\\n     n2 = Node(value=2)\\n@@ -33,19 +34,20 @@ def test_tree_parent():\\n     t = Tree(root=n0)\\n     assert isinstance(t.traverse({\\\"var\\\": 0.0}).parent, Node)\\n     assert len(t.leafs()) == 2\\n-    \\n+\\n+\\n def test_tree_to_json():\\n     def decfun(x, y):\\n         return x < y\\n+\\n     n1 = Node(value=1)\\n     n2 = Node(value=2)\\n     n0 = Node(\\n         attribute=\\\"var\\\",\\n         threshold=0.5,\\n         branches=[n1, n2],\\n-        decision_fun = decfun,\\n+        decision_fun=decfun,\\n     )\\n     t = Tree(root=n0)\\n-    \\n-    assert isinstance(t.to_json(),str)\\n \\n+    assert isinstance(t.to_json(), str)\\n\",\"diff --git a/tests/test_visualize.py b/tests/test_visualize.py\\nindex f16be13..62fe5a8 100644\\n--- a/tests/test_visualize.py\\n+++ b/tests/test_visualize.py\\n@@ -1,8 +1,12 @@\\n-import numpy as np\\n import pandas as pd\\n \\n from binarybeech.binarybeech import CART\\n-from binarybeech.visualize import plot_areas, plot_pruning_quality, extract_rules, print_rules\\n+from binarybeech.visualize import (\\n+    extract_rules,\\n+    plot_areas,\\n+    plot_pruning_quality,\\n+    print_rules,\\n+)\\n \\n \\n def test_plot_areas():\\n@@ -17,16 +21,17 @@ def test_plot_pruning_quality():\\n     c = CART(df=df_iris, y_name=\\\"species\\\", method=\\\"classification\\\", seed=42)\\n     c.train()\\n     assert isinstance(c.pruning_quality, dict)\\n-    \\n+\\n+\\n def test_print_rules():\\n     df_iris = pd.read_csv(\\\"data/iris.csv\\\")\\n     c = CART(df=df_iris, y_name=\\\"species\\\", method=\\\"classification\\\", seed=42)\\n     c.train()\\n     rules = extract_rules(c.tree)\\n-    assert isinstance(rules,dict)\\n-    \\n+    assert isinstance(rules, dict)\\n+\\n     s = print_rules(rules)\\n     print(s)\\n-    \\n-    assert isinstance(s,str)\\n-    assert s.split()[0] == \\\"setosa\\\"\\n\\\\ No newline at end of file\\n+\\n+    assert isinstance(s, str)\\n+    assert s.split()[0] == \\\"setosa\\\"\"]", "hints_text": ""}
