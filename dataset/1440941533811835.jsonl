{"instance_id": "1440941533811835", "repo": "datajunction/dj", "base_commit": "283bbcbbed04307c4b8c8b6b79d3e7d28924e0dd", "problem_statement": "Build queries for multiple metrics:\\nBuild a single query for multiple metrics. Should validate that the dimensions + filters are compatible before doing so.", "FAIL_TO_PASS": ["tests/api/cubes_test.py::test_cube_sql", "tests/api/cubes_test.py::test_create_invalid_cube", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_upsert_materialization_config", "tests/api/cubes_test.py::test_raise_on_cube_with_multiple_catalogs", "tests/api/cubes_test.py::test_read_cube"], "PASS_TO_PASS": ["tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query28.sql]", "tests/api/nodes_test.py::TestValidateNodes::test_allowing_missing_parents_for_draft_nodes", "tests/sql/functions_test.py::test_ceil[types2-expected2]", "tests/models/query_test.py::test_encode_results_unknown", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query19.sql]", "tests/api/tags_test.py::TestTags::test_list_tags", "tests/sql/functions_test.py::test_avg", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_updating_node_to_invalid_draft", "tests/sql/parsing/test_ast.py::test_ast_compile_lateral_view_explode7", "tests/construction/inference_test.py::test_raising_when_select_has_multiple_expressions_in_projection", "tests/construction/inference_test.py::test_infer_values", "tests/api/data_test.py::TestAvailabilityState::test_merging_in_a_higher_max_partition", "tests/construction/inference_test.py::test_infer_types_count", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query41.sql]", "tests/models/query_test.py::test_msgpack", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query6.sql]", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_update_nonexistent_node", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query54.sql]", "tests/construction/build_test.py::test_build_node_with_unnamed_column", "tests/sql/parsing/test_ast.py::test_ast_compile_lateral_view_explode1", "tests/api/sql_test.py::test_sql_with_filters_on_namespaced_nodes[foo.bar.municipality_dim-dimensions2-filters2-\\n", "tests/sql/functions_test.py::test_ceil[types1-expected1]", "tests/service_clients_test.py::TestQueryServiceClient::test_query_service_client_submit_query", "tests/construction/build_test.py::test_build_node[dbt.source.jaffle_shop.customers-None]", "tests/construction/compile_test.py::test_raise_on_having_without_a_groupby", "tests/api/data_test.py::TestDataForNode::test_get_metric_data", "tests/sql/parsing/test_ast.py::test_ast_compile_query_missing_columns", "tests/api/catalog_test.py::test_catalog_list", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query65.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query83.sql]", "tests/construction/build_test.py::test_build_node[dbt.transform.customer_agg-None]", "tests/construction/inference_test.py::test_raising_when_unop_bad_type", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query32.sql]", "tests/sql/functions_test.py::test_floor[types7-expected7]", "tests/construction/inference_test.py::test_infer_types_datetime", "tests/api/query_test.py::test_query_endpoint", "tests/construction/compile_test.py::test_catching_dangling_refs_in_extract_dependencies", "tests/sql/parsing/backends/types_test.py::test_types_compatible", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query57.sql]", "tests/sql/functions_test.py::test_min", "tests/api/attributes_test.py::test_adding_new_attribute", "tests/models/query_test.py::test_decode_results_unknown", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query31.sql]", "tests/construction/compile_test.py::test_raising_on_extract_from_node_with_no_query", "tests/construction/build_test.py::test_amenable_name", "tests/construction/compile_test.py::test_raise_on_unnamed_subquery_in_implicit_join", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_raise_on_multi_catalog_node", "tests/api/sql_test.py::test_sql_with_filters_on_namespaced_nodes[foo.bar.repair_orders-dimensions0-filters0-\\n", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query17.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query27.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query95.sql]", "tests/construction/compile_test.py::test_having", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query48.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query13.sql]", "tests/api/sql_test.py::test_sql_with_filters[municipality_dim-dimensions4-filters4-\\n", "tests/sql/parsing/test_ast.py::test_ast_compile_lateral_view_explode8", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query51.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query81.sql]", "tests/api/sql_test.py::test_sql", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query10.sql]", "tests/models/catalog_test.py::test_catalog_str_and_hash", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query88.sql]", "tests/api/nodes_test.py::TestValidateNodes::test_validating_an_invalid_node", "tests/construction/inference_test.py::test_infer_column_with_table", "tests/sql/functions_test.py::test_missing_functions", "tests/api/data_test.py::TestAvailabilityState::test_raising_if_availability_catalog_mismatch", "tests/api/namespaces_test.py::test_list_all_namespaces", "tests/models/node_test.py::test_extra_validation", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query77.sql]", "tests/sql/functions_test.py::test_count", "tests/api/catalog_test.py::test_catalog_adding_a_new_catalog_with_engines", "tests/utils_test.py::test_version_parse", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query68.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query58.sql]", "tests/construction/build_test.py::test_build_node[basic.source.comments-None]", "tests/sql/parse_test.py::test_is_metric", "tests/construction/exceptions_test.py::test_raise_compound_build_exception", "tests/api/sql_test.py::test_sql_with_filters_on_namespaced_nodes[foo.bar.num_repair_orders-dimensions5-filters5-\\n", "tests/api/sql_test.py::test_sql_with_filters[num_repair_orders-dimensions6-filters6-\\n", "tests/sql/functions_test.py::test_now", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_create_source_node_with_query_service", "tests/sql/functions_test.py::test_ceil[types9-expected9]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query97.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query26.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query23.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query42.sql]", "tests/sql/functions_test.py::test_floor[types5-expected5]", "tests/sql/functions_test.py::test_floor[types1-expected1]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query46.sql]", "tests/sql/functions_test.py::test_floor[types3-expected3]", "tests/sql/functions_test.py::test_coalesce_infer_type", "tests/api/nodes_test.py::TestValidateNodes::test_node_downstreams", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query39.sql]", "tests/sql/functions_test.py::test_floor[types0-expected0]", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_raise_on_source_node_with_no_catalog", "tests/api/helpers_test.py::test_get_dj_query", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query7.sql]", "tests/sql/parsing/test_ast.py::test_ast_compile_missing_references", "tests/sql/functions_test.py::test_ceil[types3-expected3]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query22.sql]", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_create_update_dimension_node", "tests/construction/build_test.py::test_build_node[basic.num_comments-None]", "tests/sql/parsing/backends/antlr4_test.py::test_antlr4_backend_trim", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query86.sql]", "tests/api/engine_test.py::test_engine_get_engine", "tests/errors_test.py::test_dj_exception", "tests/sql/parsing/backends/antlr4_test.py::test_antlr4_backend_lateral_view_explode[SELECT", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query11.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query38.sql]", "tests/construction/inference_test.py::test_infer_bad_case_types", "tests/models/hash_test.py::test_hash", "tests/construction/compile_test.py::test_raise_on_compile_node_with_no_query", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query91.sql]", "tests/api/sql_test.py::test_sql_with_filters_on_namespaced_nodes[foo.bar.num_repair_orders-dimensions4-filters4-\\n", "tests/construction/build_test.py::test_build_node[basic.dimension.users-None]", "tests/construction/compile_test.py::test_missing_references", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query61.sql]", "tests/sql/parsing/backends/antlr4_test.py::test_antlr4_backend_predicate_like", "tests/api/nodes_test.py::TestNodeColumnsAttributes::test_set_columns_attributes_failed", "tests/api/metrics_test.py::test_read_metrics", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query53.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query9.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query34.sql]", "tests/api/data_test.py::TestAvailabilityState::test_raising_when_node_does_not_exist", "tests/superset_test.py::test_select_star", "tests/api/metrics_test.py::test_common_dimensions", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query90.sql]", "tests/api/helpers_test.py::test_propagate_valid_status", "tests/construction/build_test.py::test_build_node[dbt.source.jaffle_shop.orders-None]", "tests/sql/functions_test.py::test_max", "tests/api/data_test.py::TestAvailabilityState::test_setting_availability_state", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query36.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query76.sql]", "tests/sql/parsing/test_ast.py::test_ast_compile_lateral_view_explode4", "tests/api/catalog_test.py::test_catalog_adding_a_new_catalog", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query5.sql]", "tests/utils_test.py::test_get_issue_url", "tests/api/tags_test.py::TestTags::test_create_and_read_tag", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query29.sql]", "tests/api/sql_test.py::test_sql_with_filters[long_events-dimensions3-filters3-\\n", "tests/sql/functions_test.py::test_ceil[types5-expected5]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query78.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query55.sql]", "tests/sql/parsing/test_ast.py::test_ast_compile_lateral_view_explode2", "tests/construction/inference_test.py::test_infer_types_str", "tests/sql/functions_test.py::test_to_date", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query74.sql]", "tests/sql/parsing/test_ast.py::test_ast_compile_raise_on_ambiguous_column", "tests/construction/compile_test.py::test_raise_on_unjoinable_automatic_dimension_groupby", "tests/api/data_test.py::TestDataForNode::test_get_dimension_data", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query71.sql]", "tests/api/sql_test.py::test_sql_with_filters[num_repair_orders-dimensions10-filters10-\\n", "tests/superset_test.py::test_get_metrics", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query64.sql]", "tests/api/health_test.py::test_failed_health", "tests/construction/inference_test.py::test_infer_types_avg", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query47.sql]", "tests/sql/functions_test.py::test_floor[types2-expected2]", "tests/utils_test.py::test_get_session", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query62.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query33.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query66.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query49.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query44.sql]", "tests/construction/build_test.py::test_raise_on_build_without_required_dimension_column", "tests/api/data_test.py::TestAvailabilityState::test_that_update_at_timestamp_is_being_updated", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query89.sql]", "tests/api/metrics_test.py::test_raise_common_dimensions_not_a_metric_node", "tests/api/tags_test.py::TestTags::test_update_tag", "tests/models/node_test.py::test_node_relationship", "tests/api/nodes_test.py::TestValidateNodes::test_adding_dimensions_to_node_columns", "tests/superset_test.py::test_execute", "tests/api/engine_test.py::test_engine_raise_on_engine_already_exists", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_create_dimension_node_fails", "tests/service_clients_test.py::TestQueryServiceClient::test_query_service_client_raising_error", "tests/api/data_test.py::TestDataForNode::test_get_source_data", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query25.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query30.sql]", "tests/construction/dj_query_test.py::test_build_dj_metric_query", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query16.sql]", "tests/construction/utils_test.py::test_get_dj_node_raise_unknown_node_exception", "tests/construction/build_test.py::test_build_node[dbt.dimension.customers-None]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query50.sql]", "tests/sql/parsing/test_ast.py::test_ast_compile_having", "tests/sql/functions_test.py::test_ceil[types8-expected8]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query99.sql]", "tests/api/sql_test.py::test_sql_with_filters_on_namespaced_nodes[foo.bar.num_repair_orders-dimensions3-filters3-\\n", "tests/sql/functions_test.py::test_bad_combo_types", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query37.sql]", "tests/api/sql_test.py::test_sql_with_filters[avg_repair_price-dimensions8-filters8-\\n", "tests/api/health_test.py::test_successful_health", "tests/api/catalog_test.py::test_catalog_adding_without_duplicating", "tests/sql/parsing/backends/antlr4_test.py::test_antlr4_backend_cross_join_unnest[Select", "tests/construction/inference_test.py::test_infer_map_subscripts", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query73.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query60.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query79.sql]", "tests/sql/functions_test.py::test_floor[types6-expected6]", "tests/api/data_test.py::TestAvailabilityState::test_setting_availability_state_multiple_times", "tests/construction/inference_test.py::test_infer_types_complicated", "tests/api/nodes_test.py::TestValidateNodes::test_raise_when_trying_to_validate_a_source_node", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query70.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query52.sql]", "tests/sql/functions_test.py::test_floor[types4-expected4]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query98.sql]", "tests/construction/inference_test.py::test_raising_when_expression_has_no_parent", "tests/api/data_test.py::TestAvailabilityState::test_raise_on_setting_invalid_availability_state_on_a_source_node", "tests/construction/build_test.py::test_build_node[basic.source.users-None]", "tests/api/engine_test.py::test_engine_adding_a_new_engine", "tests/sql/parsing/test_ast.py::test_ast_compile_lateral_view_explode3", "tests/sql/parsing/backends/antlr4_test.py::test_antlr4_lambda_function", "tests/construction/build_test.py::test_build_node[basic.num_users-None]", "tests/construction/inference_test.py::test_raise_on_invalid_infer_binary_op", "tests/api/helpers_test.py::test_raise_get_node_when_node_does_not_exist", "tests/construction/inference_test.py::test_raising_when_table_has_no_dj_node", "tests/service_clients_test.py::TestRequestsSessionWithEndpoint::test_prepare_request", "tests/api/metrics_test.py::test_read_metrics_errors", "tests/api/sql_test.py::test_lateral_view_explode", "tests/api/sql_test.py::test_sql_with_filters[num_repair_orders-dimensions5-filters5-\\n", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query2.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query56.sql]", "tests/sql/parsing/test_ast.py::test_ast_compile_query", "tests/service_clients_test.py::TestRequestsSessionWithEndpoint::test_make_requests", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query14.sql]", "tests/api/data_test.py::TestDataForNode::test_get_transform_data", "tests/utils_test.py::test_get_settings", "tests/construction/inference_test.py::test_column_type_validation", "tests/api/sql_test.py::test_cross_join_unnest", "tests/api/nodes_test.py::test_read_nodes", "tests/sql/functions_test.py::test_ceil[types7-expected7]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query59.sql]", "tests/api/sql_test.py::test_sql_with_filters[num_repair_orders-dimensions7-filters7-\\n", "tests/sql/parsing/backends/antlr4_test.py::test_antlr4_backend_predicate_ilike", "tests/api/attributes_test.py::test_list_attributes", "tests/sql/functions_test.py::test_floor[types9-expected9]", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_delete_node", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query87.sql]", "tests/api/engine_test.py::test_engine_list", "tests/sql/parsing/test_ast.py::test_ast_compile_table", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query8.sql]", "tests/migrations_test.py::test_migrations_are_current", "tests/sql/functions_test.py::test_ceil[types0-expected0]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query35.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query85.sql]", "tests/construction/compile_test.py::test_get_table_node_is_none", "tests/api/data_test.py::TestAvailabilityState::test_setting_availablity_state_on_a_source_node", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query93.sql]", "tests/api/sql_test.py::test_sql_with_filters[long_events-dimensions2-filters2-\\n", "tests/sql/functions_test.py::test_floor[types8-expected8]", "tests/api/sql_test.py::test_sql_with_filters[avg_repair_price-dimensions9-filters9-\\n", "tests/utils_test.py::test_setup_logging", "tests/api/catalog_test.py::test_catalog_get_catalog", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query94.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query82.sql]", "tests/api/nodes_test.py::TestNodeColumnsAttributes::test_set_columns_attributes", "tests/construction/compile_test.py::test_compile_node", "tests/api/metrics_test.py::test_get_dimensions", "tests/api/sql_test.py::test_sql_with_filters[repair_orders-dimensions1-filters1-\\n", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query24.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query1.sql]", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_create_invalid_transform_node", "tests/api/nodes_test.py::TestValidateNodes::test_validating_invalid_sql", "tests/api/nodes_test.py::test_node_similarity", "tests/api/catalog_test.py::test_catalog_raise_on_adding_a_new_catalog_with_nonexistent_engines", "tests/api/catalog_test.py::test_catalog_raise_on_catalog_already_exists", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_create_update_source_node", "tests/api/metrics_test.py::test_read_metric", "tests/sql/parsing/test_ast.py::test_ast_compile_table_missing_node", "tests/api/data_test.py::TestAvailabilityState::test_moving_back_valid_through_ts", "tests/sql/functions_test.py::test_ceil[types10-expected10]", "tests/sql/functions_test.py::test_sum", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_create_source_node_without_cols_or_query_service", "tests/sql/functions_test.py::test_ceil[types4-expected4]", "tests/sql/parsing/test_ast.py::test_ast_compile_lateral_view_explode6", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query72.sql]", "tests/sql/functions_test.py::test_ceil[types6-expected6]", "tests/api/namespaces_test.py::test_list_nodes_by_namespace", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query80.sql]", "tests/api/sql_test.py::test_sql_with_filters[repair_orders-dimensions0-filters0-\\n", "tests/construction/inference_test.py::test_infer_types_coalesce", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query18.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query63.sql]", "tests/construction/inference_test.py::test_infer_types_min_max_sum_ceil", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query12.sql]", "tests/sql/parsing/backends/antlr4_test.py::test_antlr4_backend_predicate_rlike", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query20.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query43.sql]", "tests/construction/build_test.py::test_build_metric_with_dimensions_filters", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query40.sql]", "tests/service_clients_test.py::TestQueryServiceClient::test_query_service_client_get_query", "tests/sql/functions_test.py::test_floor[types10-expected10]", "tests/construction/inference_test.py::test_infer_types_exp", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query15.sql]", "tests/construction/inference_test.py::test_infer_types_if", "tests/utils_test.py::test_get_query_service_client", "tests/api/sql_test.py::test_sql_with_filters_on_namespaced_nodes[foo.bar.repair_orders-dimensions1-filters1-\\n", "tests/api/data_test.py::TestDataForNode::test_get_dimension_data_failed", "tests/construction/build_test.py::test_build_node[basic.transform.country_agg-None]", "tests/api/sql_test.py::test_sql_with_filters_on_namespaced_nodes[foo.bar.avg_repair_price-dimensions6-filters6-\\n", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query4.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query3.sql]", "tests/construction/compile_test.py::test_raise_on_ambiguous_column", "tests/superset_test.py::test_get_view_names", "tests/construction/inference_test.py::test_infer_types_array_map", "tests/api/nodes_test.py::test_read_node", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query75.sql]", "tests/construction/build_test.py::test_build_node[basic.dimension.countries-None]", "tests/sql/parsing/test_ast.py::test_ast_compile_lateral_view_explode5", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query96.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query21.sql]", "tests/api/nodes_test.py::TestCreateOrUpdateNodes::test_create_update_transform_node", "tests/construction/build_test.py::test_build_metric_with_dimensions_aggs", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query45.sql]", "tests/api/nodes_test.py::TestValidateNodes::test_validating_with_missing_parents", "tests/api/catalog_test.py::test_catalog_adding_a_new_catalog_then_attaching_engines", "tests/api/nodes_test.py::test_resolving_downstream_status", "tests/construction/inference_test.py::test_infer_column_with_an_aliased_table", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query67.sql]", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query69.sql]", "tests/api/data_test.py::TestAvailabilityState::test_merging_in_a_lower_min_partition", "tests/service_clients_test.py::TestQueryServiceClient::test_query_service_client_get_columns_for_table", "tests/api/nodes_test.py::TestValidateNodes::test_validating_a_valid_node", "tests/api/metrics_test.py::test_raise_common_dimensions_metric_not_found", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query92.sql]", "tests/construction/inference_test.py::test_raising_when_between_different_types", "tests/utils_test.py::test_get_engine", "tests/sql/dag_test.py::test_get_dimensions", "tests/construction/exceptions_test.py::test_compound_build_exception", "tests/sql/parsing/queries/tpcds/test_tpcds.py::test_tpcds_ast_parse_comparisons[./sparksql/query84.sql]", "tests/sql/parsing/backends/antlr4_test.py::test_antlr4_backend_predicate_is_distinct_from", "tests/api/tags_test.py::TestTags::test_add_tag_to_node"], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/datajunction_dj:283bbcbbed04307c4b8c8b6b79d3e7d28924e0dd", "patch": "", "test_patch": "[\"diff --git a/tests/api/cubes_test.py b/tests/api/cubes_test.py\\nindex 761be5bc5..723289fbe 100644\\n--- a/tests/api/cubes_test.py\\n+++ b/tests/api/cubes_test.py\\n@@ -4,6 +4,8 @@\\n \\n from fastapi.testclient import TestClient\\n \\n+from tests.sql.utils import compare_query_strings\\n+\\n \\n def test_read_cube(client_with_examples: TestClient) -> None:\\n     \\\"\\\"\\\"\\n@@ -13,7 +15,9 @@ def test_read_cube(client_with_examples: TestClient) -> None:\\n     response = client_with_examples.post(\\n         \\\"/nodes/cube/\\\",\\n         json={\\n-            \\\"cube_elements\\\": [\\\"number_of_account_types\\\", \\\"account_type\\\"],\\n+            \\\"metrics\\\": [\\\"number_of_account_types\\\"],\\n+            \\\"dimensions\\\": [\\\"account_type.account_type_name\\\"],\\n+            \\\"filters\\\": [],\\n             \\\"description\\\": \\\"A cube of number of accounts grouped by account type\\\",\\n             \\\"mode\\\": \\\"published\\\",\\n             \\\"name\\\": \\\"number_of_accounts_by_account_type\\\",\\n@@ -25,7 +29,6 @@ def test_read_cube(client_with_examples: TestClient) -> None:\\n     assert data[\\\"type\\\"] == \\\"cube\\\"\\n     assert data[\\\"name\\\"] == \\\"number_of_accounts_by_account_type\\\"\\n     assert data[\\\"display_name\\\"] == \\\"Number Of Accounts By Account Type\\\"\\n-    assert data[\\\"query\\\"] is None\\n \\n     # Read the cube\\n     response = client_with_examples.get(\\\"/cubes/number_of_accounts_by_account_type\\\")\\n@@ -36,7 +39,28 @@ def test_read_cube(client_with_examples: TestClient) -> None:\\n     assert data[\\\"display_name\\\"] == \\\"Number Of Accounts By Account Type\\\"\\n     assert data[\\\"version\\\"] == \\\"v1.0\\\"\\n     assert data[\\\"description\\\"] == \\\"A cube of number of accounts grouped by account type\\\"\\n-    # Check that creating a cube with a query fails appropriately\\n+    assert compare_query_strings(\\n+        data[\\\"query\\\"],\\n+        \\\"\\\"\\\"\\n+        SELECT\\n+          account_type.account_type_name,\\n+          count(account_type.id) AS num_accounts\\n+        FROM (\\n+          SELECT\\n+            account_type_table.account_type_classification,\\n+            account_type_table.account_type_name,\\n+            account_type_table.id\\n+          FROM accounting.account_type_table AS account_type_table) AS account_type\\n+          GROUP BY\\n+            account_type.account_type_name\\n+        \\\"\\\"\\\",\\n+    )\\n+\\n+\\n+def test_create_invalid_cube(client_with_examples: TestClient):\\n+    \\\"\\\"\\\"\\n+    Check that creating a cube with a query fails appropriately\\n+    \\\"\\\"\\\"\\n     response = client_with_examples.post(\\n         \\\"/nodes/cube/\\\",\\n         json={\\n@@ -50,6 +74,21 @@ def test_read_cube(client_with_examples: TestClient) -> None:\\n     assert response.status_code == 422\\n     data = response.json()\\n     assert data[\\\"detail\\\"] == [\\n+        {\\n+            \\\"loc\\\": [\\\"body\\\", \\\"metrics\\\"],\\n+            \\\"msg\\\": \\\"field required\\\",\\n+            \\\"type\\\": \\\"value_error.missing\\\",\\n+        },\\n+        {\\n+            \\\"loc\\\": [\\\"body\\\", \\\"dimensions\\\"],\\n+            \\\"msg\\\": \\\"field required\\\",\\n+            \\\"type\\\": \\\"value_error.missing\\\",\\n+        },\\n+        {\\n+            \\\"loc\\\": [\\\"body\\\", \\\"cube_elements\\\"],\\n+            \\\"msg\\\": \\\"extra fields not permitted\\\",\\n+            \\\"type\\\": \\\"value_error.extra\\\",\\n+        },\\n         {\\n             \\\"loc\\\": [\\\"body\\\", \\\"query\\\"],\\n             \\\"msg\\\": \\\"extra fields not permitted\\\",\\n@@ -61,7 +100,8 @@ def test_read_cube(client_with_examples: TestClient) -> None:\\n     response = client_with_examples.post(\\n         \\\"/nodes/cube/\\\",\\n         json={\\n-            \\\"cube_elements\\\": [],\\n+            \\\"metrics\\\": [\\\"account_type\\\"],\\n+            \\\"dimensions\\\": [\\\"account_type.account_type_name\\\"],\\n             \\\"description\\\": \\\"A cube of number of accounts grouped by account type\\\",\\n             \\\"mode\\\": \\\"published\\\",\\n             \\\"name\\\": \\\"cubes_must_have_elements\\\",\\n@@ -70,7 +110,8 @@ def test_read_cube(client_with_examples: TestClient) -> None:\\n     assert response.status_code == 422\\n     data = response.json()\\n     assert data == {\\n-        \\\"message\\\": \\\"At least one metric is required to create a cube node\\\",\\n+        \\\"message\\\": \\\"Node account_type of type dimension cannot be added to a cube. \\\"\\n+        \\\"Did you mean to add a dimension attribute?\\\",\\n         \\\"errors\\\": [],\\n         \\\"warnings\\\": [],\\n     }\\n@@ -79,7 +120,8 @@ def test_read_cube(client_with_examples: TestClient) -> None:\\n     response = client_with_examples.post(\\n         \\\"/nodes/cube/\\\",\\n         json={\\n-            \\\"cube_elements\\\": [\\\"number_of_account_types\\\", \\\"account_type_table\\\"],\\n+            \\\"metrics\\\": [\\\"number_of_account_types\\\"],\\n+            \\\"dimensions\\\": [\\\"payment_type.payment_type_name\\\"],\\n             \\\"description\\\": \\\"\\\",\\n             \\\"mode\\\": \\\"published\\\",\\n             \\\"name\\\": \\\"cubes_cant_use_source_nodes\\\",\\n@@ -88,7 +130,8 @@ def test_read_cube(client_with_examples: TestClient) -> None:\\n     assert response.status_code == 422\\n     data = response.json()\\n     assert data == {\\n-        \\\"message\\\": \\\"Node account_type_table of type source cannot be added to a cube\\\",\\n+        \\\"message\\\": \\\"The dimension attribute `payment_type.payment_type_name` is not \\\"\\n+        \\\"available on every metric and thus cannot be included.\\\",\\n         \\\"errors\\\": [],\\n         \\\"warnings\\\": [],\\n     }\\n@@ -97,7 +140,8 @@ def test_read_cube(client_with_examples: TestClient) -> None:\\n     response = client_with_examples.post(\\n         \\\"/nodes/cube/\\\",\\n         json={\\n-            \\\"cube_elements\\\": [\\\"account_type\\\"],\\n+            \\\"metrics\\\": [],\\n+            \\\"dimensions\\\": [\\\"account_type.account_type_name\\\"],\\n             \\\"description\\\": \\\"\\\",\\n             \\\"mode\\\": \\\"published\\\",\\n             \\\"name\\\": \\\"cubes_must_have_metrics\\\",\\n@@ -115,7 +159,8 @@ def test_read_cube(client_with_examples: TestClient) -> None:\\n     response = client_with_examples.post(\\n         \\\"/nodes/cube/\\\",\\n         json={\\n-            \\\"cube_elements\\\": [\\\"number_of_account_types\\\"],\\n+            \\\"metrics\\\": [\\\"number_of_account_types\\\"],\\n+            \\\"dimensions\\\": [],\\n             \\\"description\\\": \\\"A cube of number of accounts grouped by account type\\\",\\n             \\\"mode\\\": \\\"published\\\",\\n             \\\"name\\\": \\\"cubes_must_have_dimensions\\\",\\n@@ -140,7 +185,8 @@ def test_raise_on_cube_with_multiple_catalogs(\\n     response = client_with_examples.post(\\n         \\\"/nodes/cube/\\\",\\n         json={\\n-            \\\"cube_elements\\\": [\\\"account_type\\\", \\\"basic.num_comments\\\"],\\n+            \\\"metrics\\\": [\\\"number_of_account_types\\\", \\\"basic.num_comments\\\"],\\n+            \\\"dimensions\\\": [\\\"account_type.account_type_name\\\"],\\n             \\\"description\\\": \\\"multicatalog cube's raise an error\\\",\\n             \\\"mode\\\": \\\"published\\\",\\n             \\\"name\\\": \\\"multicatalog\\\",\\n@@ -149,3 +195,101 @@ def test_raise_on_cube_with_multiple_catalogs(\\n     assert not response.ok\\n     data = response.json()\\n     assert \\\"Cannot create cube using nodes from multiple catalogs\\\" in data[\\\"message\\\"]\\n+\\n+\\n+def test_cube_sql(client_with_examples: TestClient):\\n+    \\\"\\\"\\\"\\n+    Test that the generated cube materialization SQL makes sense\\n+    \\\"\\\"\\\"\\n+    metrics_list = [\\\"num_repair_orders\\\", \\\"avg_repair_price\\\", \\\"total_repair_cost\\\"]\\n+\\n+    # Should fail because dimension attribute isn't available\\n+    response = client_with_examples.post(\\n+        \\\"/nodes/cube/\\\",\\n+        json={\\n+            \\\"metrics\\\": metrics_list,\\n+            \\\"dimensions\\\": [\\n+                \\\"contractor.company_name\\\",\\n+            ],\\n+            \\\"description\\\": \\\"Cube of various metrics related to repairs\\\",\\n+            \\\"mode\\\": \\\"published\\\",\\n+            \\\"name\\\": \\\"repairs_cube\\\",\\n+        },\\n+    )\\n+    assert response.json()[\\\"message\\\"] == (\\n+        \\\"The dimension attribute `contractor.company_name` is not available \\\"\\n+        \\\"on every metric and thus cannot be included.\\\"\\n+    )\\n+\\n+    # Should succeed\\n+    response = client_with_examples.post(\\n+        \\\"/nodes/cube/\\\",\\n+        json={\\n+            \\\"metrics\\\": metrics_list,\\n+            \\\"dimensions\\\": [\\n+                \\\"hard_hat.country\\\",\\n+                \\\"hard_hat.postal_code\\\",\\n+                \\\"hard_hat.city\\\",\\n+                \\\"hard_hat.state\\\",\\n+                \\\"dispatcher.company_name\\\",\\n+                \\\"municipality_dim.local_region\\\",\\n+            ],\\n+            \\\"description\\\": \\\"Cube of various metrics related to repairs\\\",\\n+            \\\"mode\\\": \\\"published\\\",\\n+            \\\"name\\\": \\\"repairs_cube\\\",\\n+        },\\n+    )\\n+    results = response.json()\\n+\\n+    assert results[\\\"name\\\"] == \\\"repairs_cube\\\"\\n+    assert results[\\\"display_name\\\"] == \\\"Repairs Cube\\\"\\n+    assert results[\\\"description\\\"] == \\\"Cube of various metrics related to repairs\\\"\\n+    expected_query = \\\"\\\"\\\"\\n+        SELECT\\n+          avg(price) AS avg_repair_price,\\n+          dispatcher.company_name,\\n+          hard_hat.city,\\n+          hard_hat.country,\\n+          hard_hat.postal_code,\\n+          hard_hat.state,\\n+          municipality_dim.local_region,\\n+          count(repair_orders.repair_order_id) AS num_repair_orders,\\n+          sum(price) AS total_repair_cost\\n+        FROM roads.repair_orders AS repair_orders\\n+        LEFT OUTER JOIN (\\n+          SELECT\\n+            dispatchers.company_name,\\n+            dispatchers.dispatcher_id\\n+          FROM roads.dispatchers AS dispatchers\\n+        ) AS dispatcher ON repair_orders.dispatcher_id = dispatcher.dispatcher_id\\n+        LEFT OUTER JOIN (\\n+          SELECT\\n+            hard_hats.city,\\n+            hard_hats.country,\\n+            hard_hats.hard_hat_id,\\n+            hard_hats.postal_code,\\n+            hard_hats.state\\n+          FROM roads.hard_hats AS hard_hats\\n+        ) AS hard_hat ON repair_orders.hard_hat_id = hard_hat.hard_hat_id\\n+        LEFT OUTER JOIN (\\n+          SELECT\\n+            municipality.local_region,\\n+            municipality.municipality_id\\n+          FROM roads.municipality AS municipality\\n+          LEFT JOIN roads.municipality_municipality_type AS municipality_municipality_type\\n+          ON municipality.municipality_id = municipality_municipality_type.municipality_id\\n+          LEFT JOIN roads.municipality_type AS municipality_type\\n+          ON municipality_municipality_type.municipality_type_id\\n+             = municipality_type.municipality_type_desc\\n+        ) AS municipality_dim\\n+        ON repair_orders.municipality_id = municipality_dim.municipality_id\\n+        GROUP BY\\n+          hard_hat.country,\\n+          hard_hat.postal_code,\\n+          hard_hat.city,\\n+          hard_hat.state,\\n+          dispatcher.company_name,\\n+          municipality_dim.local_region\\n+    \\\"\\\"\\\"\\n+    assert compare_query_strings(results[\\\"query\\\"], expected_query)\\n+    assert results[\\\"display_name\\\"] == \\\"Repairs Cube\\\"\\n\",\"diff --git a/tests/api/nodes_test.py b/tests/api/nodes_test.py\\nindex 73180f1a2..29a84191c 100644\\n--- a/tests/api/nodes_test.py\\n+++ b/tests/api/nodes_test.py\\n@@ -863,7 +863,8 @@ def test_upsert_materialization_config(  # pylint: disable=too-many-arguments\\n             json={\\n                 \\\"engine_name\\\": \\\"spark\\\",\\n                 \\\"engine_version\\\": \\\"2.4.4\\\",\\n-                \\\"config\\\": \\\"{}\\\",\\n+                \\\"schedule\\\": \\\"0 * * * *\\\",\\n+                \\\"config\\\": {},\\n             },\\n         )\\n         assert response.status_code == 400\\n@@ -875,7 +876,12 @@ def test_upsert_materialization_config(  # pylint: disable=too-many-arguments\\n         # Setting the materialization config for an engine that doesn't exist should fail\\n         response = client_with_examples.post(\\n             \\\"/nodes/basic.transform.country_agg/materialization/\\\",\\n-            json={\\\"engine_name\\\": \\\"spark\\\", \\\"engine_version\\\": \\\"2.4.4\\\", \\\"config\\\": \\\"{}\\\"},\\n+            json={\\n+                \\\"engine_name\\\": \\\"spark\\\",\\n+                \\\"engine_version\\\": \\\"2.4.4\\\",\\n+                \\\"config\\\": {},\\n+                \\\"schedule\\\": \\\"0 * * * *\\\",\\n+            },\\n         )\\n         assert response.status_code == 404\\n         data = response.json()\\n@@ -884,7 +890,11 @@ def test_upsert_materialization_config(  # pylint: disable=too-many-arguments\\n         # Create the engine and check the existing transform node\\n         client_with_examples.post(\\n             \\\"/engines/\\\",\\n-            json={\\\"name\\\": \\\"spark\\\", \\\"version\\\": \\\"2.4.4\\\", \\\"dialect\\\": \\\"spark\\\"},\\n+            json={\\n+                \\\"name\\\": \\\"spark\\\",\\n+                \\\"version\\\": \\\"2.4.4\\\",\\n+                \\\"dialect\\\": \\\"spark\\\",\\n+            },\\n         )\\n \\n         response = client_with_examples.get(\\\"/nodes/basic.transform.country_agg/\\\")\\n@@ -898,7 +908,8 @@ def test_upsert_materialization_config(  # pylint: disable=too-many-arguments\\n             json={\\n                 \\\"engine_name\\\": \\\"spark\\\",\\n                 \\\"engine_version\\\": \\\"2.4.4\\\",\\n-                \\\"config\\\": \\\"blahblah\\\",\\n+                \\\"config\\\": {},\\n+                \\\"schedule\\\": \\\"0 * * * *\\\",\\n             },\\n         )\\n         data = response.json()\\n@@ -914,7 +925,8 @@ def test_upsert_materialization_config(  # pylint: disable=too-many-arguments\\n         assert data[\\\"version\\\"] == \\\"v2.0\\\"\\n         assert data[\\\"materialization_configs\\\"] == [\\n             {\\n-                \\\"config\\\": \\\"blahblah\\\",\\n+                \\\"config\\\": {},\\n+                \\\"schedule\\\": \\\"0 * * * *\\\",\\n                 \\\"engine\\\": {\\n                     \\\"name\\\": \\\"spark\\\",\\n                     \\\"uri\\\": None,\\n@@ -931,8 +943,9 @@ def test_upsert_materialization_config(  # pylint: disable=too-many-arguments\\n             json={\\n                 \\\"engine_name\\\": \\\"spark\\\",\\n                 \\\"engine_version\\\": \\\"2.4.4\\\",\\n-                \\\"config\\\": \\\"blahblah\\\",\\n+                \\\"config\\\": {},\\n                 \\\"dialect\\\": \\\"spark\\\",\\n+                \\\"schedule\\\": \\\"0 * * * *\\\",\\n             },\\n         )\\n         assert response.status_code == 204\\n\",\"diff --git a/tests/api/cubes_test.py b/tests/api/cubes_test.py\\nindex 723289fbe..7ee6045e9 100644\\n--- a/tests/api/cubes_test.py\\n+++ b/tests/api/cubes_test.py\\n@@ -234,6 +234,7 @@ def test_cube_sql(client_with_examples: TestClient):\\n                 \\\"dispatcher.company_name\\\",\\n                 \\\"municipality_dim.local_region\\\",\\n             ],\\n+            \\\"filters\\\": [\\\"hard_hat.state='AZ'\\\"],\\n             \\\"description\\\": \\\"Cube of various metrics related to repairs\\\",\\n             \\\"mode\\\": \\\"published\\\",\\n             \\\"name\\\": \\\"repairs_cube\\\",\\n@@ -283,6 +284,7 @@ def test_cube_sql(client_with_examples: TestClient):\\n              = municipality_type.municipality_type_desc\\n         ) AS municipality_dim\\n         ON repair_orders.municipality_id = municipality_dim.municipality_id\\n+        WHERE hard_hat.state='AZ'\\n         GROUP BY\\n           hard_hat.country,\\n           hard_hat.postal_code,\\n@@ -291,5 +293,6 @@ def test_cube_sql(client_with_examples: TestClient):\\n           dispatcher.company_name,\\n           municipality_dim.local_region\\n     \\\"\\\"\\\"\\n+    print(results[\\\"query\\\"])\\n     assert compare_query_strings(results[\\\"query\\\"], expected_query)\\n     assert results[\\\"display_name\\\"] == \\\"Repairs Cube\\\"\\n\",\"diff --git a/tests/api/cubes_test.py b/tests/api/cubes_test.py\\nindex 7ee6045e9..856088d12 100644\\n--- a/tests/api/cubes_test.py\\n+++ b/tests/api/cubes_test.py\\n@@ -84,16 +84,6 @@ def test_create_invalid_cube(client_with_examples: TestClient):\\n             \\\"msg\\\": \\\"field required\\\",\\n             \\\"type\\\": \\\"value_error.missing\\\",\\n         },\\n-        {\\n-            \\\"loc\\\": [\\\"body\\\", \\\"cube_elements\\\"],\\n-            \\\"msg\\\": \\\"extra fields not permitted\\\",\\n-            \\\"type\\\": \\\"value_error.extra\\\",\\n-        },\\n-        {\\n-            \\\"loc\\\": [\\\"body\\\", \\\"query\\\"],\\n-            \\\"msg\\\": \\\"extra fields not permitted\\\",\\n-            \\\"type\\\": \\\"value_error.extra\\\",\\n-        },\\n     ]\\n \\n     # Check that creating a cube with no cube elements fails appropriately\\n@@ -293,6 +283,26 @@ def test_cube_sql(client_with_examples: TestClient):\\n           dispatcher.company_name,\\n           municipality_dim.local_region\\n     \\\"\\\"\\\"\\n-    print(results[\\\"query\\\"])\\n     assert compare_query_strings(results[\\\"query\\\"], expected_query)\\n-    assert results[\\\"display_name\\\"] == \\\"Repairs Cube\\\"\\n+\\n+    response = client_with_examples.get(\\\"/cubes/repairs_cube/\\\")\\n+    data = response.json()\\n+    assert data[\\\"cube_elements\\\"] == [\\n+        {\\n+            \\\"name\\\": \\\"num_repair_orders\\\",\\n+            \\\"node_name\\\": \\\"num_repair_orders\\\",\\n+            \\\"type\\\": \\\"metric\\\",\\n+        },\\n+        {\\\"name\\\": \\\"avg_repair_price\\\", \\\"node_name\\\": \\\"avg_repair_price\\\", \\\"type\\\": \\\"metric\\\"},\\n+        {\\n+            \\\"name\\\": \\\"total_repair_cost\\\",\\n+            \\\"node_name\\\": \\\"total_repair_cost\\\",\\n+            \\\"type\\\": \\\"metric\\\",\\n+        },\\n+        {\\\"name\\\": \\\"country\\\", \\\"node_name\\\": \\\"hard_hat\\\", \\\"type\\\": \\\"dimension\\\"},\\n+        {\\\"name\\\": \\\"postal_code\\\", \\\"node_name\\\": \\\"hard_hat\\\", \\\"type\\\": \\\"dimension\\\"},\\n+        {\\\"name\\\": \\\"city\\\", \\\"node_name\\\": \\\"hard_hat\\\", \\\"type\\\": \\\"dimension\\\"},\\n+        {\\\"name\\\": \\\"state\\\", \\\"node_name\\\": \\\"hard_hat\\\", \\\"type\\\": \\\"dimension\\\"},\\n+        {\\\"name\\\": \\\"company_name\\\", \\\"node_name\\\": \\\"dispatcher\\\", \\\"type\\\": \\\"dimension\\\"},\\n+        {\\\"name\\\": \\\"local_region\\\", \\\"node_name\\\": \\\"municipality_dim\\\", \\\"type\\\": \\\"dimension\\\"},\\n+    ]\\n\",\"diff --git a/tests/api/nodes_test.py b/tests/api/nodes_test.py\\nindex 29a84191c..ff8ee4715 100644\\n--- a/tests/api/nodes_test.py\\n+++ b/tests/api/nodes_test.py\\n@@ -902,7 +902,7 @@ def test_upsert_materialization_config(  # pylint: disable=too-many-arguments\\n         assert old_node_data[\\\"version\\\"] == \\\"v1.0\\\"\\n         assert old_node_data[\\\"materialization_configs\\\"] == []\\n \\n-        # Setting the materialization config should succeed with a new node revision created.\\n+        # Setting the materialization config should succeed\\n         response = client_with_examples.post(\\n             \\\"/nodes/basic.transform.country_agg/materialization/\\\",\\n             json={\\n@@ -919,10 +919,10 @@ def test_upsert_materialization_config(  # pylint: disable=too-many-arguments\\n             \\\" and engine `spark`.\\\"\\n         )\\n \\n-        # Reading the node should yield the materialization config and new revision.\\n+        # Reading the node should yield the materialization config\\n         response = client_with_examples.get(\\\"/nodes/basic.transform.country_agg/\\\")\\n         data = response.json()\\n-        assert data[\\\"version\\\"] == \\\"v2.0\\\"\\n+        assert data[\\\"version\\\"] == \\\"v1.0\\\"\\n         assert data[\\\"materialization_configs\\\"] == [\\n             {\\n                 \\\"config\\\": {},\\n@@ -935,7 +935,6 @@ def test_upsert_materialization_config(  # pylint: disable=too-many-arguments\\n                 },\\n             },\\n         ]\\n-        assert old_node_data[\\\"node_revision_id\\\"] < data[\\\"node_revision_id\\\"]\\n \\n         # Setting the same config should yield a message indicating so.\\n         response = client_with_examples.post(\"]", "hints_text": ""}
