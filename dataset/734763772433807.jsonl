{"instance_id": "734763772433807", "repo": "matchms/matchms", "base_commit": "c2df94b73172b5da24d34baf370a6eb87cb702db", "problem_statement": "Add test that checks that ALL_FILTERS contains all filter functions:\\nSince this list is used to determine order, it is important that this is complete. When adding new tests it is easy to forget, therefore it is important to add a test that checks if all functions available are in the ALL_FILTERS list. This is hard to implement, since there are also helperfunctions in the folder filtering. \\r\\n\\r\\nThis can probably be implemented after adding a decorator or creating classes, see #455 ", "FAIL_TO_PASS": ["tests/filtering/test_spectrum_processor.py::test_all_filters_is_complete"], "PASS_TO_PASS": [], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/matchms_matchms:c2df94b73172b5da24d34baf370a6eb87cb702db", "patch": "[\"diff --git a/matchms/SpectrumProcessor.py b/matchms/SpectrumProcessor.py\\nindex ca0545963..2ed15fe41 100644\\n--- a/matchms/SpectrumProcessor.py\\n+++ b/matchms/SpectrumProcessor.py\\n@@ -198,17 +198,27 @@ def __str__(self):\\n                msfilters.harmonize_undefined_inchi,\\n                msfilters.harmonize_undefined_smiles,\\n                msfilters.repair_inchi_inchikey_smiles,\\n+               msfilters.derive_smiles_from_inchi,\\n+               msfilters.repair_smiles_from_compound_name,\\n+               msfilters.derive_inchi_from_smiles,\\n+               msfilters.derive_inchikey_from_inchi,\\n+               msfilters.clean_adduct,\\n+               msfilters.repair_smiles_of_salts,\\n+               msfilters.repair_precursor_is_parent_mass,\\n+               msfilters.repair_parent_mass_is_mol_wt,\\n+               msfilters.repair_adduct_based_on_smiles,\\n                msfilters.repair_parent_mass_match_smiles_wrapper,\\n                msfilters.require_correct_ionmode,\\n                msfilters.require_precursor_below_mz,\\n-               msfilters.require_parent_mass_match_smiles,\\n                msfilters.require_valid_annotation,\\n+               msfilters.require_parent_mass_match_smiles,\\n                msfilters.normalize_intensities,\\n                msfilters.select_by_intensity,\\n                msfilters.select_by_mz,\\n                msfilters.select_by_relative_intensity,\\n                msfilters.remove_peaks_around_precursor_mz,\\n                msfilters.remove_peaks_outside_top_k,\\n+               msfilters.reduce_to_number_of_peaks,\\n                msfilters.require_minimum_number_of_peaks,\\n                msfilters.require_minimum_of_high_peaks,\\n                msfilters.add_fingerprint,\\n@@ -240,8 +250,11 @@ def __str__(self):\\n        \\\"normalize_intensities\\\",\\n     ]\\n FULLY_ANNOTATED_PROCESSING = DEFAULT_FILTERS \\\\\\n-    + [(\\\"require_correct_ionmode\\\", {\\\"ion_mode_to_keep\\\": \\\"both\\\"}),\\n-       \\\"require_parent_mass_match_smiles\\\",\\n+    + [\\\"clean_adduct\\\",\\n+       \\\"derive_inchi_from_smiles\\\",\\n+       \\\"derive_smiles_from_inchi\\\",\\n+       (\\\"require_correct_ionmode\\\", {\\\"ion_mode_to_keep\\\": \\\"both\\\"}),\\n+       (\\\"require_parent_mass_match_smiles\\\", {'mass_tolerance': 0.1}),\\n        \\\"require_valid_annotation\\\",\\n     ]\\n \\n\",\"diff --git a/matchms/filtering/filter_utils/derive_precursor_mz_and_parent_mass.py b/matchms/filtering/filter_utils/derive_precursor_mz_and_parent_mass.py\\nindex f419277bc..d673cc64a 100644\\n--- a/matchms/filtering/filter_utils/derive_precursor_mz_and_parent_mass.py\\n+++ b/matchms/filtering/filter_utils/derive_precursor_mz_and_parent_mass.py\\n@@ -3,8 +3,9 @@\\n from matchms.constants import PROTON_MASS\\n from matchms.filtering.filter_utils.interpret_unknown_adduct import \\\\\\n     get_multiplier_and_mass_from_adduct\\n-from matchms.filtering.metadata_processing.clean_adduct import (\\n-    _clean_adduct, load_known_adducts)\\n+from matchms.filtering.filter_utils.load_known_adducts import \\\\\\n+    load_known_adducts\\n+from matchms.filtering.metadata_processing.clean_adduct import _clean_adduct\\n from matchms.typing import SpectrumType\\n \\n \\n\",\"diff --git a/matchms/filtering/filter_utils/load_known_adducts.py b/matchms/filtering/filter_utils/load_known_adducts.py\\nnew file mode 100644\\nindex 000000000..ef6fd6617\\n--- /dev/null\\n+++ b/matchms/filtering/filter_utils/load_known_adducts.py\\n@@ -0,0 +1,44 @@\\n+import csv\\n+import os\\n+from functools import lru_cache\\n+from typing import Dict\\n+import pandas as pd\\n+\\n+\\n+@lru_cache(maxsize=4)\\n+def load_known_adducts() -> pd.DataFrame:\\n+    \\\"\\\"\\\"Load dictionary of known adducts containing the adduct mass and charge.\\n+    Makes sure that file loading is cached.\\n+\\n+    Adduct information is based on information from\\n+    https://fiehnlab.ucdavis.edu/staff/kind/metabolomics/ms-adduct-calculator/\\n+    and was extended by F.Huber and JJJ.v.d.Hooft.\\n+\\n+    The full table can be found at\\n+    https://github.com/matchms/matchms/blob/expand_adducts/matchms/data/known_adducts_table.csv\\n+\\n+    \\\"\\\"\\\"\\n+    known_adducts_file = os.path.join(os.path.dirname(__file__), \\\"..\\\", \\\"..\\\", \\\"data\\\", \\\"known_adducts_table.csv\\\")\\n+    assert os.path.isfile(known_adducts_file), \\\"Could not find known_adducts_table.csv.\\\"\\n+\\n+    with open(known_adducts_file, newline='', encoding='utf-8-sig') as csvfile:\\n+        adducts_dataframe = pd.read_csv(csvfile)\\n+        assert list(adducts_dataframe.columns) == [\\\"adduct\\\", \\\"ionmode\\\", \\\"charge\\\", \\\"mass_multiplier\\\", \\\"correction_mass\\\"]\\n+    return adducts_dataframe\\n+\\n+\\n+@lru_cache(maxsize=4)\\n+def load_known_adduct_conversions() -> Dict[str, dict]:\\n+    \\\"\\\"\\\"Load dictionary of known adduct conversions. Makes sure that file loading is cached.\\n+    \\\"\\\"\\\"\\n+    adduct_conversions_file = os.path.join(os.path.dirname(__file__), \\\"..\\\", \\\"..\\\", \\\"data\\\",\\n+                                           \\\"known_adduct_conversions.csv\\\")\\n+    assert os.path.isfile(adduct_conversions_file), \\\"Could not find known_adduct_conversions.csv.\\\"\\n+\\n+    with open(adduct_conversions_file, newline='', encoding='utf-8-sig') as csvfile:\\n+        reader = csv.DictReader(csvfile)\\n+        known_adduct_conversions = {}\\n+        for row in reader:\\n+            known_adduct_conversions[row['input_adduct']] = row['corrected_adduct']\\n+\\n+    return known_adduct_conversions\\n\",\"diff --git a/matchms/filtering/metadata_processing/add_retention.py b/matchms/filtering/metadata_processing/add_retention.py\\nindex 8470ca49a..b109a32a5 100644\\n--- a/matchms/filtering/metadata_processing/add_retention.py\\n+++ b/matchms/filtering/metadata_processing/add_retention.py\\n@@ -13,7 +13,7 @@\\n _retention_index_keys = [\\\"retention_index\\\", \\\"retentionindex\\\", \\\"ri\\\"]\\n \\n \\n-def safe_store_value(metadata: dict, value: Any, target_key: str) -> dict:\\n+def _safe_store_value(metadata: dict, value: Any, target_key: str) -> dict:\\n     \\\"\\\"\\\"Helper function to safely store a value in the target key without throwing an exception, but storing 'None' instead.\\n \\n     Parameters\\n@@ -30,12 +30,12 @@ def safe_store_value(metadata: dict, value: Any, target_key: str) -> dict:\\n     Spectrum with added key.\\n     \\\"\\\"\\\"\\n     if value is not None:   # one of accepted keys is present\\n-        value = safe_convert_to_float(value)\\n+        value = _safe_convert_to_float(value)\\n     metadata[target_key] = value\\n     return metadata\\n \\n \\n-def safe_convert_to_float(value: Any) -> Optional[float]:\\n+def _safe_convert_to_float(value: Any) -> Optional[float]:\\n     \\\"\\\"\\\"Safely convert value to float. Return 'None' on failure.\\n \\n     Parameters\\n@@ -52,14 +52,14 @@ def safe_convert_to_float(value: Any) -> Optional[float]:\\n             value = value[0]\\n         else:\\n             return None\\n-        \\n+\\n     # logic to read MoNA msp files which specify rt as string with \\\"min\\\" in it\\n     if isinstance(value, str):\\n         value = value.strip()\\n         pattern = r'^[+-]?(\\\\d*\\\\.)?\\\\d+\\\\s*(min|s|h|ms)'\\n         conversion = {\\\"min\\\": 60, \\\"s\\\": 1, \\\"h\\\": 3600, \\\"ms\\\": 1e-3}\\n         match = re.search(pattern, value)\\n-        \\n+\\n         if match and len(match.groups()) == 2:\\n             val, unit = value.split(' ')\\n             return float(val) * conversion[unit]\\n@@ -90,10 +90,10 @@ def _add_retention(metadata: dict, target_key: str, accepted_keys: List[str]) ->\\n     \\\"\\\"\\\"\\n     common_keys = get_common_keys(metadata.keys(), accepted_keys)\\n     values_for_keys = filter_none([metadata[key] for key in common_keys])\\n-    values = list(map(safe_convert_to_float, values_for_keys))\\n+    values = list(map(_safe_convert_to_float, values_for_keys))\\n     value = next(filter_none(values), None)\\n \\n-    metadata = safe_store_value(metadata, value, target_key)\\n+    metadata = _safe_store_value(metadata, value, target_key)\\n     return metadata\\n \\n \\n\",\"diff --git a/matchms/filtering/metadata_processing/clean_adduct.py b/matchms/filtering/metadata_processing/clean_adduct.py\\nindex 7460409d5..982fb01a0 100644\\n--- a/matchms/filtering/metadata_processing/clean_adduct.py\\n+++ b/matchms/filtering/metadata_processing/clean_adduct.py\\n@@ -1,10 +1,7 @@\\n-import csv\\n import logging\\n-import os\\n import re\\n-from functools import lru_cache\\n-from typing import Dict\\n-import pandas as pd\\n+from matchms.filtering.filter_utils.load_known_adducts import \\\\\\n+    load_known_adduct_conversions\\n \\n \\n logger = logging.getLogger(\\\"matchms\\\")\\n@@ -40,14 +37,14 @@ def _clean_adduct(adduct: str) -> str:\\n     adduct\\n         Input adduct string to be cleaned/edited.\\n     \\\"\\\"\\\"\\n-    def get_adduct_charge(adduct):\\n+    def _get_adduct_charge(adduct):\\n         regex_charges = r\\\"[1-3]{0,1}[+-]{1,2}$\\\"\\n         match = re.search(regex_charges, adduct)\\n         if match:\\n             return match.group(0)\\n         return match\\n \\n-    def adduct_conversion(adduct):\\n+    def _adduct_conversion(adduct):\\n         \\\"\\\"\\\"Convert adduct if conversion rule is known\\\"\\\"\\\"\\n         adduct_conversions = load_known_adduct_conversions()\\n         if adduct in adduct_conversions:\\n@@ -60,59 +57,20 @@ def adduct_conversion(adduct):\\n     adduct = adduct.strip().replace(\\\"\\\\n\\\", \\\"\\\").replace(\\\"*\\\", \\\"\\\")\\n     adduct = adduct.replace(\\\"++\\\", \\\"2+\\\").replace(\\\"--\\\", \\\"2-\\\")\\n     if adduct.startswith(\\\"[\\\"):\\n-        return adduct_conversion(adduct)\\n+        return _adduct_conversion(adduct)\\n \\n     if adduct.endswith(\\\"]\\\"):\\n-        return adduct_conversion(\\\"[\\\" + adduct)\\n+        return _adduct_conversion(\\\"[\\\" + adduct)\\n \\n     adduct_core = \\\"[\\\" + adduct\\n     # Remove parts that can confuse the charge extraction\\n     for mol_part in [\\\"CH2\\\", \\\"CH3\\\", \\\"NH3\\\", \\\"NH4\\\", \\\"O2\\\"]:\\n         if mol_part in adduct:\\n             adduct = adduct.split(mol_part)[-1]\\n-    adduct_charge = get_adduct_charge(adduct)\\n+    adduct_charge = _get_adduct_charge(adduct)\\n \\n     if adduct_charge is None:\\n-        return adduct_conversion(adduct_core + \\\"]\\\")\\n+        return _adduct_conversion(adduct_core + \\\"]\\\")\\n \\n     adduct_cleaned = adduct_core[:-len(adduct_charge)] + \\\"]\\\" + adduct_charge\\n-    return adduct_conversion(adduct_cleaned)\\n-\\n-\\n-@lru_cache(maxsize=4)\\n-def load_known_adducts() -> pd.DataFrame:\\n-    \\\"\\\"\\\"Load dictionary of known adducts containing the adduct mass and charge.\\n-    Makes sure that file loading is cached.\\n-\\n-    Adduct information is based on information from\\n-    https://fiehnlab.ucdavis.edu/staff/kind/metabolomics/ms-adduct-calculator/\\n-    and was extended by F.Huber and JJJ.v.d.Hooft.\\n-\\n-    The full table can be found at\\n-    https://github.com/matchms/matchms/blob/expand_adducts/matchms/data/known_adducts_table.csv\\n-\\n-    \\\"\\\"\\\"\\n-    known_adducts_file = os.path.join(os.path.dirname(__file__), \\\"..\\\", \\\"..\\\", \\\"data\\\", \\\"known_adducts_table.csv\\\")\\n-    assert os.path.isfile(known_adducts_file), \\\"Could not find known_adducts_table.csv.\\\"\\n-\\n-    with open(known_adducts_file, newline='', encoding='utf-8-sig') as csvfile:\\n-        adducts_dataframe = pd.read_csv(csvfile)\\n-        assert list(adducts_dataframe.columns) == [\\\"adduct\\\", \\\"ionmode\\\", \\\"charge\\\", \\\"mass_multiplier\\\", \\\"correction_mass\\\"]\\n-    return adducts_dataframe\\n-\\n-\\n-@lru_cache(maxsize=4)\\n-def load_known_adduct_conversions() -> Dict[str, dict]:\\n-    \\\"\\\"\\\"Load dictionary of known adduct conversions. Makes sure that file loading is cached.\\n-    \\\"\\\"\\\"\\n-    adduct_conversions_file = os.path.join(os.path.dirname(__file__), \\\"..\\\", \\\"..\\\", \\\"data\\\",\\n-                                           \\\"known_adduct_conversions.csv\\\")\\n-    assert os.path.isfile(adduct_conversions_file), \\\"Could not find known_adduct_conversions.csv.\\\"\\n-\\n-    with open(adduct_conversions_file, newline='', encoding='utf-8-sig') as csvfile:\\n-        reader = csv.DictReader(csvfile)\\n-        known_adduct_conversions = {}\\n-        for row in reader:\\n-            known_adduct_conversions[row['input_adduct']] = row['corrected_adduct']\\n-\\n-    return known_adduct_conversions\\n+    return _adduct_conversion(adduct_cleaned)\\n\",\"diff --git a/matchms/filtering/metadata_processing/clean_compound_name.py b/matchms/filtering/metadata_processing/clean_compound_name.py\\nindex bb60e6376..fdad83f0c 100644\\n--- a/matchms/filtering/metadata_processing/clean_compound_name.py\\n+++ b/matchms/filtering/metadata_processing/clean_compound_name.py\\n@@ -12,50 +12,6 @@ def clean_compound_name(spectrum_in: SpectrumType) -> SpectrumType:\\n     A list of frequently seen name additions that do not belong to the compound\\n     name will be removed.\\n     \\\"\\\"\\\"\\n-    def remove_parts_by_regular_expression(name):\\n-        \\\"\\\"\\\"Clean name string by removing known parts that don't belong there.\\\"\\\"\\\"\\n-        name = name.strip()\\n-        # remove type NCGC00180417-03_C31H40O16_\\n-        name = re.split(r\\\"[A-Z]{3,6}[0-9]{8,12}-[0-9]{2,5}_[A-Z,0-9]{4,15}_\\\", name)[-1]\\n-        # remove type NCGC00160232-01! or MLS001142816-01!\\n-        name = re.split(r\\\"[A-Z]{3,6}[0-9]{8,12}-[0-9]{2,3}\\\\!\\\", name)[-1]\\n-        # remove type Massbank:EA008813 option1|option2|option3\\n-        name = re.split(r\\\"((Massbank:)|(MassbankEU:))[A-Z]{2}[0-9]{5,6}.*\\\\|\\\", name)[-1]\\n-        # remove type Massbank:EA008813 or MassbankEU:EA008813\\n-        name = re.split(r\\\"((Massbank:)|(MassbankEU:))[A-Z]{2}[0-9]{5,6}\\\", name)[-1]\\n-        # remove type HMDB:HMDB00943-1336\\n-        name = re.split(r\\\"HMDB:HMDB[0-9]{4,7}-[0-9]{1,7}\\\", name)[-1]\\n-        # remove type MoNA:662599\\n-        name = re.split(r\\\"MoNA:[0-9]{5,10}\\\", name)[-1]\\n-        # ReSpect:PS013405 option1|option2|option3...\\n-        name = re.split(r\\\"ReSpect:[A-Z]{2,3}[0-9]{6}.*\\\\|\\\", name)[-1]\\n-        # ReSpect:PS013405 option1\\n-        name = re.split(r\\\"[A-Z]{2,3}[0-9]{6}( )\\\", name)[-1]\\n-        # remove type 0072_2-Mercaptobenzothiaz\\n-        name = re.split(r\\\"^[0-9]{4}_\\\", name)[-1]\\n-        # remove type nameofcompound_CID20_170920 or Spiraeoside_HCD30_170919\\n-        name = re.split(r\\\"_((HCD)|(CID))[0-9]{2}_[0-9]{5,6}$\\\", name)[0]\\n-        # Removes the collision energy from the compound name. Also allows for occurances of - 40.0 eV Unknown\\n-        name = re.split(r\\\"(?: - )?[0-9]+(?:\\\\.[0-9]+)? ?[eE][Vv](?: Unknown)?$\\\", name)[0]\\n-        return name\\n-\\n-    def remove_known_non_compound_parts(name):\\n-        \\\"\\\"\\\"Remove known non compound-name strings from name.\\\"\\\"\\\"\\n-        parts_remove = [\\\"Spectral Match to\\\",\\n-                        \\\"from NIST14\\\",\\n-                        \\\"Massbank:\\\"]\\n-        for part in parts_remove:\\n-            name = name.replace(part, \\\"\\\")\\n-        return name.strip(\\\"; \\\")\\n-\\n-    def remove_misplaced_mass(name):\\n-        \\\"\\\"\\\"Remove occasionally occurring parent mass addition to name.\\\"\\\"\\\"\\n-        regex_mass = r\\\"^[0-9]{2,4}\\\\.[0-9]$\\\"\\n-        end_part = name.split(\\\" \\\")[-1]\\n-        if re.search(regex_mass, end_part) is not None:\\n-            return name.replace(end_part, \\\"\\\").strip()\\n-        return name\\n-\\n     if spectrum_in is None:\\n         return None\\n \\n@@ -69,11 +25,58 @@ def remove_misplaced_mass(name):\\n         return spectrum\\n \\n     # Clean compound name\\n-    name_cleaned = remove_parts_by_regular_expression(name)\\n-    name_cleaned = remove_known_non_compound_parts(name_cleaned)\\n-    name_cleaned = remove_misplaced_mass(name_cleaned)\\n+    name_cleaned = _remove_parts_by_regular_expression(name)\\n+    name_cleaned = _remove_known_non_compound_parts(name_cleaned)\\n+    name_cleaned = _remove_misplaced_mass(name_cleaned)\\n     if name_cleaned != name:\\n         spectrum.set(\\\"compound_name\\\", name_cleaned)\\n         logger.info(\\\"Added cleaned compound name: %s\\\", name_cleaned)\\n \\n     return spectrum\\n+\\n+\\n+def _remove_parts_by_regular_expression(name):\\n+    \\\"\\\"\\\"Clean name string by removing known parts that don't belong there.\\\"\\\"\\\"\\n+    name = name.strip()\\n+    # remove type NCGC00180417-03_C31H40O16_\\n+    name = re.split(r\\\"[A-Z]{3,6}[0-9]{8,12}-[0-9]{2,5}_[A-Z,0-9]{4,15}_\\\", name)[-1]\\n+    # remove type NCGC00160232-01! or MLS001142816-01!\\n+    name = re.split(r\\\"[A-Z]{3,6}[0-9]{8,12}-[0-9]{2,3}\\\\!\\\", name)[-1]\\n+    # remove type Massbank:EA008813 option1|option2|option3\\n+    name = re.split(r\\\"((Massbank:)|(MassbankEU:))[A-Z]{2}[0-9]{5,6}.*\\\\|\\\", name)[-1]\\n+    # remove type Massbank:EA008813 or MassbankEU:EA008813\\n+    name = re.split(r\\\"((Massbank:)|(MassbankEU:))[A-Z]{2}[0-9]{5,6}\\\", name)[-1]\\n+    # remove type HMDB:HMDB00943-1336\\n+    name = re.split(r\\\"HMDB:HMDB[0-9]{4,7}-[0-9]{1,7}\\\", name)[-1]\\n+    # remove type MoNA:662599\\n+    name = re.split(r\\\"MoNA:[0-9]{5,10}\\\", name)[-1]\\n+    # ReSpect:PS013405 option1|option2|option3...\\n+    name = re.split(r\\\"ReSpect:[A-Z]{2,3}[0-9]{6}.*\\\\|\\\", name)[-1]\\n+    # ReSpect:PS013405 option1\\n+    name = re.split(r\\\"[A-Z]{2,3}[0-9]{6}( )\\\", name)[-1]\\n+    # remove type 0072_2-Mercaptobenzothiaz\\n+    name = re.split(r\\\"^[0-9]{4}_\\\", name)[-1]\\n+    # remove type nameofcompound_CID20_170920 or Spiraeoside_HCD30_170919\\n+    name = re.split(r\\\"_((HCD)|(CID))[0-9]{2}_[0-9]{5,6}$\\\", name)[0]\\n+    # Removes the collision energy from the compound name. Also allows for occurances of - 40.0 eV Unknown\\n+    name = re.split(r\\\"(?: - )?[0-9]+(?:\\\\.[0-9]+)? ?[eE][Vv](?: Unknown)?$\\\", name)[0]\\n+    return name\\n+\\n+\\n+def _remove_known_non_compound_parts(name):\\n+    \\\"\\\"\\\"Remove known non compound-name strings from name.\\\"\\\"\\\"\\n+    parts_remove = [\\\"Spectral Match to\\\",\\n+                    \\\"from NIST14\\\",\\n+                    \\\"Massbank:\\\"]\\n+    for part in parts_remove:\\n+        name = name.replace(part, \\\"\\\")\\n+    return name.strip(\\\"; \\\")\\n+\\n+\\n+def _remove_misplaced_mass(name):\\n+    \\\"\\\"\\\"Remove occasionally occurring parent mass addition to name.\\\"\\\"\\\"\\n+    regex_mass = r\\\"^[0-9]{2,4}\\\\.[0-9]$\\\"\\n+    end_part = name.split(\\\" \\\")[-1]\\n+    if re.search(regex_mass, end_part) is not None:\\n+        return name.replace(end_part, \\\"\\\").strip()\\n+    return name\\n\",\"diff --git a/matchms/filtering/metadata_processing/derive_adduct_from_name.py b/matchms/filtering/metadata_processing/derive_adduct_from_name.py\\nindex a365c1fcf..8eea01a50 100644\\n--- a/matchms/filtering/metadata_processing/derive_adduct_from_name.py\\n+++ b/matchms/filtering/metadata_processing/derive_adduct_from_name.py\\n@@ -1,7 +1,8 @@\\n import logging\\n import re\\n from matchms.typing import SpectrumType\\n-from .clean_adduct import _clean_adduct, load_known_adducts\\n+from ..filter_utils.load_known_adducts import load_known_adducts\\n+from .clean_adduct import _clean_adduct\\n \\n \\n logger = logging.getLogger(\\\"matchms\\\")\\n@@ -36,7 +37,7 @@ def derive_adduct_from_name(spectrum_in: SpectrumType,\\n     adduct_from_name = None\\n     name_split = name.split(\\\" \\\")\\n     for name_part in name_split[::-1][:2]:\\n-        if looks_like_adduct(name_part):\\n+        if _looks_like_adduct(name_part):\\n             adduct_from_name = name_part\\n             break\\n \\n@@ -47,7 +48,7 @@ def derive_adduct_from_name(spectrum_in: SpectrumType,\\n         logger.info(\\\"Removed adduct %s from compound name.\\\", adduct_from_name)\\n \\n     # Add found adduct to metadata (if not present yet)\\n-    if adduct_from_name and not looks_like_adduct(spectrum.get(\\\"adduct\\\")):\\n+    if adduct_from_name and not _looks_like_adduct(spectrum.get(\\\"adduct\\\")):\\n         adduct_cleaned = _clean_adduct(adduct_from_name)\\n         spectrum.set(\\\"adduct\\\", adduct_cleaned)\\n         logger.info(\\\"Added adduct %s from the compound name to metadata.\\\", spectrum.get('adduct'))\\n@@ -55,7 +56,7 @@ def derive_adduct_from_name(spectrum_in: SpectrumType,\\n     return spectrum\\n \\n \\n-def looks_like_adduct(adduct):\\n+def _looks_like_adduct(adduct):\\n     \\\"\\\"\\\"Return True if input string has expected format of an adduct.\\\"\\\"\\\"\\n     if not isinstance(adduct, str):\\n         return False\\n\",\"diff --git a/matchms/filtering/metadata_processing/derive_formula_from_name.py b/matchms/filtering/metadata_processing/derive_formula_from_name.py\\nindex 49c66b8f0..4e10d69bd 100644\\n--- a/matchms/filtering/metadata_processing/derive_formula_from_name.py\\n+++ b/matchms/filtering/metadata_processing/derive_formula_from_name.py\\n@@ -35,7 +35,7 @@ def derive_formula_from_name(spectrum_in: SpectrumType,\\n \\n     # Detect formula at end of compound name\\n     end_of_name = name.split(\\\" \\\")[-1]\\n-    formula_from_name = end_of_name if looks_like_formula(end_of_name) else None\\n+    formula_from_name = end_of_name if _looks_like_formula(end_of_name) else None\\n \\n     if formula_from_name and remove_formula_from_name:\\n         name_formula_removed = \\\" \\\".join(name.split(\\\" \\\")[:-1])\\n@@ -50,7 +50,7 @@ def derive_formula_from_name(spectrum_in: SpectrumType,\\n     return spectrum\\n \\n \\n-def looks_like_formula(formula):\\n+def _looks_like_formula(formula):\\n     \\\"\\\"\\\"Return True if input string has expected format of a molecular formula.\\n     Does only consider most frequent atoms found in many name strings.\\n     \\\"\\\"\\\"\\n\",\"diff --git a/matchms/filtering/metadata_processing/derive_ionmode.py b/matchms/filtering/metadata_processing/derive_ionmode.py\\nindex e4fe76bcc..11bb15a10 100644\\n--- a/matchms/filtering/metadata_processing/derive_ionmode.py\\n+++ b/matchms/filtering/metadata_processing/derive_ionmode.py\\n@@ -1,6 +1,7 @@\\n import logging\\n from matchms.typing import SpectrumType\\n-from .clean_adduct import _clean_adduct, load_known_adducts\\n+from ..filter_utils.load_known_adducts import load_known_adducts\\n+from .clean_adduct import _clean_adduct\\n \\n \\n logger = logging.getLogger(\\\"matchms\\\")\\n\",\"diff --git a/matchms/filtering/metadata_processing/make_charge_int.py b/matchms/filtering/metadata_processing/make_charge_int.py\\nindex 2c8884062..90a75efc1 100644\\n--- a/matchms/filtering/metadata_processing/make_charge_int.py\\n+++ b/matchms/filtering/metadata_processing/make_charge_int.py\\n@@ -22,7 +22,7 @@ def make_charge_int(spectrum_in: SpectrumType) -> SpectrumType:\\n \\n def _convert_charge_to_int(charge):\\n     \\\"\\\"\\\"Convert charge to integer if possible, else return None.\\\"\\\"\\\"\\n-    def try_conversion(charge):\\n+    def _try_conversion(charge):\\n         try:\\n             return int(charge)\\n         except ValueError:\\n@@ -38,11 +38,11 @@ def try_conversion(charge):\\n \\n     # Avoid pyteomics ChargeList\\n     if isinstance(charge, list):\\n-        return try_conversion(charge[0])\\n+        return _try_conversion(charge[0])\\n \\n     # convert string charges to int\\n     if isinstance(charge, str):\\n         charge = charge.strip().replace(\\\"+\\\", \\\"\\\")\\n         if len(charge) > 1 and charge[-1] == \\\"-\\\":\\n             charge = \\\"-\\\" + charge.replace(\\\"-\\\", \\\"\\\")\\n-        return try_conversion(charge)\\n+        return _try_conversion(charge)\\n\",\"diff --git a/matchms/filtering/metadata_processing/repair_adduct_based_on_smiles.py b/matchms/filtering/metadata_processing/repair_adduct_based_on_smiles.py\\nindex 02ee445c6..b577997a7 100644\\n--- a/matchms/filtering/metadata_processing/repair_adduct_based_on_smiles.py\\n+++ b/matchms/filtering/metadata_processing/repair_adduct_based_on_smiles.py\\n@@ -2,8 +2,7 @@\\n from matchms import Spectrum\\n from matchms.filtering.filter_utils.get_neutral_mass_from_smiles import \\\\\\n     get_monoisotopic_neutral_mass\\n-from matchms.filtering.metadata_processing.clean_adduct import \\\\\\n-    load_known_adducts\\n+from ..filter_utils.load_known_adducts import load_known_adducts\\n from .repair_parent_mass_is_mol_wt import repair_parent_mass_is_mol_wt\\n \\n \\n\",\"diff --git a/matchms/filtering/metadata_processing/repair_smiles_from_compound_name.py b/matchms/filtering/metadata_processing/repair_smiles_from_compound_name.py\\nindex 78b58189b..451a48896 100644\\n--- a/matchms/filtering/metadata_processing/repair_smiles_from_compound_name.py\\n+++ b/matchms/filtering/metadata_processing/repair_smiles_from_compound_name.py\\n@@ -26,20 +26,20 @@ def repair_smiles_from_compound_name(spectrum_in: Spectrum,\\n         The input spectrum.\\n     annotated_compound_names_file: str\\n         A csv file containing the compound names and matching smiles, inchi, inchikey\\n-        and monoisotopic_mass.\\n+        and monoisotopic_mass. This can be created using the the pubchem_lookup.py from matchmextras.\\n     mass_tolerance.\\n         Acceptable mass difference between query compound and pubchem result.\\n     \\\"\\\"\\\"\\n-    annotated_compound_names = load_compond_name_annotations(annotated_compound_names_file)\\n+    annotated_compound_names = _load_compound_name_annotations(annotated_compound_names_file)\\n     if spectrum_in is None:\\n         return None\\n     spectrum = spectrum_in.clone()\\n-    if check_fully_annotated(spectrum):\\n+    if _check_fully_annotated(spectrum):\\n         return spectrum\\n     compound_name = spectrum.get(\\\"compound_name\\\")\\n     parent_mass = spectrum.get('parent_mass')\\n \\n-    if is_plausible_name(compound_name) and parent_mass is not None:\\n+    if _is_plausible_name(compound_name) and parent_mass is not None:\\n         matching_compound_name = annotated_compound_names[annotated_compound_names[\\\"compound_name\\\"] == compound_name]\\n         mass_differences = np.abs(matching_compound_name[\\\"monoisotopic_mass\\\"]-parent_mass)\\n         within_mass_tolerance = matching_compound_name[mass_differences < mass_tolerance]\\n@@ -54,7 +54,7 @@ def repair_smiles_from_compound_name(spectrum_in: Spectrum,\\n     return spectrum\\n \\n \\n-def load_compond_name_annotations(annotated_compound_names_file):\\n+def _load_compound_name_annotations(annotated_compound_names_file):\\n     \\\"\\\"\\\"Loads in the annotated compound names and checks format\\\"\\\"\\\"\\n     annotated_compound_names = pd.read_csv(annotated_compound_names_file)\\n     assert list(annotated_compound_names.columns) == [\\\"compound_name\\\", \\\"smiles\\\", \\\"inchi\\\",\\n@@ -63,7 +63,7 @@ def load_compond_name_annotations(annotated_compound_names_file):\\n     return annotated_compound_names\\n \\n \\n-def check_fully_annotated(spectrum: Spectrum) -> bool:\\n+def _check_fully_annotated(spectrum: Spectrum) -> bool:\\n     \\\"\\\"\\\"Combine multiple check functions.\\n     Returns False if SMILES, InChIKey, or InChI are missing.\\n     \\\"\\\"\\\"\\n@@ -76,6 +76,6 @@ def check_fully_annotated(spectrum: Spectrum) -> bool:\\n     return True\\n \\n \\n-def is_plausible_name(compound_name):\\n+def _is_plausible_name(compound_name):\\n     \\\"\\\"\\\"Simple check if it can be a compound name.\\\"\\\"\\\"\\n     return isinstance(compound_name, str) and len(compound_name) > 4\\n\",\"diff --git a/matchms/filtering/metadata_processing/repair_smiles_of_salts.py b/matchms/filtering/metadata_processing/repair_smiles_of_salts.py\\nindex fd2ef73bb..7f31c8f0b 100644\\n--- a/matchms/filtering/metadata_processing/repair_smiles_of_salts.py\\n+++ b/matchms/filtering/metadata_processing/repair_smiles_of_salts.py\\n@@ -18,7 +18,7 @@ def repair_smiles_of_salts(spectrum_in,\\n \\n     smiles = spectrum.get(\\\"smiles\\\")\\n     parent_mass = spectrum.get(\\\"parent_mass\\\")\\n-    possible_ion_combinations = create_possible_ions(smiles)\\n+    possible_ion_combinations = _create_possible_ions(smiles)\\n     if not possible_ion_combinations:\\n         # It is not a salt\\n         return spectrum\\n@@ -38,7 +38,7 @@ def repair_smiles_of_salts(spectrum_in,\\n     return spectrum\\n \\n \\n-def create_possible_ions(smiles):\\n+def _create_possible_ions(smiles):\\n     \\\"\\\"\\\"Selects all possible ion combinations of a salt\\\"\\\"\\\"\\n \\n     results = []\\n\",\"diff --git a/matchms/filtering/metadata_processing/require_valid_annotation.py b/matchms/filtering/metadata_processing/require_valid_annotation.py\\nindex 4e3eeb6e3..39be14892 100644\\n--- a/matchms/filtering/metadata_processing/require_valid_annotation.py\\n+++ b/matchms/filtering/metadata_processing/require_valid_annotation.py\\n@@ -24,12 +24,12 @@ def require_valid_annotation(spectrum: Spectrum):\\n     if not is_valid_inchi(inchi):\\n         logger.info(\\\"Removed spectrum since inchi is not valid. Incorrect inchi = %s\\\", inchi)\\n         return None\\n-    if not check_smiles_inchi_inchikey_match(spectrum):\\n+    if not _check_smiles_inchi_inchikey_match(spectrum):\\n         return None\\n     return spectrum\\n \\n \\n-def check_smiles_inchi_inchikey_match(spectrum) -> bool:\\n+def _check_smiles_inchi_inchikey_match(spectrum) -> bool:\\n     \\\"\\\"\\\"Checks if a spectrum\\\"\\\"\\\"\\n     if spectrum is None:\\n         return False\\n\"]", "test_patch": "[\"diff --git a/tests/filtering/test_derive_adduct_from_name.py b/tests/filtering/test_derive_adduct_from_name.py\\nindex 72bb13f73..8b8ce5a06 100644\\n--- a/tests/filtering/test_derive_adduct_from_name.py\\n+++ b/tests/filtering/test_derive_adduct_from_name.py\\n@@ -2,7 +2,7 @@\\n from testfixtures import LogCapture\\n from matchms.filtering import derive_adduct_from_name\\n from matchms.filtering.metadata_processing.derive_adduct_from_name import \\\\\\n-    looks_like_adduct\\n+    _looks_like_adduct\\n from matchms.logging_functions import (reset_matchms_logger,\\n                                        set_matchms_logger_level)\\n from ..builder_Spectrum import SpectrumBuilder\\n@@ -47,6 +47,6 @@ def test_looks_like_adduct():\\n     \\\"\\\"\\\"Test if adducts are correctly identified\\\"\\\"\\\"\\n     for adduct in [\\\"M+\\\", \\\"M*+\\\", \\\"M+Cl\\\", \\\"[M+H]\\\", \\\"[2M+Na]+\\\", \\\"M+H+K\\\", \\\"[2M+ACN+H]+\\\",\\n                    \\\"MS+Na\\\", \\\"MS+H\\\", \\\"M3Cl37+Na\\\", \\\"[M+H+H2O]\\\"]:\\n-        assert looks_like_adduct(adduct), \\\"Expected this to be identified as adduct\\\"\\n+        assert _looks_like_adduct(adduct), \\\"Expected this to be identified as adduct\\\"\\n     for adduct in [\\\"N+\\\", \\\"B*+\\\", \\\"++\\\", \\\"--\\\", \\\"[--]\\\", \\\"H+M+K\\\"]:\\n-        assert not looks_like_adduct(adduct), \\\"Expected this not to be identified as adduct\\\"\\n+        assert not _looks_like_adduct(adduct), \\\"Expected this not to be identified as adduct\\\"\\n\",\"diff --git a/tests/filtering/test_filter_utils/test_interpret_unknown_adduct.py b/tests/filtering/test_filter_utils/test_interpret_unknown_adduct.py\\nindex 0a7c53d68..4fa8c34e7 100644\\n--- a/tests/filtering/test_filter_utils/test_interpret_unknown_adduct.py\\n+++ b/tests/filtering/test_filter_utils/test_interpret_unknown_adduct.py\\n@@ -1,7 +1,7 @@\\n import pytest\\n from matchms.filtering.filter_utils.interpret_unknown_adduct import \\\\\\n     get_multiplier_and_mass_from_adduct\\n-from matchms.filtering.metadata_processing.clean_adduct import \\\\\\n+from matchms.filtering.filter_utils.load_known_adducts import \\\\\\n     load_known_adducts\\n \\n \\n\",\"diff --git a/tests/filtering/test_load_adducts.py b/tests/filtering/test_load_adducts.py\\nindex 8fe7414ba..4c77c229d 100644\\n--- a/tests/filtering/test_load_adducts.py\\n+++ b/tests/filtering/test_load_adducts.py\\n@@ -1,6 +1,6 @@\\n import numpy as np\\n import pandas as pd\\n-from matchms.filtering.metadata_processing.clean_adduct import (\\n+from matchms.filtering.filter_utils.load_known_adducts import (\\n     load_known_adduct_conversions, load_known_adducts)\\n \\n \\n\",\"diff --git a/tests/filtering/test_spectrum_processor.py b/tests/filtering/test_spectrum_processor.py\\nindex 849839c2c..0cad682c9 100644\\n--- a/tests/filtering/test_spectrum_processor.py\\n+++ b/tests/filtering/test_spectrum_processor.py\\n@@ -1,7 +1,9 @@\\n+import ast\\n+import os\\n import numpy as np\\n import pytest\\n from matchms import SpectrumProcessor\\n-from matchms.SpectrumProcessor import ProcessingReport\\n+from matchms.SpectrumProcessor import ALL_FILTERS, ProcessingReport\\n from ..builder_Spectrum import SpectrumBuilder\\n \\n \\n@@ -178,3 +180,49 @@ def test_add_filter_with_matchms_filter(spectrums):\\n     assert filters[-1].__name__ == \\\"require_correct_ionmode\\\"\\n     spectrums, _ = processor.process_spectrums(spectrums, create_report=True)\\n     assert not spectrums, \\\"Expected to be empty list\\\"\\n+\\n+\\n+def test_all_filters_is_complete():\\n+    \\\"\\\"\\\"Checks that the global varible ALL_FILTERS contains all the available filters\\n+\\n+    This is important, since performing tests in the wrong order can make some filters useless.\\n+    \\\"\\\"\\\"\\n+    def get_functions_from_file(file_path):\\n+        \\\"\\\"\\\"Gets all python functions in a file\\\"\\\"\\\"\\n+        with open(file_path, 'r', encoding=\\\"utf-8\\\") as file:\\n+            tree = ast.parse(file.read(), filename=file_path)\\n+        functions = []\\n+        for node in ast.walk(tree):\\n+            if isinstance(node, ast.FunctionDef):\\n+                functions.append(node.name)\\n+        return functions\\n+\\n+    current_dir = os.path.dirname(os.path.abspath(__file__))\\n+    filtering_directory = os.path.join(current_dir, \\\"../../matchms/filtering\\\")\\n+    directories_with_filters = [\\\"metadata_processing\\\",\\n+                                \\\"peak_processing\\\"]\\n+\\n+    all_filters = [filter.__name__ for filter in ALL_FILTERS]\\n+    list_of_filter_function_names = []\\n+    for directory_with_filters in directories_with_filters:\\n+        directory_with_filters = os.path.join(filtering_directory, directory_with_filters)\\n+        scripts = os.listdir(directory_with_filters)\\n+        for script in scripts:\\n+            # Remove __init__\\n+            if script[0] == \\\"_\\\":\\n+                break\\n+            if script[-3:] == \\\".py\\\":\\n+                functions = get_functions_from_file(os.path.join(directory_with_filters, script))\\n+                for function in functions:\\n+                    if function[0] != \\\"_\\\":\\n+                        list_of_filter_function_names.append((script, function))\\n+    for script, filter_function in list_of_filter_function_names:\\n+        assert filter_function in all_filters, \\\\\\n+            f\\\"The function {filter_function} in the script {script} is not given in ALL_FILTERS, \\\" \\\\\\n+            f\\\"this should be added to ensure a correct order of filter functions.\\\" \\\\\\n+            f\\\"If this function is not a filter add a _ before the function name\\\"\\n+\\n+\\n+def test_all_filters_no_duplicates():\\n+    all_filters = [filter.__name__ for filter in ALL_FILTERS]\\n+    assert len(all_filters) == len(set(all_filters)), \\\"One of the filters appears twice in ALL_FILTERS\\\"\"]", "hints_text": ""}
