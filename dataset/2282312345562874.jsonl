{"instance_id": "2282312345562874", "repo": "vendi-ai/declarai", "base_commit": "2ad9ea3e8343d5b7629633282bf01de994d40a8d", "problem_statement": "Enable custom API headers to work with Azure OpenAI or Open Router:\\nhttps://www.reddit.com/r/LocalLLaMA/comments/15laymb/comment/jvgugw9/?utm_source=share&utm_medium=web2x&context=3", "FAIL_TO_PASS": ["tests/api/test_task_decorator.py::test_task_decorator_no_args", "tests/api/test_chat_decorator.py::test_chat", "tests/test_declarai.py::test_declarai_openai", "tests/test_declarai.py::test_declarai_azure_openai", "tests/operators/openai_operators/test_chat_operator.py::test_chat_openai_operator", "tests/test_declarai.py::test_declarai"], "PASS_TO_PASS": ["tests/operators/shared/test_output_prompt.py::test_output_prompt[foo--the", "tests/python_parser/annotations/test_type_annotation_to_schema.py::test_type_hint_resolver[bool-bool]", "tests/python_parser/annotations/test_type_annotation_to_schema.py::test_type_hint_resolver[str-str]", "tests/operators/shared/test_output_prompt.py::test_output_prompt[foo-int--\"foo\":", "tests/python_parser/annotations/test_type_annotation_to_schema.py::test_type_hint_resolver[MockSimpleModel-{{\\n", "tests/python_parser/docstring_parsers/reST/test_parser.py::test_reST_docstring_parser[This", "tests/operators/test_operator_resolver.py::test_resolve_openai_operator_without_token", "tests/python_parser/annotations/test_type_annotation_to_schema.py::test_type_hint_resolver[Dict-Dict[number,", "tests/operators/shared/test_output_prompt.py::test_output_prompt[foo-int-the", "tests/python_parser/annotations/test_type_annotation_to_schema.py::test_type_hint_resolver[int-int]", "tests/python_parser/annotations/test_type_annotation_to_schema.py::test_type_hint_resolver[Dict-Dict[string,", "tests/operators/openai_operators/test_operator.py::test_openai_operator", "tests/operators/shared/test_output_prompt.py::test_output_prompt[-int--\"declarai_result\":", "tests/operators/base/test_llm_settings.py::test_llm_settings", "tests/operators/shared/test_output_prompt.py::test_output_prompt[-int-the", "tests/python_parser/test_function_parser.py::test_output_prompt", "tests/python_parser/test_magic_parser.py::test_magic_parser", "tests/python_parser/annotations/test_type_annotation_to_schema.py::test_type_hint_resolver[MockComplexModelArray-{{\\n", "tests/python_parser/annotations/test_type_annotation_to_schema.py::test_type_hint_resolver[List-List[{{'name':", "tests/python_parser/annotations/test_type_annotation_to_schema.py::test_type_hint_resolver[MockComplexModelDict-{{\\n", "tests/operators/shared/test_output_prompt.py::test_output_prompt[---]", "tests/orchestrator/test_task_orchestrator.py::test_task", "tests/operators/test_operator_resolver.py::test_resolve_openai_operator_with_token", "tests/operators/shared/test_output_prompt.py::test_output_prompt[--the", "tests/operators/test_operator_resolver.py::test_resolve_openai_operator_no_token_raises_error", "tests/operators/shared/test_output_prompt.py::test_output_prompt[foo---\"foo\":", "tests/operators/shared/test_output_prompt.py::test_compile_output_prompt", "tests/python_parser/annotations/test_type_annotation_to_schema.py::test_type_hint_resolver[List-List[string]]", "tests/python_parser/annotations/test_type_annotation_to_schema.py::test_type_hint_resolver[float-float]"], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/vendi-ai_declarai:2ad9ea3e8343d5b7629633282bf01de994d40a8d", "patch": "", "test_patch": "[\"diff --git a/src/declarai/operators/llm.py b/src/declarai/operators/llm.py\\nindex 3dc29cf..6bd1f82 100644\\n--- a/src/declarai/operators/llm.py\\n+++ b/src/declarai/operators/llm.py\\n@@ -66,7 +66,7 @@ def __init__(\\n         self.version = version\\n \\n     @property\\n-    def model(self, delimiter: Optional[str] = \\\"-\\\") -> str:\\n+    def model(self, delimiter: Optional[str] = \\\"-\\\", with_version: bool = True) -> str:\\n         \\\"\\\"\\\"\\n         Some model providers allow defining a base model as well as a sub-model.\\n         Often the base model is an alias to latest model served on that model.\\n@@ -91,7 +91,7 @@ def model(self, delimiter: Optional[str] = \\\"-\\\") -> str:\\n         In any case you can always pass the full model name in the model parameter and leave the\\n         sub_model parameter empty if you prefer.\\n         \\\"\\\"\\\"\\n-        if self.version:\\n+        if self.version and with_version:\\n             return f\\\"{self._model}{delimiter}{self.version}\\\"\\n         return self._model\\n \\n\",\"diff --git a/tests/api/test_chat_decorator.py b/tests/api/test_chat_decorator.py\\nindex c6f156f..fee350d 100644\\n--- a/tests/api/test_chat_decorator.py\\n+++ b/tests/api/test_chat_decorator.py\\n@@ -4,8 +4,9 @@\\n from declarai.operators import Message, MessageRole\\n \\n \\n+@patch(\\\"declarai.declarai.resolve_llm\\\")\\n @patch(\\\"declarai.chat.resolve_operator\\\")\\n-def test_chat(mock_chat_resolve_operator):\\n+def test_chat(mock_chat_resolve_operator, mock_resolve_llm):\\n     operator_class_mock = MagicMock()\\n     operator_instance_mock = MagicMock()\\n \\n@@ -15,7 +16,8 @@ def test_chat(mock_chat_resolve_operator):\\n     operator_class_mock.return_value = operator_instance_mock\\n \\n     llm = MagicMock()\\n-    mock_chat_resolve_operator.return_value = (operator_class_mock, llm)\\n+    mock_chat_resolve_operator.return_value = operator_class_mock\\n+    mock_resolve_llm.return_value = llm\\n     declarai = Declarai(provider=\\\"test\\\", model=\\\"test\\\")\\n \\n     @declarai.experimental.chat\\n\",\"diff --git a/tests/api/test_task_decorator.py b/tests/api/test_task_decorator.py\\nindex e19823c..0b740f2 100644\\n--- a/tests/api/test_task_decorator.py\\n+++ b/tests/api/test_task_decorator.py\\n@@ -7,7 +7,6 @@\\n @patch(\\\"declarai.task.PythonParser\\\")\\n @patch(\\\"declarai.task.resolve_operator\\\")\\n def test_task_decorator_no_args(mocked_resolve_operator, mocked_python_parser):\\n-    llm_settings = MagicMock()\\n     operator_class_mock = MagicMock()\\n     operator_instance_mock = MagicMock()\\n     llm = MagicMock()\\n@@ -17,12 +16,12 @@ def test_task_decorator_no_args(mocked_resolve_operator, mocked_python_parser):\\n     mocked_python_parser.return_value = MagicMock()\\n     operator_instance_mock.parsed = mocked_python_parser.return_value\\n     operator_class_mock.return_value = operator_instance_mock\\n-    mocked_resolve_operator.return_value = (operator_class_mock, llm)\\n+    mocked_resolve_operator.return_value = operator_class_mock\\n \\n     middlewares = [middleware]\\n \\n     task_decorator = TaskDecorator(\\n-        llm_settings=llm_settings, middlewares=middlewares\\n+        llm=llm\\n     )\\n     decorator = task_decorator.task\\n \\n@@ -38,7 +37,7 @@ def test_task(a: str, b: int) -> str:\\n         \\\"\\\"\\\"\\n         return magic(\\\"return_name\\\", a=a, b=b)\\n \\n-    assert task_decorator.llm_settings == llm_settings\\n+    assert task_decorator.llm == llm\\n     assert test_task.middlewares == middlewares\\n     assert test_task.__name__ == \\\"test_task\\\"\\n     assert test_task.operator.parsed == mocked_python_parser.return_value\\n\",\"diff --git a/tests/operators/openai_operators/test_chat_operator.py b/tests/operators/openai_operators/test_chat_operator.py\\nnew file mode 100644\\nindex 0000000..5327c37\\n--- /dev/null\\n+++ b/tests/operators/openai_operators/test_chat_operator.py\\n@@ -0,0 +1,40 @@\\n+from declarai.operators import OpenAILLM, OpenAIChatOperator\\n+from declarai.python_parser.parser import PythonParser\\n+\\n+\\n+def test_chat_openai_operator():\\n+    openai_operator_class = OpenAIChatOperator\\n+    llm = OpenAILLM(\\n+        openai_token=\\\"test-token\\\",\\n+        model=\\\"test-model\\\",\\n+    )\\n+\\n+    class MyChat:\\n+        \\\"\\\"\\\"\\n+        This is my beloved chat\\n+        \\\"\\\"\\\"\\n+\\n+    parsed = PythonParser(MyChat)\\n+    openai_operator_instance = openai_operator_class(parsed=parsed, llm=llm)\\n+    assert openai_operator_instance.parsed.name == MyChat.__name__\\n+    compiled = openai_operator_instance.compile(messages=[])\\n+    assert isinstance(compiled, dict)\\n+    messages = list(compiled[\\\"messages\\\"])\\n+    assert len(messages) == 1\\n+    assert (\\n+        messages[0].message == \\\"This is my beloved chat\\\"\\n+    )\\n+    assert messages[0].role == \\\"system\\\"\\n+\\n+    # def openai_task():\\n+    #     ...\\n+    #\\n+    # parsed = PythonParser(openai_task)\\n+    # openai_operator_instance = openai_operator_class(parsed=parsed, llm=llm)\\n+    # assert openai_operator_instance.parsed.name == openai_task.__name__\\n+    # compiled = openai_operator_instance.compile()\\n+    # assert isinstance(compiled, dict)\\n+    # messages = list(compiled[\\\"messages\\\"])\\n+    # assert len(messages) == 1\\n+    # assert messages[0].message == \\\"\\\\n\\\\n\\\"\\n+    # assert messages[0].role == \\\"user\\\"\\n\",\"diff --git a/tests/operators/openai_operators/test_operator.py b/tests/operators/openai_operators/test_operator.py\\nindex f8a4d9c..8ac326d 100644\\n--- a/tests/operators/openai_operators/test_operator.py\\n+++ b/tests/operators/openai_operators/test_operator.py\\n@@ -1,4 +1,4 @@\\n-from declarai.operators import OpenAITaskOperator, OpenAILLM\\n+from declarai.operators import OpenAILLM, OpenAITaskOperator\\n from declarai.python_parser.parser import PythonParser\\n \\n \\n\",\"diff --git a/tests/operators/shared/test_output_prompt.py b/tests/operators/shared/test_output_prompt.py\\nindex b7a2a6d..f95f9e8 100644\\n--- a/tests/operators/shared/test_output_prompt.py\\n+++ b/tests/operators/shared/test_output_prompt.py\\n@@ -1,8 +1,7 @@\\n import pytest\\n \\n from declarai.operators.openai_operators.task_operator import compile_output_prompt\\n-from declarai.operators.templates import compile_output_schema_template\\n-from declarai.operators.templates import StructuredOutputInstructionPrompt\\n+from declarai.operators.templates import StructuredOutputInstructionPrompt, compile_output_schema_template\\n \\n \\n @pytest.mark.parametrize(\\n\",\"diff --git a/tests/operators/test_operator_resolver.py b/tests/operators/test_operator_resolver.py\\nindex 9073a8e..6b912e7 100644\\n--- a/tests/operators/test_operator_resolver.py\\n+++ b/tests/operators/test_operator_resolver.py\\n@@ -3,19 +3,17 @@\\n \\n import pytest\\n \\n-from declarai.operators import resolve_operator\\n-from declarai.operators import LLMSettings\\n-from declarai.operators.openai_operators import OpenAITaskOperator\\n-from declarai.operators.openai_operators import OpenAIError\\n+from declarai.operators import LLMSettings, resolve_operator, resolve_llm, AzureOpenAITaskOperator\\n+from declarai.operators.openai_operators import OpenAIError, OpenAITaskOperator\\n \\n \\n def test_resolve_openai_operator_with_token():\\n     kwargs = {\\\"openai_token\\\": \\\"test_token\\\"}\\n-    llm_settings = LLMSettings(provider=\\\"openai\\\", model=\\\"davinci\\\")\\n-    operator, llm = resolve_operator(llm_settings, operator_type=\\\"task\\\", **kwargs)\\n+    llm = resolve_llm(provider=\\\"openai\\\", model=\\\"davinci\\\", **kwargs)\\n+    operator = resolve_operator(llm_instance=llm, operator_type=\\\"task\\\")\\n     assert operator == OpenAITaskOperator\\n     assert llm.model == \\\"davinci\\\"\\n-    assert llm.openai.api_key  == kwargs[\\\"openai_token\\\"]\\n+    assert llm.api_key == kwargs[\\\"openai_token\\\"]\\n \\n \\n @patch(\\n@@ -23,12 +21,23 @@ def test_resolve_openai_operator_with_token():\\n     \\\"test_token\\\",\\n )\\n def test_resolve_openai_operator_without_token():\\n-    llm_settings = LLMSettings(provider=\\\"openai\\\", model=\\\"davinci\\\")\\n-    operator, llm = resolve_operator(llm_settings, operator_type=\\\"task\\\")\\n+    llm = resolve_llm(provider=\\\"openai\\\", model=\\\"davinci\\\")\\n+    operator = resolve_operator(llm, operator_type=\\\"task\\\")\\n     assert operator == OpenAITaskOperator\\n \\n \\n def test_resolve_openai_operator_no_token_raises_error():\\n     with pytest.raises(OpenAIError):\\n-        llm_settings = LLMSettings(provider=\\\"openai\\\", model=\\\"davinci\\\")\\n-        resolve_operator(llm_settings, operator_type=\\\"task\\\")\\n+        llm = resolve_llm(provider=\\\"openai\\\", model=\\\"davinci\\\")\\n+        resolve_operator(llm, operator_type=\\\"task\\\")\\n+\\n+\\n+def test_resolve_azure_operator():\\n+    llm = resolve_llm(\\n+        provider=\\\"azure-openai\\\",\\n+        model=\\\"test\\\",\\n+        azure_openai_key=\\\"123\\\",\\n+        azure_openai_api_base=\\\"456\\\",\\n+    )\\n+    operator = resolve_operator(llm, operator_type=\\\"task\\\")\\n+    assert operator == AzureOpenAITaskOperator\\n\",\"diff --git a/tests/operators/test_resolve_llm.py b/tests/operators/test_resolve_llm.py\\nnew file mode 100644\\nindex 0000000..0b693b0\\n--- /dev/null\\n+++ b/tests/operators/test_resolve_llm.py\\n@@ -0,0 +1,9 @@\\n+import pytest\\n+\\n+from declarai.operators.openai_operators import OpenAIError\\n+from declarai.operators import resolve_llm\\n+\\n+\\n+def test_resolve_openai_operator_no_token_raises_error():\\n+    with pytest.raises(OpenAIError):\\n+        resolve_llm(provider=\\\"openai\\\", model=\\\"davinci\\\")\\n\",\"diff --git a/tests/python_parser/annotations/test_type_annotation_to_schema.py b/tests/python_parser/annotations/test_type_annotation_to_schema.py\\nindex 009e491..7d5c509 100644\\n--- a/tests/python_parser/annotations/test_type_annotation_to_schema.py\\n+++ b/tests/python_parser/annotations/test_type_annotation_to_schema.py\\n@@ -3,9 +3,7 @@\\n import pytest\\n from pydantic import BaseModel, Field\\n \\n-from declarai.python_parser.type_annotation_to_schema import (\\n-    type_annotation_to_str_schema,\\n-)\\n+from declarai.python_parser.type_annotation_to_schema import type_annotation_to_str_schema\\n \\n \\n class MockSimpleModel(BaseModel):\\n\",\"diff --git a/tests/tasks/test_llm_chat.py b/tests/tasks/test_llm_chat.py\\nindex fbd50e9..785c105 100644\\n--- a/tests/tasks/test_llm_chat.py\\n+++ b/tests/tasks/test_llm_chat.py\\n@@ -2,19 +2,10 @@\\n #\\n # from pytest import fixture\\n #\\n-# from declarai.operators.base.types import Message\\n-# from declarai.tasks.llm_chat import LLMChat\\n+# from declarai.operators import Message\\n+# from declarai.chat import Chat\\n #\\n-# CHAT_TEMPLATE = \\\"{system_prompt}{output_instructions}\\\"\\n-# TEMPLATE_KWARGS = {\\n-#     \\\"system_prompt\\\": \\\"You are an assistant making people laugh.\\\",\\n-#     \\\"output_instructions\\\": \\\"\\\",\\n-# }\\n #\\n-# SYSTEM_MESSAGE = Message(\\n-#     message=\\\"You are an assistant making people laugh.\\\",\\n-#     role=\\\"system\\\",\\n-# )\\n #\\n #\\n # def test_chat_message():\\n@@ -34,10 +25,9 @@\\n # def llm_chat():\\n #     test_llm = MagicMock()\\n #     test_llm.predict.return_value = MagicMock()\\n-#     llm_chat = LLMChat(\\n-#         template=CHAT_TEMPLATE,\\n-#         template_kwargs=TEMPLATE_KWARGS,\\n-#         llm=test_llm,\\n+#     llm_chat = Chat(\\n+#         system=\\\"You are a translator from english to french\\\",\\n+#         operator,\\n #         prompt_kwargs={\\\"structured\\\": False},\\n #     )\\n #     return llm_chat\\n\",\"diff --git a/tests/test_declarai.py b/tests/test_declarai.py\\nindex f7e9e72..70f21bb 100644\\n--- a/tests/test_declarai.py\\n+++ b/tests/test_declarai.py\\n@@ -3,18 +3,53 @@\\n from declarai import Declarai\\n \\n \\n-@patch(\\\"declarai.task.resolve_operator\\\")\\n+@patch(\\\"declarai.declarai.resolve_llm\\\")\\n @patch(\\\"declarai.declarai.TaskDecorator\\\")\\n-@patch(\\\"declarai.declarai.LLMSettings\\\")\\n-def test_declarai(mocked_llm_settings, mocked_task_decorator, _):\\n+def test_declarai(mocked_task_decorator, mocked_resolve_llm):\\n     kwargs = {}\\n-    mocked_llm_settings.return_value = MagicMock()\\n+    mocked_resolve_llm.return_value = MagicMock()\\n     mocked_task_decorator.return_value.task = MagicMock()\\n \\n-    declarai = Declarai(**kwargs)\\n+    declarai = Declarai(provider=\\\"test\\\",\\n \\n-    assert declarai.llm_settings == mocked_llm_settings.return_value\\n+                        **kwargs)\\n+\\n+    assert declarai.llm == mocked_resolve_llm.return_value\\n     assert declarai.task == mocked_task_decorator.return_value.task\\n \\n     # Test experimental apis\\n     assert declarai.experimental\\n+\\n+\\n+def test_declarai_openai():\\n+    kwargs = {\\n+        \\\"model\\\": \\\"davinci\\\",\\n+        \\\"openai_token\\\": \\\"test_token\\\"\\n+    }\\n+    declarai = Declarai.openai(\\n+        **kwargs\\n+    )\\n+\\n+    assert declarai.llm.provider == \\\"openai\\\"\\n+    assert declarai.llm.model == \\\"davinci\\\"\\n+    assert declarai.llm.api_key == \\\"test_token\\\"\\n+\\n+\\n+\\n+def test_declarai_azure_openai():\\n+    kwargs = {\\n+        \\\"deployment_name\\\": \\\"test\\\",\\n+        \\\"azure_openai_key\\\": \\\"123\\\",\\n+        \\\"azure_openai_api_base\\\": \\\"456\\\",\\n+        \\\"api_version\\\": \\\"789\\\",\\n+    }\\n+    declarai = Declarai.azure_openai(\\n+        **kwargs\\n+    )\\n+\\n+    assert declarai.llm.provider == \\\"azure-openai\\\"\\n+    assert declarai.llm.model == \\\"test\\\"\\n+    assert declarai.llm.api_key == \\\"123\\\"\\n+    assert declarai.llm._kwargs[\\\"api_base\\\"] == \\\"456\\\"\\n+    assert declarai.llm._kwargs[\\\"api_version\\\"] == \\\"789\\\"\\n+\\n\"]", "hints_text": ""}
