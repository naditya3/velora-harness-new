{"instance_id": "2208026702944834", "repo": "sdv-dev/sdv", "base_commit": "8b95b135c65a4e29b3741bcf660dd8d4264eb405", "problem_statement": "Make function to estimate number of columns HMA produces.:\\n### Problem Description\\r\\n\\r\\n_As a user, I'd like to know as soon as possible if HMA will be slow so that I can properly decide whether or not to use it._\\r\\n\\r\\n### Expected behavior\\r\\n\\r\\n- Inside `HMASynthesizer`, add a function that can estimate the number or columns that will be modeled for each root table. We will use this later to give alerts.\\r\\n\\r\\nIt is understood that the exact number of rows varies depending on the transformers, constraints etc. For this reason, we only need an estimate. You can make the following assumptions:\\r\\n- Assume the default transformers are being used\\r\\n- Assume no constraints\\r\\n\\r\\n#### Requirements\\r\\n\\r\\n- The estimate should be the same order of magnitude as the actual answer.\\r\\n- It should be performant (don't go overboard on trying to make calculations more precise at the cost of performance).\\r\\n\\r\\n### Additional context\\r\\n\\r\\nThe following tips may help:\\r\\n- If a parent has a child with n columns\\r\\n    - A covariance matrix with O(n^2) columns will be added to it\\r\\n    - A column for the mean and standard deviation of the parent row will be added to it\\r\\n    - At least n columns will be added for the marginal distribution parameters\\r\\n    - At least one column will be added for the cardinality\\r\\n", "FAIL_TO_PASS": ["tests/unit/multi_table/test_hma.py::TestHMASynthesizer::test__estimate_num_columns_to_be_modeled_various_sdtypes", "tests/unit/multi_table/test_hma.py::TestHMASynthesizer::test__estimate_num_columns_to_be_modeled", "tests/unit/multi_table/test_hma.py::TestHMASynthesizer::test__estimate_num_columns_to_be_modeled_multiple_foreign_keys", "tests/unit/multi_table/test_hma.py::TestHMASynthesizer::test__estimate_num_columns_to_be_modeled_different_distributions"], "PASS_TO_PASS": [], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/sdv-dev_sdv:8b95b135c65a4e29b3741bcf660dd8d4264eb405", "patch": "[\"diff --git a/sdv/multi_table/hma.py b/sdv/multi_table/hma.py\\nindex 22f095aa7..43ba44e79 100644\\n--- a/sdv/multi_table/hma.py\\n+++ b/sdv/multi_table/hma.py\\n@@ -44,6 +44,85 @@ def __init__(self, metadata, locales=None, verbose=True):\\n             self._table_synthesizers,\\n             self._table_sizes)\\n \\n+    def _num_extended_columns(self, table_name, parent_name, columns_per_table):\\n+        \\\"\\\"\\\"Get the number of columns that will be generated for table_name.\\n+\\n+        A table generates:\\n+            - 1 num_rows column for each for each foreign key with a specific parent\\n+            - n*(n-1)/2 correlation columns for each data column\\n+            - 4 parameters columns for each data column, with:\\n+                - 1 column for parameter a\\n+                - 1 column for parameter b\\n+                - 1 column for parameter scale\\n+                - 1 column for parameter loc\\n+        \\\"\\\"\\\"\\n+        # num_rows columns\\n+        # Since HMA only supports one relationship between two tables, this should always be 1\\n+        num_cardinality_columns = len(self.metadata._get_foreign_keys(parent_name, table_name))\\n+\\n+        # no parameter columns are generated if there are no data columns\\n+        num_data_columns = columns_per_table[table_name]\\n+        if num_data_columns == 0:\\n+            return num_cardinality_columns\\n+\\n+        num_correlation_columns = (num_data_columns - 1) * num_data_columns // 2\\n+        num_parameters_columns = num_data_columns * 4\\n+\\n+        return num_correlation_columns + num_cardinality_columns + num_parameters_columns\\n+\\n+    def _estimate_columns_traversal(self, table_name, columns_per_table, visited):\\n+        \\\"\\\"\\\"Given a table, estimate how many columns each parent will model.\\n+\\n+        This method recursiverly models the children of a table all the way to the leaf nodes.\\n+        \\\"\\\"\\\"\\n+        for child_name in self.metadata._get_child_map()[table_name]:\\n+            if child_name not in visited:\\n+                self._estimate_columns_traversal(child_name, columns_per_table, visited)\\n+\\n+            columns_per_table[table_name] += \\\\\\n+                self._num_extended_columns(child_name, table_name, columns_per_table)\\n+\\n+        visited.add(table_name)\\n+\\n+    def _estimate_number_of_modeled_columns(self):\\n+        \\\"\\\"\\\"Estimate the number of columns that will be modeled for each root table.\\n+\\n+        This method estimates how many extended columns will be generated during the\\n+        `_augment_tables` method, so it traverses the graph in the same way.\\n+        If that method is ever changed, this should be updated to match.\\n+\\n+        After running this method, `columns_per_table` will store an estimate of the\\n+        total number of columns that each table has after running `_augment_tables`,\\n+        that is, the number of extended columns generated by the child tables as well\\n+        as the number of data columns in the table itself. Foreign keys and primary\\n+        keys are not counted, since they are not modeled.\\n+\\n+        Returns:\\n+            dict:\\n+                Dictionary of (table_name: int) mappings, indicating the estimated\\n+                number of columns that will be modeled for each root table.\\n+        \\\"\\\"\\\"\\n+        # This dict will store the number of data columns + extended columns for each table\\n+        # Initialize it with the number of data columns per table\\n+        columns_per_table = {}\\n+        for table_name in self.metadata.tables:\\n+            num_fks = len(self.metadata._get_all_foreign_keys(table_name))\\n+            num_pks = 1\\n+            total_cols = len(self.metadata.tables[table_name].columns)\\n+            num_data_columns = total_cols - num_fks - num_pks\\n+            columns_per_table[table_name] = num_data_columns\\n+\\n+        # Starting at root tables, recursively estimate the number of columns\\n+        # each table will model\\n+        visited = set()\\n+        non_root_tables = set(self.metadata._get_parent_map().keys())\\n+        root_parents = set(self.metadata.tables.keys()) - non_root_tables\\n+        for table_name in root_parents:\\n+            self._estimate_columns_traversal(table_name, columns_per_table, visited)\\n+\\n+        # Select only the root tables\\n+        return {table_name: columns_per_table[table_name] for table_name in root_parents}\\n+\\n     def _get_extension(self, child_name, child_table, foreign_key, progress_bar_desc):\\n         \\\"\\\"\\\"Generate the extension columns for this child table.\\n \\n@@ -145,7 +224,6 @@ def _augment_table(self, table, tables, table_name):\\n         for child_name in child_map:\\n             if child_name not in self._augmented_tables:\\n                 child_table = self._augment_table(tables[child_name], tables, child_name)\\n-\\n             else:\\n                 child_table = tables[child_name]\\n \\n\",\"diff --git a/sdv/multi_table/hma.py b/sdv/multi_table/hma.py\\nindex 43ba44e79..d99c526a6 100644\\n--- a/sdv/multi_table/hma.py\\n+++ b/sdv/multi_table/hma.py\\n@@ -250,6 +250,25 @@ def _augment_table(self, table, tables, table_name):\\n         self._clear_nans(table)\\n         return table\\n \\n+    def _augment_tables(self, processed_data):\\n+        \\\"\\\"\\\"Fit this ``HMASynthesizer`` instance to the dataset data.\\n+\\n+        Args:\\n+            processed_data (dict):\\n+                Dictionary mapping each table name to a preprocessed ``pandas.DataFrame``.\\n+        \\\"\\\"\\\"\\n+        augmented_data = deepcopy(processed_data)\\n+        self._augmented_tables = []\\n+        self._learned_relationships = 0\\n+        parent_map = self.metadata._get_parent_map()\\n+        self._print(text='Learning relationships:')\\n+        for table_name in processed_data:\\n+            if not parent_map.get(table_name):\\n+                self._augment_table(augmented_data[table_name], augmented_data, table_name)\\n+\\n+        LOGGER.info('Augmentation Complete')\\n+        return augmented_data\\n+\\n     def _pop_foreign_keys(self, table_data, table_name):\\n         \\\"\\\"\\\"Remove foreign keys from the ``table_data``.\\n \\n@@ -297,25 +316,6 @@ def _model_tables(self, augmented_data):\\n             for name, values in keys.items():\\n                 table[name] = values\\n \\n-    def _augment_tables(self, processed_data):\\n-        \\\"\\\"\\\"Fit this ``HMASynthesizer`` instance to the dataset data.\\n-\\n-        Args:\\n-            processed_data (dict):\\n-                Dictionary mapping each table name to a preprocessed ``pandas.DataFrame``.\\n-        \\\"\\\"\\\"\\n-        augmented_data = deepcopy(processed_data)\\n-        self._augmented_tables = []\\n-        self._learned_relationships = 0\\n-        parent_map = self.metadata._get_parent_map()\\n-        self._print(text='Learning relationships:')\\n-        for table_name in processed_data:\\n-            if not parent_map.get(table_name):\\n-                self._augment_table(augmented_data[table_name], augmented_data, table_name)\\n-\\n-        LOGGER.info('Augmentation Complete')\\n-        return augmented_data\\n-\\n     def _extract_parameters(self, parent_row, table_name, foreign_key):\\n         \\\"\\\"\\\"Get the params from a generated parent row.\\n \\n\",\"diff --git a/sdv/multi_table/hma.py b/sdv/multi_table/hma.py\\nindex d99c526a6..7af901485 100644\\n--- a/sdv/multi_table/hma.py\\n+++ b/sdv/multi_table/hma.py\\n@@ -201,10 +201,11 @@ def _clear_nans(table_data):\\n             table_data[column] = table_data[column].fillna(fill_value)\\n \\n     def _augment_table(self, table, tables, table_name):\\n-        \\\"\\\"\\\"Generate the extension columns for this table.\\n+        \\\"\\\"\\\"Recursively generate the extension columns for the tables in the graph.\\n \\n         For each of the table's foreign keys, generate the related extension columns,\\n-        and extend the provided table.\\n+        and extend the provided table. Generate them first for the top level tables,\\n+        then their children, and so on.\\n \\n         Args:\\n             table (pandas.DataFrame):\\n@@ -344,6 +345,8 @@ def _extract_parameters(self, parent_row, table_name, foreign_key):\\n         return flat_parameters.rename(new_keys).to_dict()\\n \\n     def _recreate_child_synthesizer(self, child_name, parent_name, parent_row):\\n+        # When more than one foreign key exists between two tables, only the first one\\n+        # will be modeled.\\n         foreign_key = self.metadata._get_foreign_keys(parent_name, child_name)[0]\\n         parameters = self._extract_parameters(parent_row, child_name, foreign_key)\\n         table_meta = self.metadata.tables[child_name]\\n@@ -453,7 +456,7 @@ def _find_parent_ids(self, child_table, parent_table, child_name, parent_name, f\\n             pandas.Series:\\n                 The parent ids for the given table data.\\n         \\\"\\\"\\\"\\n-        # Create a copy of the parent table with the primary key as index to calculate likilihoods\\n+        # Create a copy of the parent table with the primary key as index to calculate likelihoods\\n         primary_key = self.metadata.tables[parent_name].primary_key\\n         parent_table = parent_table.set_index(primary_key)\\n         num_rows = parent_table[f'__{child_name}__{foreign_key}__num_rows'].fillna(0).clip(0)\\n\",\"diff --git a/sdv/sampling/hierarchical_sampler.py b/sdv/sampling/hierarchical_sampler.py\\nindex 6b2c8f4bf..9648f1d39 100644\\n--- a/sdv/sampling/hierarchical_sampler.py\\n+++ b/sdv/sampling/hierarchical_sampler.py\\n@@ -60,7 +60,7 @@ def _sample_rows(self, synthesizer, num_rows=None):\\n         Args:\\n             synthesizer (copula.multivariate.base):\\n                 The fitted synthesizer for the table.\\n-            num_rows (int):\\n+            num_rows (int or float):\\n                 Number of rows to sample.\\n \\n         Returns:\\n@@ -96,6 +96,8 @@ def _add_child_rows(self, child_name, parent_name, parent_row, sampled_data):\\n             sampled_data (dict):\\n                 A dictionary mapping table names to sampled data (pd.DataFrame).\\n         \\\"\\\"\\\"\\n+        # When more than one foreign key exists between two tables, only the first one\\n+        # will be modeled.\\n         foreign_key = self.metadata._get_foreign_keys(parent_name, child_name)[0]\\n         num_rows = self._get_num_rows_from_parent(parent_row, child_name, foreign_key)\\n         child_synthesizer = self._recreate_child_synthesizer(child_name, parent_name, parent_row)\\n@@ -204,6 +206,9 @@ def _sample(self, scale=1.0):\\n         for relationship in self.metadata.relationships:\\n             parent_name = relationship['parent_table_name']\\n             child_name = relationship['child_table_name']\\n+            # When more than one relationship exists between two tables, only the first one\\n+            # is modeled. This means that every foreign key besides the first one is already\\n+            # in the table, since they were never removed and were treated as normal data instead.\\n             if (parent_name, child_name) not in added_relationships:\\n                 self._add_foreign_key_columns(\\n                     sampled_data[child_name],\\n\",\"diff --git a/sdv/multi_table/hma.py b/sdv/multi_table/hma.py\\nindex 7af901485..6ad72fb3a 100644\\n--- a/sdv/multi_table/hma.py\\n+++ b/sdv/multi_table/hma.py\\n@@ -345,8 +345,7 @@ def _extract_parameters(self, parent_row, table_name, foreign_key):\\n         return flat_parameters.rename(new_keys).to_dict()\\n \\n     def _recreate_child_synthesizer(self, child_name, parent_name, parent_row):\\n-        # When more than one foreign key exists between two tables, only the first one\\n-        # will be modeled.\\n+        # When more than one foreign key exists between two tables, only the first one is modeled.\\n         foreign_key = self.metadata._get_foreign_keys(parent_name, child_name)[0]\\n         parameters = self._extract_parameters(parent_row, child_name, foreign_key)\\n         table_meta = self.metadata.tables[child_name]\\n\",\"diff --git a/sdv/sampling/hierarchical_sampler.py b/sdv/sampling/hierarchical_sampler.py\\nindex 9648f1d39..10d37f7de 100644\\n--- a/sdv/sampling/hierarchical_sampler.py\\n+++ b/sdv/sampling/hierarchical_sampler.py\\n@@ -96,8 +96,7 @@ def _add_child_rows(self, child_name, parent_name, parent_row, sampled_data):\\n             sampled_data (dict):\\n                 A dictionary mapping table names to sampled data (pd.DataFrame).\\n         \\\"\\\"\\\"\\n-        # When more than one foreign key exists between two tables, only the first one\\n-        # will be modeled.\\n+        # When more than one foreign key exists between two tables, only the first one is modeled.\\n         foreign_key = self.metadata._get_foreign_keys(parent_name, child_name)[0]\\n         num_rows = self._get_num_rows_from_parent(parent_row, child_name, foreign_key)\\n         child_synthesizer = self._recreate_child_synthesizer(child_name, parent_name, parent_row)\\n@@ -207,8 +206,7 @@ def _sample(self, scale=1.0):\\n             parent_name = relationship['parent_table_name']\\n             child_name = relationship['child_table_name']\\n             # When more than one relationship exists between two tables, only the first one\\n-            # is modeled. This means that every foreign key besides the first one is already\\n-            # in the table, since they were never removed and were treated as normal data instead.\\n+            # is modeled, so that's the only one that needs to be added back.\\n             if (parent_name, child_name) not in added_relationships:\\n                 self._add_foreign_key_columns(\\n                     sampled_data[child_name],\\n\",\"diff --git a/sdv/multi_table/hma.py b/sdv/multi_table/hma.py\\nindex 6ad72fb3a..3d176a38c 100644\\n--- a/sdv/multi_table/hma.py\\n+++ b/sdv/multi_table/hma.py\\n@@ -84,7 +84,16 @@ def _estimate_columns_traversal(self, table_name, columns_per_table, visited):\\n \\n         visited.add(table_name)\\n \\n-    def _estimate_number_of_modeled_columns(self):\\n+    def _get_num_data_columns(self):\\n+        \\\"\\\"\\\"Get the number of data columns, ie colums that are not id/text, for each table.\\\"\\\"\\\"\\n+        columns_per_table = {}\\n+        for table_name, table in self.metadata.tables.items():\\n+            columns_per_table[table_name] = \\\\\\n+                sum([1 for col in table.columns.values() if col['sdtype'] not in ('id', 'text')])\\n+\\n+        return columns_per_table\\n+\\n+    def estimate_number_of_root_columns(self):\\n         \\\"\\\"\\\"Estimate the number of columns that will be modeled for each root table.\\n \\n         This method estimates how many extended columns will be generated during the\\n@@ -94,8 +103,8 @@ def _estimate_number_of_modeled_columns(self):\\n         After running this method, `columns_per_table` will store an estimate of the\\n         total number of columns that each table has after running `_augment_tables`,\\n         that is, the number of extended columns generated by the child tables as well\\n-        as the number of data columns in the table itself. Foreign keys and primary\\n-        keys are not counted, since they are not modeled.\\n+        as the number of data columns in the table itself. `id` and `text` columns,\\n+        like foreign and primary keys, are not counted since they are not modeled.\\n \\n         Returns:\\n             dict:\\n@@ -104,13 +113,7 @@ def _estimate_number_of_modeled_columns(self):\\n         \\\"\\\"\\\"\\n         # This dict will store the number of data columns + extended columns for each table\\n         # Initialize it with the number of data columns per table\\n-        columns_per_table = {}\\n-        for table_name in self.metadata.tables:\\n-            num_fks = len(self.metadata._get_all_foreign_keys(table_name))\\n-            num_pks = 1\\n-            total_cols = len(self.metadata.tables[table_name].columns)\\n-            num_data_columns = total_cols - num_fks - num_pks\\n-            columns_per_table[table_name] = num_data_columns\\n+        columns_per_table = self._get_num_data_columns()\\n \\n         # Starting at root tables, recursively estimate the number of columns\\n         # each table will model\\n\",\"diff --git a/sdv/multi_table/hma.py b/sdv/multi_table/hma.py\\nindex 3d176a38c..3ebb74116 100644\\n--- a/sdv/multi_table/hma.py\\n+++ b/sdv/multi_table/hma.py\\n@@ -56,9 +56,9 @@ def _num_extended_columns(self, table_name, parent_name, columns_per_table):\\n                 - 1 column for parameter scale\\n                 - 1 column for parameter loc\\n         \\\"\\\"\\\"\\n-        # num_rows columns\\n-        # Since HMA only supports one relationship between two tables, this should always be 1\\n-        num_cardinality_columns = len(self.metadata._get_foreign_keys(parent_name, table_name))\\n+        # The `num_rows` column. Because HMA models at most one relationship between\\n+        # two tables, this is always 1\\n+        num_cardinality_columns = 1\\n \\n         # no parameter columns are generated if there are no data columns\\n         num_data_columns = columns_per_table[table_name]\\n@@ -73,7 +73,7 @@ def _num_extended_columns(self, table_name, parent_name, columns_per_table):\\n     def _estimate_columns_traversal(self, table_name, columns_per_table, visited):\\n         \\\"\\\"\\\"Given a table, estimate how many columns each parent will model.\\n \\n-        This method recursiverly models the children of a table all the way to the leaf nodes.\\n+        This method recursively models the children of a table all the way to the leaf nodes.\\n         \\\"\\\"\\\"\\n         for child_name in self.metadata._get_child_map()[table_name]:\\n             if child_name not in visited:\\n\",\"diff --git a/sdv/multi_table/hma.py b/sdv/multi_table/hma.py\\nindex 3ebb74116..77cd6f4d9 100644\\n--- a/sdv/multi_table/hma.py\\n+++ b/sdv/multi_table/hma.py\\n@@ -85,11 +85,11 @@ def _estimate_columns_traversal(self, table_name, columns_per_table, visited):\\n         visited.add(table_name)\\n \\n     def _get_num_data_columns(self):\\n-        \\\"\\\"\\\"Get the number of data columns, ie colums that are not id/text, for each table.\\\"\\\"\\\"\\n+        \\\"\\\"\\\"Get the number of data columns, ie colums that are not id, for each table.\\\"\\\"\\\"\\n         columns_per_table = {}\\n         for table_name, table in self.metadata.tables.items():\\n             columns_per_table[table_name] = \\\\\\n-                sum([1 for col in table.columns.values() if col['sdtype'] not in ('id', 'text')])\\n+                sum([1 for col in table.columns.values() if col['sdtype'] != 'id'])\\n \\n         return columns_per_table\\n \\n@@ -103,8 +103,8 @@ def estimate_number_of_root_columns(self):\\n         After running this method, `columns_per_table` will store an estimate of the\\n         total number of columns that each table has after running `_augment_tables`,\\n         that is, the number of extended columns generated by the child tables as well\\n-        as the number of data columns in the table itself. `id` and `text` columns,\\n-        like foreign and primary keys, are not counted since they are not modeled.\\n+        as the number of data columns in the table itself. `id` columns, like foreign\\n+        and primary keys, are not counted since they are not modeled.\\n \\n         Returns:\\n             dict:\\n\",\"diff --git a/sdv/multi_table/hma.py b/sdv/multi_table/hma.py\\nindex 77cd6f4d9..fcbd4f17b 100644\\n--- a/sdv/multi_table/hma.py\\n+++ b/sdv/multi_table/hma.py\\n@@ -44,11 +44,11 @@ def __init__(self, metadata, locales=None, verbose=True):\\n             self._table_synthesizers,\\n             self._table_sizes)\\n \\n-    def _num_extended_columns(self, table_name, parent_name, columns_per_table):\\n+    def _get_num_extended_columns(self, table_name, parent_table, columns_per_table):\\n         \\\"\\\"\\\"Get the number of columns that will be generated for table_name.\\n \\n-        A table generates:\\n-            - 1 num_rows column for each for each foreign key with a specific parent\\n+        A table generates, for each foreign key:\\n+            - 1 num_rows column\\n             - n*(n-1)/2 correlation columns for each data column\\n             - 4 parameters columns for each data column, with:\\n                 - 1 column for parameter a\\n@@ -56,19 +56,17 @@ def _num_extended_columns(self, table_name, parent_name, columns_per_table):\\n                 - 1 column for parameter scale\\n                 - 1 column for parameter loc\\n         \\\"\\\"\\\"\\n-        # The `num_rows` column. Because HMA models at most one relationship between\\n-        # two tables, this is always 1\\n-        num_cardinality_columns = 1\\n+        num_rows_columns = len(self.metadata._get_foreign_keys(parent_table, table_name))\\n \\n         # no parameter columns are generated if there are no data columns\\n         num_data_columns = columns_per_table[table_name]\\n         if num_data_columns == 0:\\n-            return num_cardinality_columns\\n+            return num_rows_columns\\n \\n-        num_correlation_columns = (num_data_columns - 1) * num_data_columns // 2\\n-        num_parameters_columns = num_data_columns * 4\\n+        num_correlation_columns = num_rows_columns * (num_data_columns - 1) * num_data_columns // 2\\n+        num_parameters_columns = num_rows_columns * num_data_columns * 4\\n \\n-        return num_correlation_columns + num_cardinality_columns + num_parameters_columns\\n+        return num_correlation_columns + num_rows_columns + num_parameters_columns\\n \\n     def _estimate_columns_traversal(self, table_name, columns_per_table, visited):\\n         \\\"\\\"\\\"Given a table, estimate how many columns each parent will model.\\n@@ -80,7 +78,7 @@ def _estimate_columns_traversal(self, table_name, columns_per_table, visited):\\n                 self._estimate_columns_traversal(child_name, columns_per_table, visited)\\n \\n             columns_per_table[table_name] += \\\\\\n-                self._num_extended_columns(child_name, table_name, columns_per_table)\\n+                self._get_num_extended_columns(child_name, table_name, columns_per_table)\\n \\n         visited.add(table_name)\\n \\n@@ -93,7 +91,7 @@ def _get_num_data_columns(self):\\n \\n         return columns_per_table\\n \\n-    def estimate_number_of_root_columns(self):\\n+    def _estimate_num_columns(self):\\n         \\\"\\\"\\\"Estimate the number of columns that will be modeled for each root table.\\n \\n         This method estimates how many extended columns will be generated during the\\n@@ -123,8 +121,7 @@ def estimate_number_of_root_columns(self):\\n         for table_name in root_parents:\\n             self._estimate_columns_traversal(table_name, columns_per_table, visited)\\n \\n-        # Select only the root tables\\n-        return {table_name: columns_per_table[table_name] for table_name in root_parents}\\n+        return columns_per_table\\n \\n     def _get_extension(self, child_name, child_table, foreign_key, progress_bar_desc):\\n         \\\"\\\"\\\"Generate the extension columns for this child table.\\n@@ -348,7 +345,7 @@ def _extract_parameters(self, parent_row, table_name, foreign_key):\\n         return flat_parameters.rename(new_keys).to_dict()\\n \\n     def _recreate_child_synthesizer(self, child_name, parent_name, parent_row):\\n-        # When more than one foreign key exists between two tables, only the first one is modeled.\\n+        # A child table is created based on only one foreign key.\\n         foreign_key = self.metadata._get_foreign_keys(parent_name, child_name)[0]\\n         parameters = self._extract_parameters(parent_row, child_name, foreign_key)\\n         table_meta = self.metadata.tables[child_name]\\n\",\"diff --git a/sdv/sampling/hierarchical_sampler.py b/sdv/sampling/hierarchical_sampler.py\\nindex 10d37f7de..b19eeb694 100644\\n--- a/sdv/sampling/hierarchical_sampler.py\\n+++ b/sdv/sampling/hierarchical_sampler.py\\n@@ -96,7 +96,7 @@ def _add_child_rows(self, child_name, parent_name, parent_row, sampled_data):\\n             sampled_data (dict):\\n                 A dictionary mapping table names to sampled data (pd.DataFrame).\\n         \\\"\\\"\\\"\\n-        # When more than one foreign key exists between two tables, only the first one is modeled.\\n+        # A child table is created based on only one foreign key.\\n         foreign_key = self.metadata._get_foreign_keys(parent_name, child_name)[0]\\n         num_rows = self._get_num_rows_from_parent(parent_row, child_name, foreign_key)\\n         child_synthesizer = self._recreate_child_synthesizer(child_name, parent_name, parent_row)\\n@@ -206,7 +206,8 @@ def _sample(self, scale=1.0):\\n             parent_name = relationship['parent_table_name']\\n             child_name = relationship['child_table_name']\\n             # When more than one relationship exists between two tables, only the first one\\n-            # is modeled, so that's the only one that needs to be added back.\\n+            # is used to recreate the child tables, so that's the only one that needs to be\\n+            # added back.\\n             if (parent_name, child_name) not in added_relationships:\\n                 self._add_foreign_key_columns(\\n                     sampled_data[child_name],\\n\",\"diff --git a/sdv/multi_table/hma.py b/sdv/multi_table/hma.py\\nindex fcbd4f17b..7621f8de8 100644\\n--- a/sdv/multi_table/hma.py\\n+++ b/sdv/multi_table/hma.py\\n@@ -50,11 +50,10 @@ def _get_num_extended_columns(self, table_name, parent_table, columns_per_table)\\n         A table generates, for each foreign key:\\n             - 1 num_rows column\\n             - n*(n-1)/2 correlation columns for each data column\\n-            - 4 parameters columns for each data column, with:\\n-                - 1 column for parameter a\\n-                - 1 column for parameter b\\n-                - 1 column for parameter scale\\n-                - 1 column for parameter loc\\n+            - k parameter columns for each data column, where:\\n+                - k = 4 if the distribution is beta or truncnorm (params are a, b, loc, scale)\\n+                - k = 3 if the distribution is gamma (params are a, loc, scale)\\n+                - k = 2 if the distribution is norm or uniform (params are loc, scale)\\n         \\\"\\\"\\\"\\n         num_rows_columns = len(self.metadata._get_foreign_keys(parent_table, table_name))\\n \\n@@ -63,8 +62,16 @@ def _get_num_extended_columns(self, table_name, parent_table, columns_per_table)\\n         if num_data_columns == 0:\\n             return num_rows_columns\\n \\n+        distribution = self.get_table_parameters(table_name)['default_distribution']\\n+        num_parameters_columns = num_rows_columns * num_data_columns\\n+        if distribution in {'beta', 'truncnorm'}:\\n+            num_parameters_columns *= 4\\n+        elif distribution == 'gamma':\\n+            num_parameters_columns *= 3\\n+        elif distribution in {'norm', 'uniform'}:\\n+            num_parameters_columns *= 2\\n+\\n         num_correlation_columns = num_rows_columns * (num_data_columns - 1) * num_data_columns // 2\\n-        num_parameters_columns = num_rows_columns * num_data_columns * 4\\n \\n         return num_correlation_columns + num_rows_columns + num_parameters_columns\\n \\n@@ -72,6 +79,14 @@ def _estimate_columns_traversal(self, table_name, columns_per_table, visited):\\n         \\\"\\\"\\\"Given a table, estimate how many columns each parent will model.\\n \\n         This method recursively models the children of a table all the way to the leaf nodes.\\n+\\n+        Args:\\n+            table_name (str):\\n+                Name of the table to estimate the number of columns for.\\n+            columns_per_table (dict):\\n+                Dict that stores the number of data columns + extended columns for each table.\\n+            visited (set):\\n+                Set of table names that have already been visited.\\n         \\\"\\\"\\\"\\n         for child_name in self.metadata._get_child_map()[table_name]:\\n             if child_name not in visited:\\n\",\"diff --git a/sdv/sampling/hierarchical_sampler.py b/sdv/sampling/hierarchical_sampler.py\\nindex b19eeb694..b69206420 100644\\n--- a/sdv/sampling/hierarchical_sampler.py\\n+++ b/sdv/sampling/hierarchical_sampler.py\\n@@ -217,4 +217,5 @@ def _sample(self, scale=1.0):\\n                 )\\n                 added_relationships.add((parent_name, child_name))\\n \\n+        print(sampled_data['parent'].columns)\\n         return self._finalize(sampled_data)\\n\",\"diff --git a/sdv/sampling/hierarchical_sampler.py b/sdv/sampling/hierarchical_sampler.py\\nindex b69206420..b19eeb694 100644\\n--- a/sdv/sampling/hierarchical_sampler.py\\n+++ b/sdv/sampling/hierarchical_sampler.py\\n@@ -217,5 +217,4 @@ def _sample(self, scale=1.0):\\n                 )\\n                 added_relationships.add((parent_name, child_name))\\n \\n-        print(sampled_data['parent'].columns)\\n         return self._finalize(sampled_data)\\n\",\"diff --git a/sdv/multi_table/hma.py b/sdv/multi_table/hma.py\\nindex 7621f8de8..55013f646 100644\\n--- a/sdv/multi_table/hma.py\\n+++ b/sdv/multi_table/hma.py\\n@@ -107,7 +107,7 @@ def _get_num_data_columns(self):\\n         return columns_per_table\\n \\n     def _estimate_num_columns(self):\\n-        \\\"\\\"\\\"Estimate the number of columns that will be modeled for each root table.\\n+        \\\"\\\"\\\"Estimate the number of columns that will be modeled for each table.\\n \\n         This method estimates how many extended columns will be generated during the\\n         `_augment_tables` method, so it traverses the graph in the same way.\\n@@ -122,7 +122,7 @@ def _estimate_num_columns(self):\\n         Returns:\\n             dict:\\n                 Dictionary of (table_name: int) mappings, indicating the estimated\\n-                number of columns that will be modeled for each root table.\\n+                number of columns that will be modeled for each table.\\n         \\\"\\\"\\\"\\n         # This dict will store the number of data columns + extended columns for each table\\n         # Initialize it with the number of data columns per table\\n\"]", "test_patch": "[\"diff --git a/tests/unit/multi_table/test_hma.py b/tests/unit/multi_table/test_hma.py\\nindex 72e4e5850..cf87d6254 100644\\n--- a/tests/unit/multi_table/test_hma.py\\n+++ b/tests/unit/multi_table/test_hma.py\\n@@ -5,6 +5,7 @@\\n import pandas as pd\\n import pytest\\n \\n+from sdv.metadata.multi_table import MultiTableMetadata\\n from sdv.multi_table.hma import HMASynthesizer\\n from sdv.single_table.copulas import GaussianCopulaSynthesizer\\n from tests.utils import get_multi_table_data, get_multi_table_metadata\\n@@ -496,3 +497,120 @@ def test__add_foreign_key_columns(self):\\n         })\\n         pd.testing.assert_frame_equal(expected_parent_table, parent_table)\\n         pd.testing.assert_frame_equal(expected_child_table, child_table)\\n+\\n+    def test__estimate_number_of_columns_to_be_modeled(self):\\n+        \\\"\\\"\\\"Test the estimated number of columns is exactly the number of columns to be modeled.\\n+\\n+        The dataset used follows the structure below:\\n+            R1   R2\\n+              \\\\\\\\ /\\n+              GP\\n+              / \\\\\\n+             P - C\\n+        \\\"\\\"\\\"\\n+        # Setup\\n+        root1 = pd.DataFrame({'R1': [0, 1, 2]})\\n+        root2 = pd.DataFrame({'R2': [0, 1, 2], 'data': [0, 1, 2]})\\n+        grandparent = pd.DataFrame({'GP': [0, 1, 2], 'R1': [0, 1, 2], 'R2': [0, 1, 2]})\\n+        parent = pd.DataFrame({'P': [0, 1, 2], 'GP': [0, 1, 2]})\\n+        child = pd.DataFrame({'C': [0, 1, 2], 'P': [0, 1, 2], 'GP': [0, 1, 2]})\\n+        data = {\\n+            'root1': root1,\\n+            'root2': root2,\\n+            'grandparent': grandparent,\\n+            'parent': parent,\\n+            'child': child\\n+        }\\n+        metadata = MultiTableMetadata.load_from_dict({\\n+            'tables': {\\n+                'root1': {\\n+                    'primary_key': 'R1',\\n+                    'columns': {\\n+                        'R1': {'sdtype': 'id'},\\n+                    }\\n+                },\\n+                'root2': {\\n+                    'primary_key': 'R2',\\n+                    'columns': {\\n+                        'R2': {'sdtype': 'id'},\\n+                        'data': {'sdtype': 'numerical'}\\n+                    }\\n+                },\\n+                'grandparent': {\\n+                    'primary_key': 'GP',\\n+                    'columns': {\\n+                        'GP': {'sdtype': 'id'},\\n+                        'R1': {'sdtype': 'id'},\\n+                        'R2': {'sdtype': 'id'},\\n+                    }\\n+                },\\n+                'parent': {\\n+                    'primary_key': 'P',\\n+                    'columns': {\\n+                        'P': {'sdtype': 'id'},\\n+                        'GP': {'sdtype': 'id'},\\n+                    }\\n+                },\\n+                'child': {\\n+                    'primary_key': 'C',\\n+                    'columns': {\\n+                        'C': {'sdtype': 'id'},\\n+                        'P': {'sdtype': 'id'},\\n+                        'GP': {'sdtype': 'id'},\\n+                    }\\n+                }\\n+            },\\n+            'relationships': [\\n+                {\\n+                    'parent_table_name': 'root1',\\n+                    'parent_primary_key': 'R1',\\n+                    'child_table_name': 'grandparent',\\n+                    'child_foreign_key': 'R1'\\n+                },\\n+                {\\n+                    'parent_table_name': 'root2',\\n+                    'parent_primary_key': 'R2',\\n+                    'child_table_name': 'grandparent',\\n+                    'child_foreign_key': 'R2'\\n+                },\\n+                {\\n+                    'parent_table_name': 'grandparent',\\n+                    'parent_primary_key': 'GP',\\n+                    'child_table_name': 'parent',\\n+                    'child_foreign_key': 'GP'\\n+                },\\n+                {\\n+                    'parent_table_name': 'grandparent',\\n+                    'parent_primary_key': 'GP',\\n+                    'child_table_name': 'child',\\n+                    'child_foreign_key': 'GP'\\n+                },\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'P',\\n+                    'child_table_name': 'child',\\n+                    'child_foreign_key': 'P'\\n+                },\\n+            ]\\n+        })\\n+        synthesizer = HMASynthesizer(metadata)\\n+        synthesizer._finalize = Mock()\\n+\\n+        # Run estimation\\n+        estimated_num_columns = synthesizer._estimate_number_of_modeled_columns()\\n+\\n+        # Run actual modeling\\n+        synthesizer.fit(data)\\n+        synthesizer.sample(scale=1)\\n+\\n+        # Assert only root table columns are estimated\\n+        assert set(estimated_num_columns.keys()) == {'root1', 'root2'}\\n+\\n+        # Assert estimated number of columns is correct\\n+        # Notice we need to subtract 1 because the primary key is not modeled\\n+        tables = synthesizer._finalize.call_args[0][0]\\n+        num_root1_cols = len(tables['root1'].columns) - 1\\n+        assert num_root1_cols == estimated_num_columns['root1'] == 40\\n+\\n+        num_root2_cols = len(tables['root2'].columns) - 1\\n+        assert num_root2_cols == estimated_num_columns['root2'] == 41\\n\",\"diff --git a/tests/unit/multi_table/test_hma.py b/tests/unit/multi_table/test_hma.py\\nindex cf87d6254..fe2b9f017 100644\\n--- a/tests/unit/multi_table/test_hma.py\\n+++ b/tests/unit/multi_table/test_hma.py\\n@@ -503,7 +503,7 @@ def test__estimate_number_of_columns_to_be_modeled(self):\\n \\n         The dataset used follows the structure below:\\n             R1   R2\\n-              \\\\\\\\ /\\n+              \\\\ /\\n               GP\\n               / \\\\\\n              P - C\\n\",\"diff --git a/tests/unit/multi_table/test_hma.py b/tests/unit/multi_table/test_hma.py\\nindex fe2b9f017..dd8298f95 100644\\n--- a/tests/unit/multi_table/test_hma.py\\n+++ b/tests/unit/multi_table/test_hma.py\\n@@ -502,11 +502,11 @@ def test__estimate_number_of_columns_to_be_modeled(self):\\n         \\\"\\\"\\\"Test the estimated number of columns is exactly the number of columns to be modeled.\\n \\n         The dataset used follows the structure below:\\n-            R1   R2\\n-              \\\\ /\\n-              GP\\n-              / \\\\\\n-             P - C\\n+            R1 R2\\n+            | /\\n+            GP\\n+            | \\\\\\n+            P-C\\n         \\\"\\\"\\\"\\n         # Setup\\n         root1 = pd.DataFrame({'R1': [0, 1, 2]})\\n\",\"diff --git a/tests/unit/multi_table/test_hma.py b/tests/unit/multi_table/test_hma.py\\nindex dd8298f95..7bab15530 100644\\n--- a/tests/unit/multi_table/test_hma.py\\n+++ b/tests/unit/multi_table/test_hma.py\\n@@ -501,6 +501,9 @@ def test__add_foreign_key_columns(self):\\n     def test__estimate_number_of_columns_to_be_modeled(self):\\n         \\\"\\\"\\\"Test the estimated number of columns is exactly the number of columns to be modeled.\\n \\n+        To check that the number columns is correct we Mock the ``_finalize`` method\\n+        and compare its output (minus the primary key) with the estimated number of columns.\\n+\\n         The dataset used follows the structure below:\\n             R1 R2\\n             | /\\n@@ -597,7 +600,7 @@ def test__estimate_number_of_columns_to_be_modeled(self):\\n         synthesizer._finalize = Mock()\\n \\n         # Run estimation\\n-        estimated_num_columns = synthesizer._estimate_number_of_modeled_columns()\\n+        estimated_num_columns = synthesizer.estimate_number_of_root_columns()\\n \\n         # Run actual modeling\\n         synthesizer.fit(data)\\n@@ -607,10 +610,123 @@ def test__estimate_number_of_columns_to_be_modeled(self):\\n         assert set(estimated_num_columns.keys()) == {'root1', 'root2'}\\n \\n         # Assert estimated number of columns is correct\\n-        # Notice we need to subtract 1 because the primary key is not modeled\\n+        # We need to subract 1 from the sampled data because the primary key is present\\n         tables = synthesizer._finalize.call_args[0][0]\\n         num_root1_cols = len(tables['root1'].columns) - 1\\n         assert num_root1_cols == estimated_num_columns['root1'] == 40\\n \\n         num_root2_cols = len(tables['root2'].columns) - 1\\n         assert num_root2_cols == estimated_num_columns['root2'] == 41\\n+\\n+    def test__estimate_number_of_columns_to_be_modeled_various_sdtypes(self):\\n+        \\\"\\\"\\\"Test the estimated number of columns is correct for various sdtypes.\\n+\\n+        To check that the number columns is correct we Mock the ``_finalize`` method\\n+        and compare its output (minus the primary key) with the estimated number of columns.\\n+\\n+        The dataset used follows the structure below:\\n+            R1 R2\\n+            | /\\n+            GP\\n+            |\\n+            P\\n+        \\\"\\\"\\\"\\n+        # Setup\\n+        root1 = pd.DataFrame({'R1': [0, 1, 2]})\\n+        root2 = pd.DataFrame({'R2': [0, 1, 2], 'data': [0, 1, 2]})\\n+        grandparent = pd.DataFrame({'GP': [0, 1, 2], 'R1': [0, 1, 2], 'R2': [0, 1, 2]})\\n+        parent = pd.DataFrame({\\n+            'P': [0, 1, 2],\\n+            'GP': [0, 1, 2],\\n+            'numerical': [.1, .5, np.nan],\\n+            'categorical': ['a', np.nan, 'c'],\\n+            'datetime': [None, '2019-01-02', '2019-01-03'],\\n+            'boolean': [float('nan'), False, True],\\n+            'id': [0, 1, 2],\\n+            'text': ['a', 'b', 'c']\\n+        })\\n+        data = {\\n+            'root1': root1,\\n+            'root2': root2,\\n+            'grandparent': grandparent,\\n+            'parent': parent,\\n+        }\\n+        metadata = MultiTableMetadata.load_from_dict({\\n+            'tables': {\\n+                'root1': {\\n+                    'primary_key': 'R1',\\n+                    'columns': {\\n+                        'R1': {'sdtype': 'id'},\\n+                    }\\n+                },\\n+                'root2': {\\n+                    'primary_key': 'R2',\\n+                    'columns': {\\n+                        'R2': {'sdtype': 'id'},\\n+                        'data': {'sdtype': 'numerical'}\\n+                    }\\n+                },\\n+                'grandparent': {\\n+                    'primary_key': 'GP',\\n+                    'columns': {\\n+                        'GP': {'sdtype': 'id'},\\n+                        'R1': {'sdtype': 'id'},\\n+                        'R2': {'sdtype': 'id'},\\n+                    }\\n+                },\\n+                'parent': {\\n+                    'primary_key': 'P',\\n+                    'columns': {\\n+                        'P': {'sdtype': 'id'},\\n+                        'GP': {'sdtype': 'id'},\\n+                        'numerical': {'sdtype': 'numerical'},\\n+                        'categorical': {'sdtype': 'categorical'},\\n+                        'datetime': {'sdtype': 'datetime'},\\n+                        'boolean': {'sdtype': 'boolean'},\\n+                        'text': {'sdtype': 'text'},\\n+                        'id': {'sdtype': 'id'},\\n+                    }\\n+                }\\n+            },\\n+            'relationships': [\\n+                {\\n+                    'parent_table_name': 'root1',\\n+                    'parent_primary_key': 'R1',\\n+                    'child_table_name': 'grandparent',\\n+                    'child_foreign_key': 'R1'\\n+                },\\n+                {\\n+                    'parent_table_name': 'root2',\\n+                    'parent_primary_key': 'R2',\\n+                    'child_table_name': 'grandparent',\\n+                    'child_foreign_key': 'R2'\\n+                },\\n+                {\\n+                    'parent_table_name': 'grandparent',\\n+                    'parent_primary_key': 'GP',\\n+                    'child_table_name': 'parent',\\n+                    'child_foreign_key': 'GP'\\n+                },\\n+            ]\\n+        })\\n+        synthesizer = HMASynthesizer(metadata)\\n+        synthesizer._finalize = Mock()\\n+\\n+        # Run estimation\\n+        estimated_num_columns = synthesizer.estimate_number_of_root_columns()\\n+\\n+        # Run actual modeling\\n+        synthesizer.fit(data)\\n+        synthesizer.sample()\\n+\\n+        # Assert only root table columns are estimated\\n+        assert set(estimated_num_columns.keys()) == {'root1', 'root2'}\\n+\\n+        # Assert estimated number of columns is correct\\n+        # We need to subract 1 from the sampled data because the primary key is present\\n+        tables = synthesizer._finalize.call_args[0][0]\\n+        num_root1_cols = len(tables['root1'].columns) - 1\\n+        assert num_root1_cols == estimated_num_columns['root1'] == 346\\n+\\n+        num_root2_cols = len(tables['root2'].columns) - 1\\n+        assert num_root2_cols == estimated_num_columns['root2'] == 347\\n\",\"diff --git a/tests/unit/multi_table/test_hma.py b/tests/unit/multi_table/test_hma.py\\nindex 7bab15530..88b487837 100644\\n--- a/tests/unit/multi_table/test_hma.py\\n+++ b/tests/unit/multi_table/test_hma.py\\n@@ -643,7 +643,6 @@ def test__estimate_number_of_columns_to_be_modeled_various_sdtypes(self):\\n             'datetime': [None, '2019-01-02', '2019-01-03'],\\n             'boolean': [float('nan'), False, True],\\n             'id': [0, 1, 2],\\n-            'text': ['a', 'b', 'c']\\n         })\\n         data = {\\n             'root1': root1,\\n@@ -683,7 +682,6 @@ def test__estimate_number_of_columns_to_be_modeled_various_sdtypes(self):\\n                         'categorical': {'sdtype': 'categorical'},\\n                         'datetime': {'sdtype': 'datetime'},\\n                         'boolean': {'sdtype': 'boolean'},\\n-                        'text': {'sdtype': 'text'},\\n                         'id': {'sdtype': 'id'},\\n                     }\\n                 }\\n\",\"diff --git a/tests/unit/multi_table/test_hma.py b/tests/unit/multi_table/test_hma.py\\nindex 88b487837..40340d2a9 100644\\n--- a/tests/unit/multi_table/test_hma.py\\n+++ b/tests/unit/multi_table/test_hma.py\\n@@ -498,15 +498,148 @@ def test__add_foreign_key_columns(self):\\n         pd.testing.assert_frame_equal(expected_parent_table, parent_table)\\n         pd.testing.assert_frame_equal(expected_child_table, child_table)\\n \\n-    def test__estimate_number_of_columns_to_be_modeled(self):\\n+    def test__estimate_num_columns_to_be_modeled_multiple_foreign_keys(self):\\n+        \\\"\\\"\\\"Test it when there are two relationships between a parent and a child tables.\\n+\\n+        To check that the number columns is correct we Mock the ``_finalize`` method\\n+        and compare its output with the estimated number of columns.\\n+        \\\"\\\"\\\"\\n+        # Setup\\n+        parent = pd.DataFrame({'id': [0, 1, 2]})\\n+        child = pd.DataFrame({\\n+            'id': [0, 1, 2], 'id1': [0, 1, 2], 'id2': [0, 1, 2], 'col1': [0, 1, 2]})\\n+        data = {'parent': parent, 'child': child}\\n+        metadata = MultiTableMetadata.load_from_dict({\\n+            'tables': {\\n+                'parent': {\\n+                    'primary_key': 'id',\\n+                    'columns': {\\n+                        'id': {'sdtype': 'id'},\\n+                    }\\n+                },\\n+                'child': {\\n+                    'primary_key': 'id',\\n+                    'columns': {\\n+                        'id': {'sdtype': 'id'},\\n+                        'id1': {'sdtype': 'id'},\\n+                        'id2': {'sdtype': 'id'},\\n+                        'col1': {'sdtype': 'numerical'},\\n+                    }\\n+                },\\n+            },\\n+            'relationships': [\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child',\\n+                    'child_foreign_key': 'id1'\\n+                },\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child',\\n+                    'child_foreign_key': 'id2'\\n+                },\\n+            ]\\n+        })\\n+        synthesizer = HMASynthesizer(metadata)\\n+        synthesizer._finalize = Mock()\\n+\\n+        # Run estimation\\n+        estimated_num_columns = synthesizer._estimate_num_columns()\\n+\\n+        # Run actual modeling\\n+        synthesizer.fit(data)\\n+        synthesizer.sample()\\n+\\n+        # Assert estimated number of columns is correct\\n+        tables = synthesizer._finalize.call_args[0][0]\\n+        for table_name, table in tables.items():\\n+            # Subract all the id columns present in the data, as those are not estimated\\n+            num_table_cols = len(table.columns)\\n+            if table_name == 'parent':\\n+                num_table_cols -= 1\\n+            if table_name == 'child':\\n+                num_table_cols -= 3\\n+\\n+            assert num_table_cols == estimated_num_columns[table_name]\\n+\\n+    def test__estimate_num_columns_to_be_modeled_multiple_foreign_keys2(self):\\n+        \\\"\\\"\\\"Test it when there are two relationships between a parent and a child tables.\\n+\\n+        To check that the number columns is correct we Mock the ``_finalize`` method\\n+        and compare its output with the estimated number of columns.\\n+        \\\"\\\"\\\"\\n+        # Setup\\n+        parent = pd.DataFrame({'id': [0, 1, 2]})\\n+        child = pd.DataFrame({'id': [0, 1, 2], 'id1': [0, 1, 2],\\n+                             'id2': [0, 1, 2], 'col1': [0, 1, 2]})\\n+        data = {'parent': parent, 'child': child}\\n+        metadata = MultiTableMetadata.load_from_dict({\\n+            'tables': {\\n+                'parent': {\\n+                    'primary_key': 'id',\\n+                    'columns': {\\n+                        'id': {'sdtype': 'id'},\\n+                    }\\n+                },\\n+                'child': {\\n+                    'primary_key': 'id',\\n+                    'columns': {\\n+                        'id': {'sdtype': 'id'},\\n+                        'id1': {'sdtype': 'id'},\\n+                        'id2': {'sdtype': 'id'},\\n+                        'col1': {'sdtype': 'numerical'},\\n+                    }\\n+                },\\n+            },\\n+            'relationships': [\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child',\\n+                    'child_foreign_key': 'id1'\\n+                },\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child',\\n+                    'child_foreign_key': 'id2'\\n+                },\\n+            ]\\n+        })\\n+        synthesizer = HMASynthesizer(metadata)\\n+        synthesizer.set_table_parameters(table_name='child', default_distribution='norm')\\n+        synthesizer._finalize = Mock()\\n+\\n+        # Run estimation\\n+        estimated_num_columns = synthesizer._estimate_num_columns()\\n+\\n+        # Run actual modeling\\n+        synthesizer.fit(data)\\n+        synthesizer.sample()\\n+\\n+        # Assert estimated number of columns is correct\\n+        tables = synthesizer._finalize.call_args[0][0]\\n+        for table_name, table in tables.items():\\n+            # Subract all the id columns present in the data, as those are not estimated\\n+            num_table_cols = len(table.columns)\\n+            if table_name == 'parent':\\n+                num_table_cols -= 1\\n+            if table_name == 'child':\\n+                num_table_cols -= 3\\n+\\n+            assert num_table_cols == estimated_num_columns[table_name]\\n+\\n+    def test__estimate_num_columns_to_be_modeled(self):\\n         \\\"\\\"\\\"Test the estimated number of columns is exactly the number of columns to be modeled.\\n \\n         To check that the number columns is correct we Mock the ``_finalize`` method\\n-        and compare its output (minus the primary key) with the estimated number of columns.\\n+        and compare its output with the estimated number of columns.\\n \\n         The dataset used follows the structure below:\\n             R1 R2\\n-            | /\\n+            || /\\n             GP\\n             | \\\\\\n             P-C\\n@@ -514,7 +647,8 @@ def test__estimate_number_of_columns_to_be_modeled(self):\\n         # Setup\\n         root1 = pd.DataFrame({'R1': [0, 1, 2]})\\n         root2 = pd.DataFrame({'R2': [0, 1, 2], 'data': [0, 1, 2]})\\n-        grandparent = pd.DataFrame({'GP': [0, 1, 2], 'R1': [0, 1, 2], 'R2': [0, 1, 2]})\\n+        grandparent = pd.DataFrame({\\n+            'GP': [0, 1, 2], 'R1_1': [0, 1, 2], 'R1_2': [0, 1, 2], 'R2': [0, 1, 2]})\\n         parent = pd.DataFrame({'P': [0, 1, 2], 'GP': [0, 1, 2]})\\n         child = pd.DataFrame({'C': [0, 1, 2], 'P': [0, 1, 2], 'GP': [0, 1, 2]})\\n         data = {\\n@@ -543,7 +677,8 @@ def test__estimate_number_of_columns_to_be_modeled(self):\\n                     'primary_key': 'GP',\\n                     'columns': {\\n                         'GP': {'sdtype': 'id'},\\n-                        'R1': {'sdtype': 'id'},\\n+                        'R1_1': {'sdtype': 'id'},\\n+                        'R1_2': {'sdtype': 'id'},\\n                         'R2': {'sdtype': 'id'},\\n                     }\\n                 },\\n@@ -568,7 +703,13 @@ def test__estimate_number_of_columns_to_be_modeled(self):\\n                     'parent_table_name': 'root1',\\n                     'parent_primary_key': 'R1',\\n                     'child_table_name': 'grandparent',\\n-                    'child_foreign_key': 'R1'\\n+                    'child_foreign_key': 'R1_1'\\n+                },\\n+                {\\n+                    'parent_table_name': 'root1',\\n+                    'parent_primary_key': 'R1',\\n+                    'child_table_name': 'grandparent',\\n+                    'child_foreign_key': 'R1_2'\\n                 },\\n                 {\\n                     'parent_table_name': 'root2',\\n@@ -600,29 +741,33 @@ def test__estimate_number_of_columns_to_be_modeled(self):\\n         synthesizer._finalize = Mock()\\n \\n         # Run estimation\\n-        estimated_num_columns = synthesizer.estimate_number_of_root_columns()\\n+        estimated_num_columns = synthesizer._estimate_num_columns()\\n \\n         # Run actual modeling\\n         synthesizer.fit(data)\\n         synthesizer.sample(scale=1)\\n \\n-        # Assert only root table columns are estimated\\n-        assert set(estimated_num_columns.keys()) == {'root1', 'root2'}\\n-\\n         # Assert estimated number of columns is correct\\n-        # We need to subract 1 from the sampled data because the primary key is present\\n         tables = synthesizer._finalize.call_args[0][0]\\n-        num_root1_cols = len(tables['root1'].columns) - 1\\n-        assert num_root1_cols == estimated_num_columns['root1'] == 40\\n-\\n-        num_root2_cols = len(tables['root2'].columns) - 1\\n-        assert num_root2_cols == estimated_num_columns['root2'] == 41\\n-\\n-    def test__estimate_number_of_columns_to_be_modeled_various_sdtypes(self):\\n+        for table_name, table in tables.items():\\n+            # Subract all the id columns present in the data, as those are not estimated\\n+            num_table_cols = len(table.columns)\\n+            if table_name == 'child':\\n+                num_table_cols -= 3\\n+            if table_name == 'parent':\\n+                num_table_cols -= 2\\n+            if table_name == 'grandparent':\\n+                num_table_cols -= 4\\n+            if table_name in {'root1', 'root2'}:\\n+                num_table_cols -= 1\\n+\\n+            assert num_table_cols == estimated_num_columns[table_name]\\n+\\n+    def test__estimate_num_columns_to_be_modeled_various_sdtypes(self):\\n         \\\"\\\"\\\"Test the estimated number of columns is correct for various sdtypes.\\n \\n         To check that the number columns is correct we Mock the ``_finalize`` method\\n-        and compare its output (minus the primary key) with the estimated number of columns.\\n+        and compare its output with the estimated number of columns.\\n \\n         The dataset used follows the structure below:\\n             R1 R2\\n@@ -711,20 +856,20 @@ def test__estimate_number_of_columns_to_be_modeled_various_sdtypes(self):\\n         synthesizer._finalize = Mock()\\n \\n         # Run estimation\\n-        estimated_num_columns = synthesizer.estimate_number_of_root_columns()\\n+        estimated_num_columns = synthesizer._estimate_num_columns()\\n \\n         # Run actual modeling\\n         synthesizer.fit(data)\\n         synthesizer.sample()\\n \\n-        # Assert only root table columns are estimated\\n-        assert set(estimated_num_columns.keys()) == {'root1', 'root2'}\\n-\\n         # Assert estimated number of columns is correct\\n-        # We need to subract 1 from the sampled data because the primary key is present\\n         tables = synthesizer._finalize.call_args[0][0]\\n-        num_root1_cols = len(tables['root1'].columns) - 1\\n-        assert num_root1_cols == estimated_num_columns['root1'] == 346\\n-\\n-        num_root2_cols = len(tables['root2'].columns) - 1\\n-        assert num_root2_cols == estimated_num_columns['root2'] == 347\\n+        for table_name, table in tables.items():\\n+            # Subract all the id columns present in the data, as those are not estimated\\n+            num_table_cols = len(table.columns)\\n+            if table_name in {'parent', 'grandparent'}:\\n+                num_table_cols -= 3\\n+            if table_name in {'root1', 'root2'}:\\n+                num_table_cols -= 1\\n+\\n+            assert num_table_cols == estimated_num_columns[table_name]\\n\",\"diff --git a/tests/unit/multi_table/test_hma.py b/tests/unit/multi_table/test_hma.py\\nindex 40340d2a9..e802aaeac 100644\\n--- a/tests/unit/multi_table/test_hma.py\\n+++ b/tests/unit/multi_table/test_hma.py\\n@@ -564,17 +564,40 @@ def test__estimate_num_columns_to_be_modeled_multiple_foreign_keys(self):\\n \\n             assert num_table_cols == estimated_num_columns[table_name]\\n \\n-    def test__estimate_num_columns_to_be_modeled_multiple_foreign_keys2(self):\\n-        \\\"\\\"\\\"Test it when there are two relationships between a parent and a child tables.\\n+    def test__estimate_num_columns_to_be_modeled_different_distributions(self):\\n+        \\\"\\\"\\\"Test it when there the default distributions of the tables have been changed.\\n+\\n+        The schema will be 1 parent and 5 children, all of which have different distributions,\\n+        all of which have two foreign keys to the parent table.\\n \\n         To check that the number columns is correct we Mock the ``_finalize`` method\\n         and compare its output with the estimated number of columns.\\n         \\\"\\\"\\\"\\n         # Setup\\n         parent = pd.DataFrame({'id': [0, 1, 2]})\\n-        child = pd.DataFrame({'id': [0, 1, 2], 'id1': [0, 1, 2],\\n-                             'id2': [0, 1, 2], 'col1': [0, 1, 2]})\\n-        data = {'parent': parent, 'child': child}\\n+        child = pd.DataFrame({\\n+            'id': [0, 1, 2],\\n+            'id1': [0, 1, 2],\\n+            'id2': [0, 1, 2],\\n+            'col': [.2, .3, .2]\\n+        })\\n+        data = {\\n+            'parent': parent,\\n+            'child_norm': child,\\n+            'child_beta': child,\\n+            'child_gamma': child,\\n+            'child_truncnorm': child,\\n+            'child_uniform': child\\n+        }\\n+        child_dict = {\\n+            'primary_key': 'id',\\n+            'columns': {\\n+                'id': {'sdtype': 'id'},\\n+                'id1': {'sdtype': 'id'},\\n+                'id2': {'sdtype': 'id'},\\n+                'col': {'sdtype': 'numerical'},\\n+            }\\n+        }\\n         metadata = MultiTableMetadata.load_from_dict({\\n             'tables': {\\n                 'parent': {\\n@@ -583,33 +606,92 @@ def test__estimate_num_columns_to_be_modeled_multiple_foreign_keys2(self):\\n                         'id': {'sdtype': 'id'},\\n                     }\\n                 },\\n-                'child': {\\n-                    'primary_key': 'id',\\n-                    'columns': {\\n-                        'id': {'sdtype': 'id'},\\n-                        'id1': {'sdtype': 'id'},\\n-                        'id2': {'sdtype': 'id'},\\n-                        'col1': {'sdtype': 'numerical'},\\n-                    }\\n-                },\\n+                'child_norm': child_dict,\\n+                'child_beta': child_dict,\\n+                'child_gamma': child_dict,\\n+                'child_truncnorm': child_dict,\\n+                'child_uniform': child_dict,\\n             },\\n             'relationships': [\\n                 {\\n                     'parent_table_name': 'parent',\\n                     'parent_primary_key': 'id',\\n-                    'child_table_name': 'child',\\n+                    'child_table_name': 'child_norm',\\n                     'child_foreign_key': 'id1'\\n                 },\\n                 {\\n                     'parent_table_name': 'parent',\\n                     'parent_primary_key': 'id',\\n-                    'child_table_name': 'child',\\n+                    'child_table_name': 'child_norm',\\n+                    'child_foreign_key': 'id2'\\n+                },\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child_beta',\\n+                    'child_foreign_key': 'id1'\\n+                },\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child_beta',\\n+                    'child_foreign_key': 'id2'\\n+                },\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child_truncnorm',\\n+                    'child_foreign_key': 'id1'\\n+                },\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child_truncnorm',\\n+                    'child_foreign_key': 'id2'\\n+                },\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child_uniform',\\n+                    'child_foreign_key': 'id1'\\n+                },\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child_uniform',\\n+                    'child_foreign_key': 'id2'\\n+                },\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child_gamma',\\n+                    'child_foreign_key': 'id1'\\n+                },\\n+                {\\n+                    'parent_table_name': 'parent',\\n+                    'parent_primary_key': 'id',\\n+                    'child_table_name': 'child_gamma',\\n                     'child_foreign_key': 'id2'\\n                 },\\n             ]\\n         })\\n         synthesizer = HMASynthesizer(metadata)\\n-        synthesizer.set_table_parameters(table_name='child', default_distribution='norm')\\n+        synthesizer.set_table_parameters(\\n+            table_name='child_norm',\\n+            table_parameters={'default_distribution': 'norm'}\\n+        )\\n+        synthesizer.set_table_parameters(\\n+            table_name='child_gamma',\\n+            table_parameters={'default_distribution': 'gamma'}\\n+        )\\n+        synthesizer.set_table_parameters(\\n+            table_name='child_truncnorm',\\n+            table_parameters={'default_distribution': 'truncnorm'}\\n+        )\\n+        synthesizer.set_table_parameters(\\n+            table_name='child_uniform',\\n+            table_parameters={'default_distribution': 'uniform'}\\n+        )\\n         synthesizer._finalize = Mock()\\n \\n         # Run estimation\\n@@ -626,7 +708,7 @@ def test__estimate_num_columns_to_be_modeled_multiple_foreign_keys2(self):\\n             num_table_cols = len(table.columns)\\n             if table_name == 'parent':\\n                 num_table_cols -= 1\\n-            if table_name == 'child':\\n+            else:\\n                 num_table_cols -= 3\\n \\n             assert num_table_cols == estimated_num_columns[table_name]\\n\",\"diff --git a/tests/unit/multi_table/test_hma.py b/tests/unit/multi_table/test_hma.py\\nindex e802aaeac..e53a17479 100644\\n--- a/tests/unit/multi_table/test_hma.py\\n+++ b/tests/unit/multi_table/test_hma.py\\n@@ -507,7 +507,11 @@ def test__estimate_num_columns_to_be_modeled_multiple_foreign_keys(self):\\n         # Setup\\n         parent = pd.DataFrame({'id': [0, 1, 2]})\\n         child = pd.DataFrame({\\n-            'id': [0, 1, 2], 'id1': [0, 1, 2], 'id2': [0, 1, 2], 'col1': [0, 1, 2]})\\n+            'id': [0, 1, 2],\\n+            'id1': [0, 1, 2],\\n+            'id2': [0, 1, 2],\\n+            'col1': [0, 1, 2]\\n+        })\\n         data = {'parent': parent, 'child': child}\\n         metadata = MultiTableMetadata.load_from_dict({\\n             'tables': {\\n@@ -730,7 +734,8 @@ def test__estimate_num_columns_to_be_modeled(self):\\n         root1 = pd.DataFrame({'R1': [0, 1, 2]})\\n         root2 = pd.DataFrame({'R2': [0, 1, 2], 'data': [0, 1, 2]})\\n         grandparent = pd.DataFrame({\\n-            'GP': [0, 1, 2], 'R1_1': [0, 1, 2], 'R1_2': [0, 1, 2], 'R2': [0, 1, 2]})\\n+            'GP': [0, 1, 2], 'R1_1': [0, 1, 2], 'R1_2': [0, 1, 2], 'R2': [0, 1, 2]\\n+        })\\n         parent = pd.DataFrame({'P': [0, 1, 2], 'GP': [0, 1, 2]})\\n         child = pd.DataFrame({'C': [0, 1, 2], 'P': [0, 1, 2], 'GP': [0, 1, 2]})\\n         data = {\"]", "hints_text": ""}
