{"instance_id": "1300837564594063", "repo": "anaphory/lexedata", "base_commit": "f27489bdc0420ec11f7d0363437a4a98906163a7", "problem_statement": "lexedata.report.filter needs -o argument for writing to file instead of printing to stdout:\\n", "FAIL_TO_PASS": ["test/test_coverage.py::test_coverage_concept_report[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_coverage.py::test_coverage_report_with_concept_table", "test/test_na_forms.py::test_coverage_report_missing_and_na_default", "test/test_coverage.py::test_uncoded_coverage_report[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_coverage.py::test_coverage_report[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_na_forms.py::test_coverage_report_missing_and_na_ignore", "test/test_extended_validate.py::test_check_empty_forms_warning", "test/test_various_parsers.py::test_filter_parser", "test/test_extended_validate.py::test_check_no_separator_in_ids", "test/test_extended_validate.py::test_check_foreignkeys_correct", "test/test_extended_validate.py::test_check_na_forms", "test/test_coverage.py::test_coverage_report_with_primary_concepts", "test/test_coverage.py::test_coverage_report_uncoded[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_extended_validate.py::test_check_unicode_data_warning"], "PASS_TO_PASS": ["test/test_cognate_exporter.py::test_no_comment_column", "test/test_additional_import.py::test_concept_not_found[single_import_parameters0]", "test/test_cognate_exporter.py::test_adding_singleton_cognatesets_with_status", "test/test_na_forms.py::test_phylogenetics_exporter_unknown", "test/test_excel_conversion.py::test_toexcel_runs[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp]", "test/test_matrix_exporter.py::test_toexcel_filtered[data/cldf/minimal/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_various_parsers.py::test_loglevel_parser", "test/test_na_forms.py::test_interleaved_import_dash", "test/test_excel_import.py::test_dialect_missing_key_excel_parser", "test/test_cellparser.py::test_fields_of_formtable_no_source[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_matrix_exporter.py::test_toexcel_filtered[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp]", "test/test_cellparser.py::test_cellparser_empty1", "test/test_small_example.py::test_add_cog_tables_valid", "test/test_edictor.py::test_forms_to_csv", "test/test_concept_guesser.py::test_no_concepticon_definition_column_added", "test/test_central_concepts_cognatesets.py::test_central_concept_status_column[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_clis.py::test_exit", "test/test_na_forms.py::test_interleaved_import_skips_na", "test/test_homophones_merger.py::test_merge_3", "test/test_cellparser.py::test_cellparser_form_7", "test/test_edictor.py::test_roundtrip[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp]", "test/test_excel_conversion.py::test_fromexcel_correct[excel_wordlist1]", "test/test_various_parsers.py::test_listorfromfile_list", "test/test_excel_conversion.py::test_roundtrip_separator_column[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_form_matcher.py::test_all_ipa_symbols", "test/test_matrix_exporter.py::test_toexcel_runs[data/cldf/minimal/cldf-metadata.json-copy_to_temp]", "test/test_cellparser.py::test_cellparser_unexpected_variant", "test/test_dataset_issues.py::test_python_slice_is_wrong", "test/test_matrix_exporter.py::test_toexcel_runs[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_additional_import.py::test_missing_concept[single_import_parameters0]", "test/test_homophones_merger.py::test_merge_group_assertion_error", "test/test_segment.py::test_unknown_sound", "test/test_cellparser.py::test_cellparser_form_5", "test/test_excel_conversion.py::test_roundtrip_separator_column[data/cldf/minimal/cldf-metadata.json-copy_to_temp]", "test/test_cellparser.py::test_cellparser_form_3", "test/test_central_concepts_cognatesets.py::test_add_concepts_to_maweti_cognatesets[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_na_forms.py::test_homohpones_skips_na_forms", "test/test_excel_conversion.py::test_toexcel_runs[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_excel_util.py::test_normalize_header", "test/test_form_matcher.py::test_form_association", "test/test_additional_import.py::test_import_error_missing_parameter_column[single_import_parameters0]", "test/test_cellparser.py::test_fields_of_formtable_no_form[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_excel_conversion.py::test_roundtrip[data/cldf/minimal/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_homophones_merger.py::test_skip", "test/test_na_forms.py::test_extended_cldf_validate", "test/test_na_forms.py::test_single_excel_import_skips_na", "test/test_cognate_detector.py::test_filter_function_factory", "test/test_cellparser.py::test_misshaped_source", "test/test_cellparser.py::test_mawetiparser_multiple_comments", "test/test_additional_import.py::test_add_new_forms_maweti[single_import_parameters0]", "test/test_concept_guesser.py::test_concepticon_definitions[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_excel_import.py::test_no_dialect_excel_parser", "test/test_matrix_exporter.py::test_toexcel_filtered[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_edictor.py::test_write_edictor_singleton_dataset", "test/test_excel_import.py::test_no_dialect_excel_cognate_parser", "test/test_additional_import.py::test_import_report_skipped[single_import_parameters0]", "test/test_excel_conversion.py::test_fromexcel_runs[excel_wordlist1]", "test/test_small_example.py::test_create_metadata_valid", "test/test_homophones_merger.py::test_order_merge", "test/test_central_concepts_cognatesets.py::test_value_error_no_concepticonReferenc_for_concepts", "test/test_excel_conversion.py::test_fromexcel_runs[excel_wordlist0]", "test/test_dataset_issues.py::test_backward_slice_is_wrong", "test/test_additional_import.py::test_superfluous_columns1[single_import_parameters0]", "test/test_edictor.py::test_match_cognatesets_2", "test/test_additional_import.py::test_concept_separator[single_import_parameters0]", "test/test_na_forms.py::test_add_segments_skips_na_forms", "test/test_cellparser.py::test_cellparser_form_4", "test/test_cellparser.py::test_cellparser_form_1", "test/test_util.py::test_normal_table_names[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_cellparser.py::test_source_from_source_string2", "test/test_cellparser.py::test_cellparser_form_6", "test/test_edictor.py::test_match_cognatesets_1", "test/test_matrix_exporter.py::test_toexcel_filtered[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_cellparser.py::test_cellparser_separate_2", "test/test_homophones_merger.py::test_errors", "test/test_excel_import.py::test_db_chache", "test/test_form_matcher.py::test_source_context", "test/test_edictor.py::test_write_edictor_empty_dataset", "test/test_cellparser.py::test_cellparser_separate_1", "test/test_concept_guesser.py::test_concepticon_id_of_concepts_correct[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_na_forms.py::test_add_singlestons", "test/test_dataset_issues.py::test_missing_forms_not_coded", "test/test_matrix_exporter.py::test_toexcel_runs[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp]", "test/test_excel_util.py::test_cell_value", "test/test_small_example.py::test_interleaved", "test/test_small_example.py::test_create_metadata_correct", "test/test_homophones_merger.py::test_merge_report_parser", "test/test_excel_conversion.py::test_roundtrip[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_homophones_merger.py::test_union", "test/test_additional_import.py::test_concept_file_not_found", "test/test_cognate_exporter.py::test_no_cognate_table", "test/test_excel_import.py::test_cognate_parser_language_not_found", "test/test_cellparser.py::test_parser_variant_lands_in_comment", "test/test_excel_import.py::test_properties_regex_error", "test/test_excel_conversion.py::test_excel_messy_row", "test/test_cellparser.py::test_cellparser_no_real_variant", "test/test_cellparser.py::test_source_from_source_string1", "test/test_na_forms.py::test_single_excel_import_dash", "test/test_edictor.py::test_roundtrip[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_excel_import.py::test_no_wordlist_and_no_cogsets", "test/test_edictor.py::test_roundtrip[data/cldf/minimal/cldf-metadata.json-copy_to_temp]", "test/test_cellparser.py::test_cellparser_separate_warning", "test/test_excel_conversion.py::test_roundtrip[data/cldf/minimal/cldf-metadata.json-copy_to_temp]", "test/test_cellparser.py::test_cellparser_not_parsable", "test/test_dataset_issues.py::test_alignments_must_match_segments", "test/test_cellparser.py::test_cellparser_separate_5", "test/test_cellparser.py::test_fields_of_formtable_no_value[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_excel_conversion.py::test_cell_comments_and_comment_column", "test/test_matrix_exporter.py::test_toexcel_runs[data/cldf/minimal/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_form_matcher.py::test_form_association_identical", "test/test_excel_conversion.py::test_roundtrip[data/cldf/minimal/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_excel_import.py::test_no_first_row_in_excel", "test/test_dataset_issues.py::test_default_metathesis_is_okay", "test/test_additional_import.py::test_import_report_existing_form[single_import_parameters0]", "test/test_excel_conversion.py::test_roundtrip_separator_column[data/cldf/minimal/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_cognate_exporter.py::test_included_segments", "test/test_dataset_issues.py::test_strict_metathesis_is_wrong", "test/test_cellparser.py::test_cellparser_empty2", "test/test_cognate_exporter.py::test_missing_required_column", "test/test_excel_conversion.py::test_roundtrip_separator_column[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp]", "test/test_excel_import.py::test_language_regex_error", "test/test_add_singleton.py::test_singletons", "test/test_excel_conversion.py::test_cell_comments_export", "test/test_excel_conversion.py::test_roundtrip_separator_column[data/cldf/minimal/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_additional_import.py::test_import_report_new_language[single_import_parameters0]", "test/test_cellparser.py::test_cellparser_form_2", "test/test_central_concepts_cognatesets.py::test_value_error_no_parameterReference_for_cognateset[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_concept_guesser.py::test_value_error_no_parameter_reference_for_cognateset[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_additional_import.py::test_new_concept_association[single_import_parameters0]", "test/test_excel_conversion.py::test_roundtrip_separator_column[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_excel_conversion.py::test_toexcel_runs[data/cldf/minimal/cldf-metadata.json-copy_to_temp]", "test/test_homophones_merger.py::test_preprocessing", "test/test_na_forms.py::test_edictor_exporter_no_na_forms", "test/test_additional_import.py::test_missing_columns1[single_import_parameters0]", "test/test_cognate_exporter.py::test_no_cognateset_table", "test/test_concept_guesser.py::test_value_error_no_concepticon_reference_for_concepts", "test/test_matrix_exporter.py::test_cell_comments_export", "test/test_concept_guesser.py::test_add_concepticon_names_missing_column", "test/test_coverage.py::test_no_primary_concepts[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_homophones_merger.py::test_merge_group_not_implemented", "test/test_cellparser.py::test_mawetiparser_postprocessing", "test/test_dataset_issues.py::test_overlong_slice_is_wrong", "test/test_additional_import.py::test_no_concept_separator[single_import_parameters0]", "test/test_matrix_exporter.py::test_toexcel_filtered[data/cldf/minimal/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_matrix_exporter.py::test_toexcel_filtered[data/cldf/minimal/cldf-metadata.json-copy_to_temp]", "test/test_excel_import.py::test_properties_comment_regex_error", "test/test_small_example.py::test_add_cog_tables_correct", "test/test_homophones_merger.py::test_merge_1", "test/test_cellparser.py::test_fields_of_formtable_no_comment[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_homophones_merger.py::test_merge_2", "test/test_cellparser.py::test_fields_of_formtable_no_transcription[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_excel_conversion.py::test_toexcel_runs[data/cldf/minimal/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_add_singleton.py::test_no_status_column", "test/test_additional_import.py::test_form_exists[single_import_parameters0]", "test/test_cellparser.py::test_cellparser_separate_4", "test/test_segment.py::test_deleting_symbols", "test/test_concept_guesser.py::test_concepticon_reference_missing", "test/test_edictor.py::test_roundtrip[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_segment.py::test_unkown_aspiration", "test/test_excel_conversion.py::test_cell_comments", "test/test_cognate_exporter.py::test_adding_singleton_cognatesets", "test/test_util_simplify_ids.py::test_update_ids", "test/test_dataset_issues.py::test_alignments_must_match_length", "test/test_util_simplify_ids.py::test_integer_ids", "test/test_segment.py::test_prenasal_before_vowel", "test/test_cellparser.py::test_cellparser_default", "test/test_cellparser.py::test_cellparser_missmatching", "test/test_cellparser.py::test_fields_of_formtable_no_language_reference[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_na_forms.py::test_phylogenetics_exporter_dash_is_absence", "test/test_edictor.py::test_roundtrip[data/cldf/minimal/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_cellparser.py::test_source_from_source_string3", "test/test_excel_import.py::test_language_comment_regex_error", "test/test_segment.py::test_segment_inventory_report", "test/test_homophones_merger.py::test_parse_merge_override", "test/test_matrix_exporter.py::test_toexcel_runs[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_excel_conversion.py::test_roundtrip[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp]", "test/test_matrix_exporter.py::test_toexcel_runs[data/cldf/minimal/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_cellparser.py::test_cellparser_separate_3", "test/test_dataset_issues.py::test_alignments_must_match_segments_ignore_gaps", "test/test_additional_import.py::test_superfluous_columns2[single_import_parameters0]", "test/test_excel_conversion.py::test_fromexcel_correct[excel_wordlist0]", "test/test_homophones_merger.py::test_simple", "test/test_segment.py::test_segment_report", "test/test_cellparser.py::test_mawetiparser_no_duplicate_sources", "test/test_concept_guesser.py::test_add_concepts_to_maweti_cognatesets[data/cldf/smallmawetiguarani/cldf-metadata.json]", "test/test_homophones_merger.py::test_concatenations", "test/test_additional_import.py::test_missing_columns2[single_import_parameters0]", "test/test_excel_conversion.py::test_toexcel_runs[data/cldf/minimal/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_excel_conversion.py::test_toexcel_runs[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_segment.py::test_illegal_symbol", "test/test_excel_conversion.py::test_roundtrip[data/cldf/smallmawetiguarani/cldf-metadata.json-copy_to_temp_no_bib]", "test/test_additional_import.py::test_add_concept_to_existing_form[single_import_parameters0]", "test/test_various_parsers.py::test_listorfromfile_file", "test/test_additional_import.py::test_import_report_add_concept[single_import_parameters0]", "test/test_form_matcher.py::test_form_association_id_after_normalization", "test/test_segment.py::test_add_segments_to_dataset", "test/test_excel_import.py::test_dialect_missing_key_excel_cognate_parser", "test/test_edictor.py::test_roundtrip[data/cldf/minimal/cldf-metadata.json-copy_to_temp_bad_bib]", "test/test_homophones_merger.py::test_constants"], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/anaphory_lexedata:f27489bdc0420ec11f7d0363437a4a98906163a7", "patch": "", "test_patch": "[\"diff --git a/test/test_various_parsers.py b/test/test_various_parsers.py\\nindex cc918ead..e27ebab4 100644\\n--- a/test/test_various_parsers.py\\n+++ b/test/test_various_parsers.py\\n@@ -27,12 +27,16 @@ def test_listorfromfile_file():\\n \\n \\n def test_filter_parser():\\n-    parameters = filter_parser().parse_args([\\\"form\\\", \\\"a\\\", \\\"FormTable\\\", \\\"-V\\\"])\\n+    _, fname = tempfile.mkstemp(\\\".csv\\\")\\n+    parameters = filter_parser().parse_args(\\n+        [\\\"form\\\", \\\"a\\\", \\\"FormTable\\\", \\\"-V\\\", \\\"-o\\\", fname]\\n+    )\\n     assert parameters.table == \\\"FormTable\\\"\\n     assert parameters.column == \\\"form\\\"\\n     assert parameters.filter == \\\"a\\\"\\n     assert parameters.invert is True\\n     assert parameters.output_columns == []\\n+    assert parameters.output_file.name == fname\\n \\n \\n def test_loglevel_parser():\\n\",\"diff --git a/.github/workflows/python-tox.yml b/.github/workflows/python-tox.yml\\nindex 048210f1..e14ed195 100644\\n--- a/.github/workflows/python-tox.yml\\n+++ b/.github/workflows/python-tox.yml\\n@@ -13,7 +13,7 @@ jobs:\\n     runs-on: ubuntu-latest\\n     strategy:\\n       matrix:\\n-        python: [3.8, 3.9, 3.10]\\n+        python: [3.7, 3.8, 3.9, 3.10]\\n         pycldf: [1.24.0, 1.21.0, NEWEST]\\n     steps:\\n     - uses: actions/checkout@v2\\n\",\"diff --git a/.github/workflows/python-tox.yml b/.github/workflows/python-tox.yml\\nindex e14ed195..048210f1 100644\\n--- a/.github/workflows/python-tox.yml\\n+++ b/.github/workflows/python-tox.yml\\n@@ -13,7 +13,7 @@ jobs:\\n     runs-on: ubuntu-latest\\n     strategy:\\n       matrix:\\n-        python: [3.7, 3.8, 3.9, 3.10]\\n+        python: [3.8, 3.9, 3.10]\\n         pycldf: [1.24.0, 1.21.0, NEWEST]\\n     steps:\\n     - uses: actions/checkout@v2\\n\",\"diff --git a/test/test_coverage.py b/test/test_coverage.py\\nindex b5d1b141..ae1977ee 100644\\n--- a/test/test_coverage.py\\n+++ b/test/test_coverage.py\\n@@ -28,11 +28,10 @@ def test_no_primary_concepts(caplog, cldf_wordlist):\\n \\n def test_uncoded_coverage_report(cldf_wordlist):\\n     dataset = cldf_wordlist\\n-    data, _ = coverage_report(\\n+    data = coverage_report(\\n         dataset=dataset,\\n         min_percentage=0,\\n         with_concept=[],\\n-        missing=False,\\n         only_coded=False,\\n     )\\n     assert data == [\\n@@ -45,8 +44,10 @@ def test_uncoded_coverage_report(cldf_wordlist):\\n \\n def test_coverage_report(cldf_wordlist):\\n     dataset = cldf_wordlist\\n-    data, _ = coverage_report(\\n-        dataset=dataset, min_percentage=0, with_concept=[], missing=False\\n+    data = coverage_report(\\n+        dataset=dataset,\\n+        min_percentage=0,\\n+        with_concept=[],\\n     )\\n     assert math.isnan(data[2][4])\\n     data[2][4] = 0\\n@@ -60,7 +61,7 @@ def test_coverage_report(cldf_wordlist):\\n \\n def test_coverage_concept_report(cldf_wordlist):\\n     dataset = cldf_wordlist\\n-    data, _ = coverage_report_concepts(dataset=dataset)\\n+    data = coverage_report_concepts(dataset=dataset)\\n     assert data == [\\n         [\\\"one\\\", 3],\\n         [\\\"one_1\\\", 1],\\n\",\"diff --git a/test/test_extended_validate.py b/test/test_extended_validate.py\\nnew file mode 100644\\nindex 00000000..6a675c8b\\n--- /dev/null\\n+++ b/test/test_extended_validate.py\\n@@ -0,0 +1,95 @@\\n+from pathlib import Path\\n+import re\\n+\\n+import pytest\\n+\\n+\\n+from helper_functions import copy_to_temp\\n+import lexedata.report.extended_cldf_validate as validate\\n+\\n+\\n+def test_check_foreignkeys_correct():\\n+    dataset, target = copy_to_temp(\\n+        Path(__file__).parent / \\\"data/cldf/smallmawetiguarani/cldf-metadata.json\\\"\\n+    )\\n+    assert validate.check_foreign_keys(dataset=dataset)\\n+\\n+\\n+@pytest.mark.skip(\\n+    reason=\\\"How to change the foreign key of the given dataset in a simple way?\\\"\\n+)\\n+def test_check_foreignkeys_warning(caplog):\\n+    dataset, target = copy_to_temp(\\n+        Path(__file__).parent / \\\"data/cldf/smallmawetiguarani/cldf-metadata.json\\\"\\n+    )\\n+\\n+\\n+@pytest.mark.skip(reason=\\\"Resolve TODO in extended_cldf_validate and check test data\\\")\\n+def test_check_unicode_data():\\n+    dataset, target = copy_to_temp(\\n+        Path(__file__).parent / \\\"data/cldf/smallmawetiguarani/cldf-metadata.json\\\"\\n+    )\\n+    assert validate.check_unicode_data(dataset=dataset)\\n+\\n+\\n+def test_check_unicode_data_warning(caplog):\\n+    dataset, target = copy_to_temp(\\n+        Path(__file__).parent / \\\"data/cldf/smallmawetiguarani/cldf-metadata.json\\\"\\n+    )\\n+    # insert incorrect unicode style\\n+    c_f_form = dataset[\\\"FormTable\\\", \\\"form\\\"].name\\n+    forms = [f for f in dataset[\\\"FormTable\\\"]]\\n+    form = forms[0]\\n+    form[c_f_form] = \\\"\\\\u0041\\\\u0300\\\"\\n+    forms[0] = form\\n+    dataset.write(FormTable=forms)\\n+\\n+    validate.check_unicode_data(dataset=dataset)\\n+    assert re.search(\\n+        \\\"Value À of row ache_one in table forms.csv is not in NFC normalized unicode\\\",\\n+        caplog.text,\\n+    )\\n+\\n+\\n+def test_check_empty_forms():\\n+    dataset, target = copy_to_temp(\\n+        Path(__file__).parent / \\\"data/cldf/smallmawetiguarani/cldf-metadata.json\\\"\\n+    )\\n+    assert validate.check_empty_forms(dataset=dataset)\\n+\\n+\\n+def test_check_empty_forms_warning(caplog):\\n+    dataset, target = copy_to_temp(\\n+        Path(__file__).parent / \\\"data/cldf/smallmawetiguarani/cldf-metadata.json\\\"\\n+    )\\n+    c_f_form = dataset[\\\"FormTable\\\", \\\"form\\\"].name\\n+    c_f_concept = dataset[\\\"FormTable\\\", \\\"parameterReference\\\"].name\\n+    forms = [f for f in dataset[\\\"FormTable\\\"]]\\n+    form = forms[0]\\n+    form[c_f_form] = \\\"\\\"\\n+    form[c_f_concept] = form[c_f_concept] + [\\\"two\\\"]\\n+    forms[0] = form\\n+    dataset.write(FormTable=forms)\\n+    validate.check_empty_forms(dataset=dataset)\\n+    assert re.search(r\\\"Non empty forms exist for the empty form ache_one\\\", caplog.text)\\n+\\n+\\n+def test_check_no_separator_in_ids():\\n+    dataset, target = copy_to_temp(\\n+        Path(__file__).parent / \\\"data/cldf/smallmawetiguarani/cldf-metadata.json\\\"\\n+    )\\n+    assert validate.check_no_separator_in_ids(dataset=dataset)\\n+\\n+\\n+@pytest.mark.skip(reason=\\\"not yet finished\\\")\\n+def test_check_no_separator_in_ids_warning(caplog):\\n+    dataset, target = copy_to_temp(\\n+        Path(__file__).parent / \\\"data/cldf/smallmawetiguarani/cldf-metadata.json\\\"\\n+    )\\n+    # c_c_id = dataset[\\\"ParameterTable\\\", \\\"id\\\"].name\\n+    # c_f_concept = dataset[\\\"FormTable\\\", \\\"parameterReference\\\"].name\\n+    # forms = [f for f in dataset[\\\"FormTable\\\"]]\\n+    # form = forms[0]\\n+    # concept_id = form[c_f_concept][0]\\n+    # concepts = {c[c_c_id]: c for c in dataset[\\\"ParameterTable\\\"]}\\n+    # concept = [c for c in dataset[\\\"ParameterTable\\\"] if c[c_c_id] == concept_id]\\n\",\"diff --git a/test/test_coverage.py b/test/test_coverage.py\\nindex ae1977ee..f1851220 100644\\n--- a/test/test_coverage.py\\n+++ b/test/test_coverage.py\\n@@ -7,6 +7,7 @@\\n \\n from lexedata.report.coverage import coverage_report, coverage_report_concepts\\n from lexedata.util.fs import copy_dataset\\n+from lexedata import util\\n \\n \\n @pytest.fixture(\\n@@ -72,3 +73,63 @@ def test_coverage_concept_report(cldf_wordlist):\\n         [\\\"five\\\", 3],\\n         [\\\"hand\\\", 1],\\n     ]\\n+\\n+\\n+def test_coverage_report_uncoded(cldf_wordlist):\\n+    dataset = cldf_wordlist\\n+    data = coverage_report(\\n+        dataset=dataset,\\n+        min_percentage=0,\\n+        with_concept=[],\\n+        only_coded=False,\\n+    )\\n+    assert data == [\\n+        [\\\"ache\\\", \\\"Aché\\\", 6, 0.6, 1.5],\\n+        [\\\"paraguayan_guarani\\\", \\\"Paraguayan Guaraní\\\", 7, 0.7, 1.0],\\n+        [\\\"old_paraguayan_guarani\\\", \\\"Old Paraguayan Guaraní\\\", 1, 0.1, 1.0],\\n+        [\\\"kaiwa\\\", \\\"Kaiwá\\\", 5, 0.5, 1.0],\\n+    ]\\n+\\n+\\n+def test_coverage_report_with_concept_table():\\n+    ds = util.fs.new_wordlist(\\n+        FormTable=[\\n+            {\\\"ID\\\": \\\"f2\\\", \\\"Language_ID\\\": \\\"l1\\\", \\\"Parameter_ID\\\": \\\"c2\\\", \\\"Form\\\": \\\"-\\\"},\\n+            {\\\"ID\\\": \\\"f3\\\", \\\"Language_ID\\\": \\\"l1\\\", \\\"Parameter_ID\\\": \\\"c3\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f4\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c1\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f5\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c2\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f6\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c3\\\", \\\"Form\\\": \\\"form\\\"},\\n+        ],\\n+        ParameterTable=[\\n+            {\\\"ID\\\": \\\"c1\\\"},\\n+            {\\\"ID\\\": \\\"c2\\\"},\\n+            {\\\"ID\\\": \\\"c3\\\"},\\n+            {\\\"ID\\\": \\\"c4\\\"},\\n+        ],\\n+    )\\n+    data = coverage_report(ds, only_coded=False)\\n+    assert data == [[\\\"l1\\\", \\\"l1\\\", 2, 0.5, 1.0], [\\\"l2\\\", \\\"l2\\\", 3, 0.75, 1.0]]\\n+\\n+\\n+def test_coverage_report_with_primary_concepts():\\n+    ds = util.fs.new_wordlist(\\n+        FormTable=[\\n+            {\\\"ID\\\": \\\"f2\\\", \\\"Language_ID\\\": \\\"l1\\\", \\\"Parameter_ID\\\": \\\"c2\\\", \\\"Form\\\": \\\"-\\\"},\\n+            {\\\"ID\\\": \\\"f3\\\", \\\"Language_ID\\\": \\\"l1\\\", \\\"Parameter_ID\\\": \\\"c3\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f4\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c1\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f5\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c2\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f6\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c3\\\", \\\"Form\\\": \\\"form\\\"},\\n+        ],\\n+        ParameterTable=[],\\n+    )\\n+    ds.add_columns(\\\"ParameterTable\\\", \\\"Primary\\\")\\n+    ds.write(\\n+        ParameterTable=[\\n+            {\\\"ID\\\": \\\"c1\\\", \\\"Primary\\\": \\\"yes\\\"},\\n+            {\\\"ID\\\": \\\"c2\\\", \\\"Primary\\\": \\\"yes\\\"},\\n+            {\\\"ID\\\": \\\"c3\\\", \\\"Primary\\\": \\\"yes\\\"},\\n+            {\\\"ID\\\": \\\"c4\\\", \\\"Primary\\\": \\\"\\\"},\\n+        ],\\n+    )\\n+    data = coverage_report(ds, only_coded=False)\\n+    assert data == [[\\\"l1\\\", \\\"l1\\\", 2, 2.0 / 3.0, 1.0], [\\\"l2\\\", \\\"l2\\\", 3, 1.0, 1.0]]\\n\",\"diff --git a/test/test_na_forms.py b/test/test_na_forms.py\\nindex 49eb12f5..4fc4978f 100644\\n--- a/test/test_na_forms.py\\n+++ b/test/test_na_forms.py\\n@@ -17,14 +17,13 @@\\n > value in a data row.\\n \\n There is, however, a third case: Data where the source states that the\\n-parameter value is not applicable to the language. We encode this generally by\\n-\\\"-\\\", but our goal is to in the end also accept other non-empty strings that\\n-contain no alphabetical characters, in particular \\\"/\\\" and \\\"–\\\".\\n+parameter value is not applicable to the language. We encode this by\\n+\\\"-\\\". We call these “NA forms”.\\n \\n Some source datasets use \\\"?\\\" to indicate cases 1 and 2, this needs to be\\n handled upon import.\\n \\n-Special handling of these three different NA forms alongside valid forms is\\n+Special handling of these three different NA/Missing forms alongside valid forms is\\n tested by this module. It affects multiple different components of Lexedata.\\n \\n \\\"\\\"\\\"\\n@@ -49,11 +48,12 @@\\n from lexedata.edit.add_singleton_cognatesets import create_singeltons\\n \\n from lexedata.report.homophones import list_homophones\\n+from lexedata.report.coverage import coverage_report, Missing\\n \\n+from lexedata import util, cli\\n from lexedata.types import WorldSet\\n from lexedata.util.fs import copy_dataset\\n from helper_functions import copy_metadata, copy_to_temp\\n-import lexedata.cli as cli\\n \\n \\n # Test the importers\\n@@ -691,9 +691,33 @@ def test_extended_cldf_validate():\\n     ...\\n \\n \\n-# TODO: so far coverage.py does not report forms at all, though we can skip \\\"\\\" and \\\"-\\\" forms\\n-def test_coverage_reports_na():\\n-    # TODO: Check that the coverage report can treat \\\"\\\" forms like missing\\n-    # rows, and that it can report \\\"-\\\" forms separately, and that it counts\\n-    # neither of these two as present forms.\\n-    ...\\n+def test_coverage_report_missing_and_na_default():\\n+    ds = util.fs.new_wordlist(\\n+        FormTable=[\\n+            {\\\"ID\\\": \\\"f1\\\", \\\"Language_ID\\\": \\\"l1\\\", \\\"Parameter_ID\\\": \\\"c1\\\", \\\"Form\\\": \\\"\\\"},\\n+            {\\\"ID\\\": \\\"f2\\\", \\\"Language_ID\\\": \\\"l1\\\", \\\"Parameter_ID\\\": \\\"c2\\\", \\\"Form\\\": \\\"-\\\"},\\n+            {\\\"ID\\\": \\\"f3\\\", \\\"Language_ID\\\": \\\"l1\\\", \\\"Parameter_ID\\\": \\\"c3\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f4\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c1\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f5\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c2\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f6\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c3\\\", \\\"Form\\\": \\\"form\\\"},\\n+        ]\\n+    )\\n+    ds[\\\"FormTable\\\", \\\"Form\\\"].required = False\\n+    data = coverage_report(ds, only_coded=False)\\n+    assert data == [[\\\"l1\\\", \\\"l1\\\", 2, 2.0 / 3.0, 1.0], [\\\"l2\\\", \\\"l2\\\", 3, 1.0, 1.0]]\\n+\\n+\\n+def test_coverage_report_missing_and_na_ignore():\\n+    ds = util.fs.new_wordlist(\\n+        FormTable=[\\n+            {\\\"ID\\\": \\\"f1\\\", \\\"Language_ID\\\": \\\"l1\\\", \\\"Parameter_ID\\\": \\\"c1\\\", \\\"Form\\\": \\\"\\\"},\\n+            {\\\"ID\\\": \\\"f2\\\", \\\"Language_ID\\\": \\\"l1\\\", \\\"Parameter_ID\\\": \\\"c2\\\", \\\"Form\\\": \\\"-\\\"},\\n+            {\\\"ID\\\": \\\"f3\\\", \\\"Language_ID\\\": \\\"l1\\\", \\\"Parameter_ID\\\": \\\"c3\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f4\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c1\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f5\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c2\\\", \\\"Form\\\": \\\"form\\\"},\\n+            {\\\"ID\\\": \\\"f6\\\", \\\"Language_ID\\\": \\\"l2\\\", \\\"Parameter_ID\\\": \\\"c3\\\", \\\"Form\\\": \\\"form\\\"},\\n+        ]\\n+    )\\n+    ds[\\\"FormTable\\\", \\\"Form\\\"].required = False\\n+    data = coverage_report(ds, only_coded=False, missing=Missing.IGNORE)\\n+    assert data == [[\\\"l1\\\", \\\"l1\\\", 2, 1.0 / 3.0, 1.0], [\\\"l2\\\", \\\"l2\\\", 3, 1.0, 1.0]]\\n\",\"diff --git a/test/test_na_forms.py b/test/test_na_forms.py\\nindex 4fc4978f..01fb8471 100644\\n--- a/test/test_na_forms.py\\n+++ b/test/test_na_forms.py\\n@@ -720,4 +720,4 @@ def test_coverage_report_missing_and_na_ignore():\\n     )\\n     ds[\\\"FormTable\\\", \\\"Form\\\"].required = False\\n     data = coverage_report(ds, only_coded=False, missing=Missing.IGNORE)\\n-    assert data == [[\\\"l1\\\", \\\"l1\\\", 2, 1.0 / 3.0, 1.0], [\\\"l2\\\", \\\"l2\\\", 3, 1.0, 1.0]]\\n+    assert data == [[\\\"l1\\\", \\\"l1\\\", 1, 1.0 / 3.0, 1.0], [\\\"l2\\\", \\\"l2\\\", 3, 1.0, 1.0]]\\n\",\"diff --git a/test/test_extended_validate.py b/test/test_extended_validate.py\\nindex 6a675c8b..b6aff846 100644\\n--- a/test/test_extended_validate.py\\n+++ b/test/test_extended_validate.py\\n@@ -1,4 +1,5 @@\\n from pathlib import Path\\n+import unicodedata\\n import re\\n \\n import pytest\\n@@ -46,16 +47,19 @@ def test_check_unicode_data_warning(caplog):\\n \\n     validate.check_unicode_data(dataset=dataset)\\n     assert re.search(\\n-        \\\"Value À of row ache_one in table forms.csv is not in NFC normalized unicode\\\",\\n-        caplog.text,\\n+        unicodedata.normalize(\\n+            \\\"NFC\\\",\\n+            \\\"Value À of row 1 in table forms.csv is not in NFC normalized unicode\\\",\\n+        ),\\n+        unicodedata.normalize(\\\"NFC\\\", caplog.text),\\n     )\\n \\n \\n-def test_check_empty_forms():\\n+def test_check_na_forms():\\n     dataset, target = copy_to_temp(\\n         Path(__file__).parent / \\\"data/cldf/smallmawetiguarani/cldf-metadata.json\\\"\\n     )\\n-    assert validate.check_empty_forms(dataset=dataset)\\n+    assert validate.check_nal_form_has_no_alternative(dataset=dataset)\\n \\n \\n def test_check_empty_forms_warning(caplog):\\n@@ -70,7 +74,7 @@ def test_check_empty_forms_warning(caplog):\\n     form[c_f_concept] = form[c_f_concept] + [\\\"two\\\"]\\n     forms[0] = form\\n     dataset.write(FormTable=forms)\\n-    validate.check_empty_forms(dataset=dataset)\\n+    validate.check_nal_form_has_no_alternative(dataset=dataset)\\n     assert re.search(r\\\"Non empty forms exist for the empty form ache_one\\\", caplog.text)\\n \\n \\n\",\"diff --git a/test/test_extended_validate.py b/test/test_extended_validate.py\\nindex b6aff846..82bb6c51 100644\\n--- a/test/test_extended_validate.py\\n+++ b/test/test_extended_validate.py\\n@@ -59,7 +59,7 @@ def test_check_na_forms():\\n     dataset, target = copy_to_temp(\\n         Path(__file__).parent / \\\"data/cldf/smallmawetiguarani/cldf-metadata.json\\\"\\n     )\\n-    assert validate.check_nal_form_has_no_alternative(dataset=dataset)\\n+    assert validate.check_na_form_has_no_alternative(dataset=dataset)\\n \\n \\n def test_check_empty_forms_warning(caplog):\\n@@ -74,7 +74,7 @@ def test_check_empty_forms_warning(caplog):\\n     form[c_f_concept] = form[c_f_concept] + [\\\"two\\\"]\\n     forms[0] = form\\n     dataset.write(FormTable=forms)\\n-    validate.check_nal_form_has_no_alternative(dataset=dataset)\\n+    validate.check_na_form_has_no_alternative(dataset=dataset)\\n     assert re.search(r\\\"Non empty forms exist for the empty form ache_one\\\", caplog.text)\\n \\n \\n\",\"diff --git a/test/test_extended_validate.py b/test/test_extended_validate.py\\nindex 82bb6c51..05b45e2a 100644\\n--- a/test/test_extended_validate.py\\n+++ b/test/test_extended_validate.py\\n@@ -70,12 +70,12 @@ def test_check_empty_forms_warning(caplog):\\n     c_f_concept = dataset[\\\"FormTable\\\", \\\"parameterReference\\\"].name\\n     forms = [f for f in dataset[\\\"FormTable\\\"]]\\n     form = forms[0]\\n-    form[c_f_form] = \\\"\\\"\\n+    form[c_f_form] = \\\"-\\\"\\n     form[c_f_concept] = form[c_f_concept] + [\\\"two\\\"]\\n     forms[0] = form\\n     dataset.write(FormTable=forms)\\n     validate.check_na_form_has_no_alternative(dataset=dataset)\\n-    assert re.search(r\\\"Non empty forms exist for the empty form ache_one\\\", caplog.text)\\n+    assert re.search(r\\\"exist for the NA form ache_one\\\", caplog.text)\\n \\n \\n def test_check_no_separator_in_ids():\"]", "hints_text": ""}
