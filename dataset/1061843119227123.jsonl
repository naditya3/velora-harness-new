{"instance_id": "1061843119227123", "repo": "equinor/ert-storage", "base_commit": "fbb8513fae853f55f279f35c1672662f435e2962", "problem_statement": "Make RecordType be a ENUM:\\nCurrently the `record_type` is a integer column with a hacky conversion to and from `enum.Enum`, rather than an enum column like `record_class`. We should convert it to the same mechanism as `record_class`.", "FAIL_TO_PASS": ["tests/integration/test_records.py::test_ensemble_wide_parameters_dataframe[application/x-dataframe]", "tests/integration/test_record_infos.py::test_different_record_classes", "tests/integration/test_records.py::test_ensemble_file", "tests/integration/test_update.py::test_observation_transformations", "tests/integration/test_responses.py::test_get_response_data", "tests/integration/test_records.py::test_ensemble_matrix_dataframe[application/x-dataframe]", "tests/integration/gql/test_ensembles.py::test_get_ensemble", "tests/integration/gql/test_experiments.py::test_get_single_experiment", "tests/integration/test_records.py::test_ensemble_matrix_json[numpy-json]", "tests/integration/test_experiments.py::test_ensembles", "tests/integration/test_records.py::test_ensemble_wide_parameters_dataframe[text/csv]", "tests/integration/test_records.py::test_parameters", "tests/integration/test_observations.py::test_observations_with_records", "tests/integration/test_records.py::test_missing_record_exception", "tests/integration/test_records.py::test_ensemble_matrix_json[numpy-numpy]", "tests/integration/gql/test_experiments.py::test_create_experiment", "tests/integration/test_records.py::test_blocked_blob", "tests/integration/test_records.py::test_list", "tests/integration/test_records.py::test_ensemble_matrix_dataframe[text/csv]", "tests/integration/gql/test_ensembles.py::test_create_ensemble", "tests/integration/test_records.py::test_ensemble_matrix_json[json-json]", "tests/integration/test_records.py::test_ensemble_wide_parameters_1d", "tests/integration/compute/test_misfits_endpoints.py::test_misfits_with_labels", "tests/integration/gql/test_experiments.py::test_create_experiment_with_ensemble", "tests/integration/test_observations.py::test_records_with_observations", "tests/integration/gql/test_priors.py::test_get_prior_for_parameters", "tests/integration/test_records.py::test_matrix", "tests/integration/test_records.py::test_forward_model_file", "tests/integration/test_experiments.py::test_ensemble_size", "tests/integration/test_records.py::test_responses", "tests/integration/test_metadata.py::test_metadata[post_record]", "tests/integration/test_records.py::test_ensemble_size_out_of_bounds", "tests/integration/test_records.py::test_ensemble_matrix_json[json-numpy]", "tests/integration/test_experiments.py::test_delete_experiment", "tests/integration/test_responses.py::test_get_response_data_with_nan", "tests/integration/test_metadata.py::test_metadata[post_ensemble]", "tests/integration/test_records.py::test_ensemble_wide_parameters", "tests/integration/test_update.py::test_ensemble_parent_child_link", "tests/integration/gql/test_responses.py::test_get_gql_response"], "PASS_TO_PASS": ["tests/integration/test_metadata.py::test_metadata[post_observation]", "tests/integration/test_priors.py::test_post_prior[make_trig_prior]", "tests/integration/test_priors.py::test_post_prior[make_stdnormal_prior]", "tests/integration/gql/test_experiments.py::test_get_list_experiments", "tests/unit/test_testclient.py::test_rest[True]", "tests/integration/test_priors.py::test_post_prior[make_truncnormal_prior]", "tests/unit/test_testclient.py::test_environ", "tests/unit/test_testclient.py::test_rest[False]", "tests/integration/test_experiments.py::test_list", "tests/integration/gql/test_priors.py::test_get_priors", "tests/integration/test_priors.py::test_post_prior[make_uniform_prior]", "tests/integration/test_observations.py::test_observations", "tests/unit/test_testclient.py::test_gql[True]", "tests/integration/test_priors.py::test_post_prior[make_loguniform_prior]", "tests/integration/test_priors.py::test_post_multiple_priors", "tests/integration/test_priors.py::test_post_prior[make_normal_prior]", "tests/integration/test_priors.py::test_post_prior[make_erf_prior]", "tests/integration/test_metadata.py::test_metadata[post_experiment]", "tests/integration/test_priors.py::test_post_prior[make_duniform_prior]", "tests/integration/test_priors.py::test_post_prior[make_derf_prior]", "tests/integration/test_priors.py::test_post_prior[make_const_prior]", "tests/unit/test_testclient.py::test_gql[False]", "tests/integration/test_priors.py::test_post_prior[make_lognormal_prior]"], "language": "python", "test_command": "source /saved/ENV || source /saved/*/ENV && pytest --no-header -rA --tb=no -p no:cacheprovider --continue-on-collection-errors", "test_output_parser": "python/parse_log_pytest_v3", "image_storage_uri": "vmvm-registry.fbinfra.net/repomate_image_activ_pytest/equinor_ert-storage:fbb8513fae853f55f279f35c1672662f435e2962", "patch": "[\"diff --git a/ert_storage/_alembic/alembic/versions/021d7514e351_add_recordinfo.py b/ert_storage/_alembic/alembic/versions/021d7514e351_add_recordinfo.py\\nnew file mode 100644\\nindex 00000000..fa34a3aa\\n--- /dev/null\\n+++ b/ert_storage/_alembic/alembic/versions/021d7514e351_add_recordinfo.py\\n@@ -0,0 +1,127 @@\\n+\\\"\\\"\\\"Add RecordInfo\\n+\\n+Revision ID: 021d7514e351\\n+Revises: 7812741cc469\\n+Create Date: 2021-05-18 10:09:39.833270\\n+\\n+\\\"\\\"\\\"\\n+from alembic import op\\n+import sqlalchemy as sa\\n+from sqlalchemy.dialects import postgresql\\n+\\n+# revision identifiers, used by Alembic.\\n+revision = \\\"021d7514e351\\\"\\n+down_revision = \\\"7812741cc469\\\"\\n+branch_labels = None\\n+depends_on = None\\n+\\n+\\n+def upgrade():\\n+    op.execute(\\\"ALTER TYPE recordtype RENAME VALUE 'float_vector' TO 'f64_matrix'\\\")\\n+    op.drop_column(\\\"record\\\", \\\"record_class\\\")\\n+    op.execute(\\\"DROP TYPE recordclass\\\")\\n+    recordtype_postgres = postgresql.ENUM(\\n+        \\\"f64_matrix\\\", \\\"file\\\", name=\\\"recordtype\\\", create_type=False\\n+    )\\n+    # ### commands auto generated by Alembic - please adjust! ###\\n+    op.create_table(\\n+        \\\"record_info\\\",\\n+        sa.Column(\\\"pk\\\", sa.Integer(), nullable=False),\\n+        sa.Column(\\n+            \\\"time_created\\\",\\n+            sa.DateTime(),\\n+            server_default=sa.text(\\\"now()\\\"),\\n+            nullable=True,\\n+        ),\\n+        sa.Column(\\n+            \\\"time_updated\\\",\\n+            sa.DateTime(),\\n+            server_default=sa.text(\\\"now()\\\"),\\n+            nullable=True,\\n+        ),\\n+        sa.Column(\\\"ensemble_pk\\\", sa.Integer(), nullable=False),\\n+        sa.Column(\\\"name\\\", sa.String(), nullable=False),\\n+        sa.Column(\\n+            \\\"record_type\\\",\\n+            recordtype_postgres,\\n+            nullable=False,\\n+        ),\\n+        sa.Column(\\n+            \\\"record_class\\\",\\n+            sa.Enum(\\\"parameter\\\", \\\"response\\\", \\\"other\\\", name=\\\"recordclass\\\"),\\n+            nullable=False,\\n+        ),\\n+        sa.Column(\\\"prior_pk\\\", sa.Integer(), nullable=True),\\n+        sa.ForeignKeyConstraint(\\n+            [\\\"ensemble_pk\\\"],\\n+            [\\\"ensemble.pk\\\"],\\n+        ),\\n+        sa.ForeignKeyConstraint(\\n+            [\\\"prior_pk\\\"],\\n+            [\\\"prior.pk\\\"],\\n+        ),\\n+        sa.PrimaryKeyConstraint(\\\"pk\\\"),\\n+        sa.UniqueConstraint(\\\"name\\\", \\\"ensemble_pk\\\"),\\n+    )\\n+    op.add_column(\\n+        \\\"ensemble\\\", sa.Column(\\\"parameter_names\\\", sa.ARRAY(sa.String()), nullable=False)\\n+    )\\n+    op.add_column(\\n+        \\\"ensemble\\\", sa.Column(\\\"response_names\\\", sa.ARRAY(sa.String()), nullable=False)\\n+    )\\n+    op.drop_column(\\\"ensemble\\\", \\\"inputs\\\")\\n+    op.add_column(\\\"record\\\", sa.Column(\\\"record_info_pk\\\", sa.Integer(), nullable=True))\\n+    op.drop_constraint(\\\"record_prior_pk_fkey\\\", \\\"record\\\", type_=\\\"foreignkey\\\")\\n+    op.drop_constraint(\\\"record_ensemble_id_fkey\\\", \\\"record\\\", type_=\\\"foreignkey\\\")\\n+    op.create_foreign_key(None, \\\"record\\\", \\\"record_info\\\", [\\\"record_info_pk\\\"], [\\\"pk\\\"])\\n+    op.drop_column(\\\"record\\\", \\\"ensemble_pk\\\")\\n+    op.drop_column(\\\"record\\\", \\\"prior_pk\\\")\\n+    op.drop_column(\\\"record\\\", \\\"record_type\\\")\\n+    op.drop_column(\\\"record\\\", \\\"name\\\")\\n+    # ### end Alembic commands ###\\n+\\n+\\n+def downgrade():\\n+    # ### commands auto generated by Alembic - please adjust! ###\\n+    op.add_column(\\n+        \\\"record\\\", sa.Column(\\\"name\\\", sa.VARCHAR(), autoincrement=False, nullable=False)\\n+    )\\n+    op.add_column(\\n+        \\\"record\\\",\\n+        sa.Column(\\n+            \\\"record_class\\\",\\n+            postgresql.ENUM(\\\"parameter\\\", \\\"response\\\", \\\"other\\\", name=\\\"recordclass\\\"),\\n+            autoincrement=False,\\n+            nullable=True,\\n+        ),\\n+    )\\n+    op.add_column(\\n+        \\\"record\\\",\\n+        sa.Column(\\\"record_type\\\", sa.INTEGER(), autoincrement=False, nullable=False),\\n+    )\\n+    op.add_column(\\n+        \\\"record\\\",\\n+        sa.Column(\\\"prior_pk\\\", sa.INTEGER(), autoincrement=False, nullable=True),\\n+    )\\n+    op.add_column(\\n+        \\\"record\\\",\\n+        sa.Column(\\\"ensemble_pk\\\", sa.INTEGER(), autoincrement=False, nullable=True),\\n+    )\\n+    op.drop_constraint(None, \\\"record\\\", type_=\\\"foreignkey\\\")\\n+    op.create_foreign_key(\\n+        \\\"record_ensemble_id_fkey\\\", \\\"record\\\", \\\"ensemble\\\", [\\\"ensemble_pk\\\"], [\\\"pk\\\"]\\n+    )\\n+    op.create_foreign_key(\\n+        \\\"record_prior_pk_fkey\\\", \\\"record\\\", \\\"prior\\\", [\\\"prior_pk\\\"], [\\\"pk\\\"]\\n+    )\\n+    op.drop_column(\\\"record\\\", \\\"record_info_pk\\\")\\n+    op.add_column(\\n+        \\\"ensemble\\\",\\n+        sa.Column(\\n+            \\\"inputs\\\", postgresql.ARRAY(sa.VARCHAR()), autoincrement=False, nullable=True\\n+        ),\\n+    )\\n+    op.drop_column(\\\"ensemble\\\", \\\"response_names\\\")\\n+    op.drop_column(\\\"ensemble\\\", \\\"parameter_names\\\")\\n+    op.drop_table(\\\"record_info\\\")\\n+    # ### end Alembic commands ###\\n\",\"diff --git a/ert_storage/database_schema/__init__.py b/ert_storage/database_schema/__init__.py\\nindex 8f6dbb1b..213082c8 100644\\n--- a/ert_storage/database_schema/__init__.py\\n+++ b/ert_storage/database_schema/__init__.py\\n@@ -1,5 +1,6 @@\\n from .metadatafield import MetadataField\\n-from .record import Record, F64Matrix, File, FileBlock, RecordClass, RecordType\\n+from .record_info import RecordInfo, RecordType, RecordClass\\n+from .record import Record, F64Matrix, File, FileBlock\\n from .ensemble import Ensemble\\n from .experiment import Experiment\\n from .observation import Observation, ObservationTransformation\\n\",\"diff --git a/ert_storage/database_schema/ensemble.py b/ert_storage/database_schema/ensemble.py\\nindex 3130e5bc..e8c28786 100644\\n--- a/ert_storage/database_schema/ensemble.py\\n+++ b/ert_storage/database_schema/ensemble.py\\n@@ -1,13 +1,11 @@\\n-from enum import Enum\\n-from typing import Any, Iterable\\n-from uuid import uuid4\\n+from typing import List\\n+from uuid import uuid4, UUID as PyUUID\\n import sqlalchemy as sa\\n from sqlalchemy.orm import relationship\\n from sqlalchemy.sql import func\\n from ert_storage.database import Base\\n from .metadatafield import MetadataField\\n-from .record import RecordClass, Record\\n-from ert_storage.ext.uuid import UUID\\n+from ert_storage.ext.uuid import UUID as UUID\\n from ert_storage.ext.sqlalchemy_arrays import StringArray\\n \\n \\n@@ -21,10 +19,11 @@ class Ensemble(Base, MetadataField):\\n     time_updated = sa.Column(\\n         sa.DateTime, server_default=func.now(), onupdate=func.now()\\n     )\\n-    inputs = sa.Column(StringArray)\\n-    records = relationship(\\n-        \\\"Record\\\",\\n-        foreign_keys=\\\"[Record.ensemble_pk]\\\",\\n+    parameter_names = sa.Column(StringArray, nullable=False)\\n+    response_names = sa.Column(StringArray, nullable=False)\\n+    record_infos = relationship(\\n+        \\\"RecordInfo\\\",\\n+        foreign_keys=\\\"[RecordInfo.ensemble_pk]\\\",\\n         cascade=\\\"all, delete-orphan\\\",\\n         lazy=\\\"dynamic\\\",\\n     )\\n@@ -44,5 +43,9 @@ class Ensemble(Base, MetadataField):\\n     )\\n \\n     @property\\n-    def parameters(self) -> Iterable[\\\"Record\\\"]:\\n-        return self.records.filter_by(record_class=RecordClass.parameter)\\n+    def parent_ensemble_id(self) -> PyUUID:\\n+        return self.parent.ensemble_reference.id\\n+\\n+    @property\\n+    def child_ensemble_ids(self) -> List[PyUUID]:\\n+        return [x.ensemble_result.id for x in self.children]\\n\",\"diff --git a/ert_storage/database_schema/prior.py b/ert_storage/database_schema/prior.py\\nindex 6c0bcf6f..781c45ea 100644\\n--- a/ert_storage/database_schema/prior.py\\n+++ b/ert_storage/database_schema/prior.py\\n@@ -42,4 +42,3 @@ class Prior(Base, MetadataField):\\n         sa.Integer, sa.ForeignKey(\\\"experiment.pk\\\"), nullable=False\\n     )\\n     experiment = relationship(\\\"Experiment\\\")\\n-    parameters = relationship(\\\"Record\\\", foreign_keys=\\\"[Record.prior_pk]\\\")\\n\",\"diff --git a/ert_storage/database_schema/record.py b/ert_storage/database_schema/record.py\\nindex 709361e5..0a581b83 100644\\n--- a/ert_storage/database_schema/record.py\\n+++ b/ert_storage/database_schema/record.py\\n@@ -1,38 +1,23 @@\\n-from enum import Enum\\n-from typing import Any, Optional\\n+from typing import Any\\n+from uuid import uuid4\\n+\\n import sqlalchemy as sa\\n-from ert_storage.database import Base\\n from sqlalchemy.sql import func\\n from sqlalchemy.orm import relationship\\n+from sqlalchemy.ext.hybrid import hybrid_property\\n+\\n+from ert_storage.ext.sqlalchemy_arrays import FloatArray\\n from ert_storage.ext.uuid import UUID\\n-from uuid import uuid4\\n+from ert_storage.database import Base\\n \\n from .metadatafield import MetadataField\\n from .observation import observation_record_association\\n-from ert_storage.ext.sqlalchemy_arrays import FloatArray\\n-\\n-\\n-class RecordType(Enum):\\n-    float_vector = 1\\n-    file = 2\\n-\\n-\\n-class RecordClass(Enum):\\n-    parameter = 1\\n-    response = 2\\n-    other = 3\\n+from .record_info import RecordType\\n \\n \\n class Record(Base, MetadataField):\\n     __tablename__ = \\\"record\\\"\\n \\n-    def __init__(\\n-        self, *args: Any, record_type: Optional[RecordType] = None, **kwargs: Any\\n-    ) -> None:\\n-        if record_type is not None:\\n-            kwargs.setdefault(\\\"record_type\\\", record_type)\\n-        super().__init__(*args, **kwargs)\\n-\\n     pk = sa.Column(sa.Integer, primary_key=True)\\n     id = sa.Column(UUID, unique=True, default=uuid4, nullable=False)\\n     time_created = sa.Column(sa.DateTime, server_default=func.now())\\n@@ -40,38 +25,41 @@ def __init__(\\n         sa.DateTime, server_default=func.now(), onupdate=func.now()\\n     )\\n \\n-    name = sa.Column(sa.String, nullable=False)\\n     realization_index = sa.Column(sa.Integer, nullable=True)\\n-    record_type = sa.Column(sa.Enum(RecordType), nullable=False)\\n+\\n+    record_info_pk = sa.Column(\\n+        sa.Integer, sa.ForeignKey(\\\"record_info.pk\\\"), nullable=True\\n+    )\\n+    record_info = relationship(\\\"RecordInfo\\\", back_populates=\\\"records\\\")\\n \\n     file_pk = sa.Column(sa.Integer, sa.ForeignKey(\\\"file.pk\\\"))\\n     f64_matrix_pk = sa.Column(sa.Integer, sa.ForeignKey(\\\"f64_matrix.pk\\\"))\\n \\n     file = relationship(\\\"File\\\", cascade=\\\"all\\\")\\n     f64_matrix = relationship(\\\"F64Matrix\\\", cascade=\\\"all\\\")\\n-    ensemble_pk = sa.Column(sa.Integer, sa.ForeignKey(\\\"ensemble.pk\\\"), nullable=True)\\n-    ensemble = relationship(\\\"Ensemble\\\", back_populates=\\\"records\\\")\\n+\\n     observations = relationship(\\n         \\\"Observation\\\",\\n         secondary=observation_record_association,\\n         back_populates=\\\"records\\\",\\n     )\\n-    record_class = sa.Column(sa.Enum(RecordClass))\\n-\\n-    prior_pk = sa.Column(sa.Integer, sa.ForeignKey(\\\"prior.pk\\\"), nullable=True)\\n-    prior = relationship(\\\"Prior\\\", back_populates=\\\"parameters\\\")\\n \\n     @property\\n     def data(self) -> Any:\\n-        if self.record_type == RecordType.file:\\n+        info = self.record_info\\n+        if info.record_type == RecordType.file:\\n             return self.file.content\\n-        elif self.record_type == RecordType.float_vector:\\n+        elif info.record_type == RecordType.f64_matrix:\\n             return self.f64_matrix.content\\n         else:\\n             raise NotImplementedError(\\n                 f\\\"The record type {self.record_type} is not yet implemented\\\"\\n             )\\n \\n+    @property\\n+    def name(self) -> str:\\n+        return self.record_info.name\\n+\\n \\n class File(Base):\\n     __tablename__ = \\\"file\\\"\\n\",\"diff --git a/ert_storage/database_schema/record_info.py b/ert_storage/database_schema/record_info.py\\nnew file mode 100644\\nindex 00000000..fdccc5d4\\n--- /dev/null\\n+++ b/ert_storage/database_schema/record_info.py\\n@@ -0,0 +1,46 @@\\n+from enum import Enum\\n+\\n+import sqlalchemy as sa\\n+from sqlalchemy.orm import relationship\\n+from sqlalchemy.sql import func\\n+\\n+from ert_storage.database import Base\\n+\\n+\\n+class RecordType(Enum):\\n+    f64_matrix = 1\\n+    file = 2\\n+\\n+\\n+class RecordClass(Enum):\\n+    parameter = 1\\n+    response = 2\\n+    other = 3\\n+\\n+\\n+class RecordInfo(Base):\\n+    __tablename__ = \\\"record_info\\\"\\n+    __table_args__ = (sa.UniqueConstraint(\\\"name\\\", \\\"ensemble_pk\\\"),)\\n+\\n+    pk = sa.Column(sa.Integer, primary_key=True)\\n+    time_created = sa.Column(sa.DateTime, server_default=func.now())\\n+    time_updated = sa.Column(\\n+        sa.DateTime, server_default=func.now(), onupdate=func.now()\\n+    )\\n+\\n+    ensemble_pk = sa.Column(sa.Integer, sa.ForeignKey(\\\"ensemble.pk\\\"), nullable=False)\\n+    ensemble = relationship(\\\"Ensemble\\\")\\n+\\n+    records = relationship(\\n+        \\\"Record\\\",\\n+        foreign_keys=\\\"[Record.record_info_pk]\\\",\\n+        cascade=\\\"all, delete-orphan\\\",\\n+    )\\n+\\n+    name = sa.Column(sa.String, nullable=False)\\n+    record_type = sa.Column(sa.Enum(RecordType), nullable=False)\\n+    record_class = sa.Column(sa.Enum(RecordClass), nullable=False)\\n+\\n+    # Parameter-specific data\\n+    prior_pk = sa.Column(sa.Integer, sa.ForeignKey(\\\"prior.pk\\\"), nullable=True)\\n+    prior = relationship(\\\"Prior\\\")\\n\",\"diff --git a/ert_storage/endpoints/compute/misfits.py b/ert_storage/endpoints/compute/misfits.py\\nindex 15f58536..463cb14c 100644\\n--- a/ert_storage/endpoints/compute/misfits.py\\n+++ b/ert_storage/endpoints/compute/misfits.py\\n@@ -1,3 +1,4 @@\\n+from ert_storage.database_schema.record import F64Matrix\\n import numpy as np\\n import pandas as pd\\n from uuid import UUID\\n@@ -33,20 +34,25 @@ async def get_response_misfits(\\n     Compute univariate misfits for response(s)\\n     \\\"\\\"\\\"\\n \\n-    ensemble = db.query(ds.Ensemble).filter_by(id=ensemble_id).one()\\n-    reponse_query = (\\n+    response_query = (\\n         db.query(ds.Record)\\n+        .filter(ds.Record.observations != None)\\n+        .join(ds.RecordInfo)\\n         .filter_by(\\n-            ensemble_pk=ensemble.pk,\\n             name=response_name,\\n-            record_type=ds.RecordType.float_vector,\\n+            record_type=ds.RecordType.f64_matrix,\\n         )\\n-        .filter(ds.Record.observations != None)\\n+        .join(ds.Ensemble)\\n+        .filter_by(id=ensemble_id)\\n     )\\n     if realization_index is not None:\\n-        responses = [reponse_query.filter_by(realization_index=realization_index).one()]\\n+        responses = [\\n+            response_query.filter(\\n+                ds.Record.realization_index == realization_index\\n+            ).one()\\n+        ]\\n     else:\\n-        responses = reponse_query.all()\\n+        responses = response_query.all()\\n \\n     observation_df = None\\n     response_dict = {}\\n@@ -80,5 +86,5 @@ async def get_response_misfits(\\n         )\\n     return Response(\\n         content=result_df.to_csv().encode(),\\n-        media_type=\\\"application/x-dataframe\\\",\\n+        media_type=\\\"text/csv\\\",\\n     )\\n\",\"diff --git a/ert_storage/endpoints/ensembles.py b/ert_storage/endpoints/ensembles.py\\nindex a2543c34..e20e2d92 100644\\n--- a/ert_storage/endpoints/ensembles.py\\n+++ b/ert_storage/endpoints/ensembles.py\\n@@ -12,11 +12,12 @@\\n @router.post(\\\"/experiments/{experiment_id}/ensembles\\\", response_model=js.EnsembleOut)\\n def post_ensemble(\\n     *, db: Session = Depends(get_db), ens_in: js.EnsembleIn, experiment_id: UUID\\n-) -> js.EnsembleOut:\\n+) -> ds.Ensemble:\\n \\n     experiment = db.query(ds.Experiment).filter_by(id=experiment_id).one()\\n     ens = ds.Ensemble(\\n-        inputs=ens_in.parameters,\\n+        parameter_names=ens_in.parameter_names,\\n+        response_names=ens_in.response_names,\\n         experiment=experiment,\\n         size=ens_in.size,\\n         _metadata=ens_in.metadata,\\n@@ -28,25 +29,12 @@ def post_ensemble(\\n         update_obj.ensemble_result = ens\\n     db.commit()\\n \\n-    return js.EnsembleOut(\\n-        id=ens.id,\\n-        size=ens.size,\\n-        children=[child.ensemble_result.id for child in ens.children],\\n-        parent=ens.parent.ensemble_reference.id if ens.parent else None,\\n-    )\\n+    return ens\\n \\n \\n @router.get(\\\"/ensembles/{ensemble_id}\\\", response_model=js.EnsembleOut)\\n-def get_ensemble(*, db: Session = Depends(get_db), ensemble_id: UUID) -> js.EnsembleOut:\\n-    ens = db.query(ds.Ensemble).filter_by(id=ensemble_id).one()\\n-\\n-    return js.EnsembleOut(\\n-        id=ens.id,\\n-        size=ens.size,\\n-        children=[child.ensemble_result.id for child in ens.children],\\n-        parent=ens.parent.ensemble_reference.id if ens.parent else None,\\n-        experiment_id=ens.experiment.id,\\n-    )\\n+def get_ensemble(*, db: Session = Depends(get_db), ensemble_id: UUID) -> ds.Ensemble:\\n+    return db.query(ds.Ensemble).filter_by(id=ensemble_id).one()\\n \\n \\n @router.put(\\\"/ensembles/{ensemble_id}/metadata\\\")\\n\",\"diff --git a/ert_storage/endpoints/experiments.py b/ert_storage/endpoints/experiments.py\\nindex e265e0bd..3286bf28 100644\\n--- a/ert_storage/endpoints/experiments.py\\n+++ b/ert_storage/endpoints/experiments.py\\n@@ -62,18 +62,8 @@ def post_experiments(\\n )\\n def get_experiment_ensembles(\\n     *, db: Session = Depends(get_db), experiment_id: UUID\\n-) -> List[js.EnsembleOut]:\\n-    experiment = db.query(ds.Experiment).filter_by(id=experiment_id).one()\\n-    return [\\n-        js.EnsembleOut(\\n-            id=ens.id,\\n-            size=ens.size,\\n-            children=[child.ensemble_result.id for child in ens.children],\\n-            parent=ens.parent.ensemble_reference.id if ens.parent else None,\\n-            experiment_id=ens.experiment.id,\\n-        )\\n-        for ens in experiment.ensembles\\n-    ]\\n+) -> List[ds.Ensemble]:\\n+    return db.query(ds.Ensemble).join(ds.Experiment).filter_by(id=experiment_id).all()\\n \\n \\n @router.put(\\\"/experiments/{experiment_id}/metadata\\\")\\n\",\"diff --git a/ert_storage/endpoints/records.py b/ert_storage/endpoints/records.py\\nindex 632013f7..089befe0 100644\\n--- a/ert_storage/endpoints/records.py\\n+++ b/ert_storage/endpoints/records.py\\n@@ -18,6 +18,7 @@\\n )\\n from fastapi.responses import Response, StreamingResponse\\n from pydantic import BaseModel\\n+from sqlalchemy.exc import IntegrityError\\n from sqlalchemy.orm.exc import NoResultFound\\n from sqlalchemy.orm.attributes import flag_modified\\n from ert_storage.database import Session, get_db, HAS_AZURE_BLOB_STORAGE, BLOB_CONTAINER\\n@@ -66,17 +67,15 @@ async def post_ensemble_record_file(\\n         file_obj.content = await file.read()\\n \\n     db.add(file_obj)\\n-    record_obj = ds.Record(\\n-        name=name,\\n-        record_type=ds.RecordType.file,\\n+    _create_record(\\n+        db,\\n+        ensemble,\\n+        name,\\n+        ds.RecordType.file,\\n         realization_index=realization_index,\\n         file=file_obj,\\n-        record_class=ds.RecordClass.other,\\n     )\\n \\n-    record_obj.ensemble = ensemble\\n-    db.add(record_obj)\\n-\\n \\n @router.put(\\\"/ensembles/{ensemble_id}/records/{name}/blob\\\")\\n async def add_block(\\n@@ -105,9 +104,9 @@ async def add_block(\\n \\n     record_obj = (\\n         db.query(ds.Record)\\n-        .filter_by(\\n-            ensemble_pk=ensemble.pk, name=name, realization_index=realization_index\\n-        )\\n+        .filter_by(realization_index=realization_index)\\n+        .join(ds.RecordInfo)\\n+        .filter_by(ensemble_pk=ensemble.pk, name=name)\\n         .one()\\n     )\\n     if HAS_AZURE_BLOB_STORAGE:\\n@@ -147,17 +146,16 @@ async def create_blob(\\n         pass\\n \\n     db.add(file_obj)\\n-    record_obj = ds.Record(\\n-        name=name,\\n-        record_type=ds.RecordType.file,\\n+\\n+    _create_record(\\n+        db,\\n+        ensemble,\\n+        name,\\n+        ds.RecordType.file,\\n         realization_index=realization_index,\\n         file=file_obj,\\n-        record_class=ds.RecordClass.other,\\n     )\\n \\n-    record_obj.ensemble = ensemble\\n-    db.add(record_obj)\\n-\\n \\n @router.patch(\\\"/ensembles/{ensemble_id}/records/{name}/blob\\\")\\n async def finalize_blob(\\n@@ -175,9 +173,9 @@ async def finalize_blob(\\n \\n     record_obj = (\\n         db.query(ds.Record)\\n-        .filter_by(\\n-            ensemble_pk=ensemble.pk, name=name, realization_index=realization_index\\n-        )\\n+        .filter_by(realization_index=realization_index)\\n+        .join(ds.RecordInfo)\\n+        .filter_by(ensemble_pk=ensemble.pk, name=name)\\n         .one()\\n     )\\n \\n@@ -214,7 +212,6 @@ async def post_ensemble_record_matrix(\\n     name: str,\\n     realization_index: Optional[int] = None,\\n     content_type: str = Header(\\\"application/json\\\"),\\n-    record_class: Optional[str] = None,\\n     prior_id: Optional[UUID] = None,\\n     request: Request,\\n ) -> js.RecordOut:\\n@@ -227,7 +224,10 @@ async def post_ensemble_record_matrix(\\n         )\\n         content_type = \\\"text/csv\\\"\\n \\n-    if prior_id is not None and record_class != \\\"parameter\\\":\\n+    ensemble = _get_and_assert_ensemble(db, ensemble_id, name, realization_index)\\n+    is_parameter = name in ensemble.parameter_names\\n+    is_response = name in ensemble.response_names\\n+    if prior_id is not None and not is_parameter:\\n         raise HTTPException(\\n             status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\\n             detail={\\n@@ -238,7 +238,7 @@ async def post_ensemble_record_matrix(\\n                 \\\"prior_id\\\": str(prior_id),\\n             },\\n         )\\n-    ensemble = _get_and_assert_ensemble(db, ensemble_id, name, realization_index)\\n+\\n     labels = None\\n     prior = (\\n         (\\n@@ -283,13 +283,9 @@ async def post_ensemble_record_matrix(\\n                 \\\"realization_index\\\": realization_index,\\n             },\\n         )\\n-    if not record_class:\\n-        record_class_enum = ds.RecordClass.other\\n-    else:\\n-        record_class_enum = ds.RecordClass.__members__[record_class]\\n \\n     # Require that the dimensionality of an ensemble-wide parameter matrix is at least 2\\n-    if realization_index is None and record_class_enum == ds.RecordClass.parameter:\\n+    if realization_index is None and is_parameter:\\n         if content.ndim <= 1:\\n             raise HTTPException(\\n                 status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\\n@@ -305,18 +301,22 @@ async def post_ensemble_record_matrix(\\n     matrix_obj = ds.F64Matrix(content=content.tolist(), labels=labels)\\n     db.add(matrix_obj)\\n \\n-    record_obj = ds.Record(\\n-        name=name,\\n-        record_type=ds.RecordType.float_vector,\\n+    record_class = ds.RecordClass.other\\n+    if is_parameter:\\n+        record_class = ds.RecordClass.parameter\\n+    if is_response:\\n+        record_class = ds.RecordClass.response\\n+\\n+    return _create_record(\\n+        db,\\n+        ensemble,\\n+        name,\\n+        ds.RecordType.f64_matrix,\\n+        record_class,\\n+        prior,\\n         f64_matrix=matrix_obj,\\n         realization_index=realization_index,\\n-        record_class=record_class_enum,\\n-        prior=prior,\\n     )\\n-    record_obj.ensemble = ensemble\\n-    db.add(record_obj)\\n-    db.commit()\\n-    return record_obj\\n \\n \\n @router.put(\\\"/ensembles/{ensemble_id}/records/{name}/metadata\\\")\\n@@ -558,10 +558,9 @@ async def get_ensemble_record(\\n             bundle = _get_ensemble_record(db, ensemble_id, name)\\n \\n             # Only parameter records can be \\\"up-casted\\\" to ensemble-wide\\n-            if (\\n-                bundle.record_type != ds.RecordType.float_vector\\n-                or bundle.record_class != ds.RecordClass.parameter\\n-            ):\\n+            is_matrix = bundle.record_info.record_type == ds.RecordType.f64_matrix\\n+            is_parameter = name in bundle.record_info.ensemble.parameter_names\\n+            if not is_matrix or not is_parameter:\\n                 raise exc\\n     return await _get_record_data(bundle, accept, realization_index)\\n \\n@@ -571,7 +570,7 @@ async def get_ensemble_parameters(\\n     *, db: Session = Depends(get_db), ensemble_id: UUID\\n ) -> List[str]:\\n     ensemble = db.query(ds.Ensemble).filter_by(id=ensemble_id).one()\\n-    return ensemble.inputs\\n+    return ensemble.parameter_names\\n \\n \\n @router.get(\\n@@ -579,18 +578,22 @@ async def get_ensemble_parameters(\\n )\\n async def get_ensemble_records(\\n     *, db: Session = Depends(get_db), ensemble_id: UUID\\n-) -> Mapping[str, js.RecordOut]:\\n-    ensemble = db.query(ds.Ensemble).filter_by(id=ensemble_id).one()\\n+) -> Mapping[str, ds.Record]:\\n     return {\\n-        rec.name: js.RecordOut(id=rec.id, name=rec.name, metadata=rec.metadata_dict)\\n-        for rec in ensemble.records\\n+        rec.name: rec\\n+        for rec in (\\n+            db.query(ds.Record)\\n+            .join(ds.RecordInfo)\\n+            .join(ds.Ensemble)\\n+            .filter_by(id=ensemble_id)\\n+            .all()\\n+        )\\n     }\\n \\n \\n @router.get(\\\"/records/{record_id}\\\", response_model=js.RecordOut)\\n-async def get_record(*, db: Session = Depends(get_db), record_id: UUID) -> js.RecordOut:\\n-    rec = db.query(ds.Record).filter_by(id=record_id).one()\\n-    return js.RecordOut(id=rec.id, name=rec.name, metadata=rec.metadata_dict)\\n+async def get_record(*, db: Session = Depends(get_db), record_id: UUID) -> ds.Record:\\n+    return db.query(ds.Record).filter_by(id=record_id).one()\\n \\n \\n @router.get(\\\"/records/{record_id}/data\\\")\\n@@ -615,12 +618,17 @@ async def get_record_data(\\n )\\n def get_ensemble_responses(\\n     *, db: Session = Depends(get_db), ensemble_id: UUID\\n-) -> Mapping[str, js.RecordOut]:\\n-    ensemble = db.query(ds.Ensemble).filter_by(id=ensemble_id).one()\\n+) -> Mapping[str, ds.Record]:\\n     return {\\n-        rec.name: js.RecordOut(id=rec.id, name=rec.name, metadata=rec.metadata_dict)\\n-        for rec in ensemble.records\\n-        if rec.record_class == ds.RecordClass.response\\n+        rec.name: rec\\n+        for rec in (\\n+            db.query(ds.Record)\\n+            .join(ds.RecordInfo)\\n+            .filter_by(record_class=ds.RecordClass.response)\\n+            .join(ds.Ensemble)\\n+            .filter_by(id=ensemble_id)\\n+            .all()\\n+        )\\n     }\\n \\n \\n@@ -629,12 +637,11 @@ def _get_ensemble_record(db: Session, ensemble_id: UUID, name: str) -> ds.Record\\n         ensemble = db.query(ds.Ensemble).filter_by(id=ensemble_id).one()\\n         return (\\n             db.query(ds.Record)\\n-            .filter(\\n-                sa.and_(\\n-                    ds.Record.ensemble_pk == ensemble.pk,\\n-                    ds.Record.name == name,\\n-                    ds.Record.realization_index == None,\\n-                )\\n+            .filter_by(realization_index=None)\\n+            .join(ds.RecordInfo)\\n+            .filter_by(\\n+                ensemble_pk=ensemble.pk,\\n+                name=name,\\n             )\\n             .one()\\n         )\\n@@ -656,12 +663,11 @@ def _get_forward_model_record(\\n         ensemble = db.query(ds.Ensemble).filter_by(id=ensemble_id).one()\\n         return (\\n             db.query(ds.Record)\\n-            .filter(\\n-                sa.and_(\\n-                    ds.Record.ensemble_pk == ensemble.pk,\\n-                    ds.Record.name == name,\\n-                    ds.Record.realization_index == realization_index,\\n-                )\\n+            .filter_by(realization_index=realization_index)\\n+            .join(ds.RecordInfo)\\n+            .filter_by(\\n+                ensemble_pk=ensemble.pk,\\n+                name=name,\\n             )\\n             .one()\\n         )\\n@@ -684,7 +690,11 @@ def _get_and_assert_ensemble(\\n     \\\"\\\"\\\"\\n     ensemble = db.query(ds.Ensemble).filter_by(id=ensemble_id).one()\\n \\n-    q = db.query(ds.Record).filter_by(ensemble_pk=ensemble.pk, name=name)\\n+    q = (\\n+        db.query(ds.Record)\\n+        .join(ds.RecordInfo)\\n+        .filter_by(ensemble_pk=ensemble.pk, name=name)\\n+    )\\n     if realization_index is not None:\\n         if realization_index not in range(ensemble.size) and ensemble.size != -1:\\n             raise HTTPException(\\n@@ -720,8 +730,8 @@ def _get_and_assert_ensemble(\\n async def _get_record_data(\\n     record: ds.Record, accept: Optional[str], realization_index: Optional[int] = None\\n ) -> Response:\\n-    type_ = record.record_type\\n-    if type_ == ds.RecordType.float_vector:\\n+    type_ = record.record_info.record_type\\n+    if type_ == ds.RecordType.f64_matrix:\\n         if realization_index is None:\\n             content = record.f64_matrix.content\\n         else:\\n@@ -782,3 +792,65 @@ async def chunk_generator() -> AsyncGenerator[bytes, None]:\\n     raise NotImplementedError(\\n         f\\\"Getting record data for type {type_} and Accept header {accept} not implemented\\\"\\n     )\\n+\\n+\\n+def _create_record(\\n+    db: Session,\\n+    ensemble: ds.Ensemble,\\n+    name: str,\\n+    record_type: ds.RecordType,\\n+    record_class: ds.RecordClass = ds.RecordClass.other,\\n+    prior: Optional[ds.Prior] = None,\\n+    **kwargs: Any,\\n+) -> ds.Record:\\n+    record_info = ds.RecordInfo(\\n+        ensemble=ensemble,\\n+        name=name,\\n+        record_class=record_class,\\n+        record_type=record_type,\\n+        prior=prior,\\n+    )\\n+    record = ds.Record(record_info=record_info, **kwargs)\\n+\\n+    nested = db.begin_nested()\\n+    try:\\n+        db.add(record)\\n+        db.commit()\\n+    except IntegrityError:\\n+        # Assuming this is a UNIQUE constraint failure due to an existing\\n+        # record_info with the same name and ensemble. Try to fetch the\\n+        # record_info\\n+        nested.rollback()\\n+        old_record_info = (\\n+            db.query(ds.RecordInfo).filter_by(ensemble=ensemble, name=name).one()\\n+        )\\n+\\n+        # Check that the parameters match\\n+        if record_info.record_class != old_record_info.record_class:\\n+            raise HTTPException(\\n+                status_code=status.HTTP_409_CONFLICT,\\n+                detail={\\n+                    \\\"error\\\": \\\"Record class of new record does not match previous record class\\\",\\n+                    \\\"new_record_class\\\": str(record_info.record_class),\\n+                    \\\"old_record_class\\\": str(old_record_info.record_class),\\n+                    \\\"name\\\": name,\\n+                    \\\"ensemble_id\\\": str(ensemble.id),\\n+                },\\n+            )\\n+        if record_info.record_type != old_record_info.record_type:\\n+            raise HTTPException(\\n+                status_code=status.HTTP_409_CONFLICT,\\n+                detail={\\n+                    \\\"error\\\": \\\"Record type of new record does not match previous record type\\\",\\n+                    \\\"new_record_type\\\": str(record_info.record_type),\\n+                    \\\"old_record_type\\\": str(old_record_info.record_type),\\n+                    \\\"name\\\": name,\\n+                    \\\"ensemble_id\\\": str(ensemble.id),\\n+                },\\n+            )\\n+\\n+        record = ds.Record(record_info=old_record_info, **kwargs)\\n+        db.add(record)\\n+        db.commit()\\n+\\n+    return record\\n\",\"diff --git a/ert_storage/endpoints/responses.py b/ert_storage/endpoints/responses.py\\nindex 7eaa1d72..8374d4d1 100644\\n--- a/ert_storage/endpoints/responses.py\\n+++ b/ert_storage/endpoints/responses.py\\n@@ -19,12 +19,13 @@ async def get_ensemble_response_dataframe(\\n     ensemble = db.query(ds.Ensemble).filter_by(id=ensemble_id).one()\\n     records = (\\n         db.query(ds.Record)\\n+        .filter(ds.Record.realization_index != None)\\n+        .join(ds.RecordInfo)\\n         .filter_by(\\n             ensemble_pk=ensemble.pk,\\n             name=response_name,\\n             record_class=ds.RecordClass.response,\\n         )\\n-        .filter(ds.Record.realization_index != None)\\n     ).all()\\n     df_list = []\\n     for record in records:\\n@@ -39,5 +40,5 @@ async def get_ensemble_response_dataframe(\\n \\n     return Response(\\n         content=pd.concat(df_list, axis=0).to_csv().encode(),\\n-        media_type=\\\"application/csv\\\",\\n+        media_type=\\\"text/csv\\\",\\n     )\\n\",\"diff --git a/ert_storage/graphql/ensembles.py b/ert_storage/graphql/ensembles.py\\nindex 3d2ca408..a2f912d2 100644\\n--- a/ert_storage/graphql/ensembles.py\\n+++ b/ert_storage/graphql/ensembles.py\\n@@ -1,4 +1,4 @@\\n-from typing import Iterable, List, Optional, TYPE_CHECKING\\n+from typing import List, Iterable, Optional, TYPE_CHECKING\\n import graphene as gr\\n from graphene_sqlalchemy.utils import get_session\\n \\n@@ -21,7 +21,7 @@ class Meta:\\n         gr.List(\\\"ert_storage.graphql.responses.Response\\\"),\\n         names=gr.Argument(gr.List(gr.String), required=False, default_value=None),\\n     )\\n-    unique_responses = gr.List(\\\"ert_storage.graphql.responses.Response\\\")\\n+    unique_responses = gr.List(\\\"ert_storage.graphql.unique_responses.UniqueResponse\\\")\\n \\n     parameters = gr.List(\\\"ert_storage.graphql.parameters.Parameter\\\")\\n \\n@@ -40,33 +40,33 @@ def resolve_parent_ensemble(\\n \\n     def resolve_unique_responses(\\n         root: ds.Ensemble, info: \\\"ResolveInfo\\\"\\n-    ) -> Iterable[ds.Record]:\\n+    ) -> Iterable[ds.RecordInfo]:\\n         session = info.context[\\\"session\\\"]  # type: ignore\\n-        response_names = [\\n-            x[0]\\n-            for x in session.query(ds.Record.name)\\n-            .filter_by(ensemble_pk=root.pk, record_class=ds.RecordClass.response)\\n-            .filter(ds.Record.realization_index != None)\\n-            .distinct()\\n-        ]\\n-        return [\\n-            root.records.filter_by(name=response_name)[0]\\n-            for response_name in response_names\\n-        ]\\n+        return root.record_infos.filter_by(record_class=ds.RecordClass.response)\\n \\n     def resolve_responses(\\n         root: ds.Ensemble, info: \\\"ResolveInfo\\\", names: Optional[Iterable[str]] = None\\n     ) -> Iterable[ds.Record]:\\n-        if names is None:\\n-            return root.records.filter_by(record_class=ds.RecordClass.response)\\n-        return root.records.filter_by(record_class=ds.RecordClass.response).filter(\\n-            ds.Record.name.in_(names)\\n+        session = info.context[\\\"session\\\"]  # type: ignore\\n+        q = (\\n+            session.query(ds.Record)\\n+            .join(ds.RecordInfo)\\n+            .filter_by(ensemble=root, record_class=ds.RecordClass.response)\\n         )\\n+        if names is not None:\\n+            q = q.filter(ds.RecordInfo.name.in_(names))\\n+        return q.all()\\n \\n     def resolve_parameters(\\n         root: ds.Ensemble, info: \\\"ResolveInfo\\\"\\n-    ) -> Iterable[ds.Prior]:\\n-        return root.parameters\\n+    ) -> Iterable[ds.Record]:\\n+        session = info.context[\\\"session\\\"]  # type: ignore\\n+        return (\\n+            session.query(ds.Record)\\n+            .join(ds.RecordInfo)\\n+            .filter_by(ensemble=root, record_class=ds.RecordClass.parameter)\\n+            .all()\\n+        )\\n \\n \\n class CreateEnsemble(SQLAlchemyMutation):\\n@@ -74,14 +74,14 @@ class Meta:\\n         model = ds.Ensemble\\n \\n     class Arguments:\\n-        parameters = gr.List(gr.String)\\n+        parameter_names = gr.List(gr.String)\\n         size = gr.Int()\\n \\n     @staticmethod\\n     def mutate(\\n         root: Optional[\\\"Experiment\\\"],\\n         info: \\\"ResolveInfo\\\",\\n-        parameters: List[str],\\n+        parameter_names: List[str],\\n         size: int,\\n         experiment_id: Optional[str] = None,\\n     ) -> ds.Ensemble:\\n@@ -94,7 +94,12 @@ def mutate(\\n         else:\\n             raise ValueError(\\\"ID is required\\\")\\n \\n-        ensemble = ds.Ensemble(inputs=parameters, experiment=experiment, size=size)\\n+        ensemble = ds.Ensemble(\\n+            parameter_names=parameter_names,\\n+            response_names=[],\\n+            experiment=experiment,\\n+            size=size,\\n+        )\\n \\n         db.add(ensemble)\\n         db.commit()\\n\",\"diff --git a/ert_storage/graphql/parameters.py b/ert_storage/graphql/parameters.py\\nindex 30b22288..79e0046a 100644\\n--- a/ert_storage/graphql/parameters.py\\n+++ b/ert_storage/graphql/parameters.py\\n@@ -15,8 +15,12 @@ class Parameter(SQLAlchemyObjectType):\\n     class Meta:\\n         model = ds.Record\\n \\n+    name = gr.String()\\n     prior = gr.JSONString()\\n \\n+    def resolve_name(root: ds.Record, info: \\\"ResolveInfo\\\") -> str:\\n+        return root.name\\n+\\n     def resolve_prior(root: ds.Record, info: \\\"ResolveInfo\\\") -> Optional[dict]:\\n-        prior = root.prior\\n+        prior = root.record_info.prior\\n         return prior_to_dict(prior) if prior is not None else None\\n\",\"diff --git a/ert_storage/graphql/responses.py b/ert_storage/graphql/responses.py\\nindex 71cd727b..8154009a 100644\\n--- a/ert_storage/graphql/responses.py\\n+++ b/ert_storage/graphql/responses.py\\n@@ -12,3 +12,8 @@\\n class Response(SQLAlchemyObjectType):\\n     class Meta:\\n         model = ds.Record\\n+\\n+    name = gr.String()\\n+\\n+    def resolve_name(root: ds.Record, info: \\\"ResolveInfo\\\") -> str:\\n+        return root.name\\n\",\"diff --git a/ert_storage/graphql/unique_responses.py b/ert_storage/graphql/unique_responses.py\\nnew file mode 100644\\nindex 00000000..4d8acac5\\n--- /dev/null\\n+++ b/ert_storage/graphql/unique_responses.py\\n@@ -0,0 +1,13 @@\\n+from typing import TYPE_CHECKING\\n+\\n+from ert_storage.ext.graphene_sqlalchemy import SQLAlchemyObjectType\\n+from ert_storage import database_schema as ds\\n+\\n+\\n+if TYPE_CHECKING:\\n+    from graphql.execution.base import ResolveInfo\\n+\\n+\\n+class UniqueResponse(SQLAlchemyObjectType):\\n+    class Meta:\\n+        model = ds.RecordInfo\\n\",\"diff --git a/ert_storage/json_schema/ensemble.py b/ert_storage/json_schema/ensemble.py\\nindex c5d6b93f..d1f4fba3 100644\\n--- a/ert_storage/json_schema/ensemble.py\\n+++ b/ert_storage/json_schema/ensemble.py\\n@@ -1,23 +1,35 @@\\n from uuid import UUID\\n-from typing import List, Optional, Any\\n-from pydantic import BaseModel\\n+from typing import List, Optional, Any, Mapping\\n+from pydantic import BaseModel, Field, root_validator\\n \\n \\n class _Ensemble(BaseModel):\\n-    metadata: Optional[Any]\\n     size: int\\n+    parameter_names: List[str]\\n+    response_names: List[str]\\n \\n \\n class EnsembleIn(_Ensemble):\\n-    parameters: List[str]\\n     update_id: Optional[UUID] = None\\n+    metadata: Optional[Any]\\n+\\n+    @root_validator\\n+    def _check_names_no_overlap(cls, values: Mapping[str, Any]) -> Mapping[str, Any]:\\n+        \\\"\\\"\\\"\\n+        Verify that `parameter_names` and `response_names` don't overlap. Ie, no\\n+        record can be both a parameter and a response.\\n+        \\\"\\\"\\\"\\n+        if not set(values[\\\"parameter_names\\\"]).isdisjoint(set(values[\\\"response_names\\\"])):\\n+            raise ValueError(\\\"parameters and responses cannot have a name in common\\\")\\n+        return values\\n \\n \\n class EnsembleOut(_Ensemble):\\n     id: UUID\\n-    children: List[UUID]\\n-    parent: Optional[UUID] = None\\n+    children: List[UUID] = Field(alias=\\\"child_ensemble_ids\\\")\\n+    parent: Optional[UUID] = Field(alias=\\\"parent_ensemble_id\\\")\\n     experiment_id: Optional[UUID] = None\\n+    metadata: Mapping[str, Any] = Field(alias=\\\"metadata_dict\\\")\\n \\n     class Config:\\n         orm_mode = True\\n\",\"diff --git a/ert_storage/json_schema/record.py b/ert_storage/json_schema/record.py\\nindex 0fa29e56..646608dd 100644\\n--- a/ert_storage/json_schema/record.py\\n+++ b/ert_storage/json_schema/record.py\\n@@ -1,6 +1,6 @@\\n from uuid import UUID\\n from typing import Any, Mapping\\n-from pydantic import BaseModel\\n+from pydantic import BaseModel, Field\\n \\n \\n class _Record(BaseModel):\\n@@ -10,7 +10,7 @@ class _Record(BaseModel):\\n class RecordOut(_Record):\\n     id: UUID\\n     name: str\\n-    _metadata: Mapping[str, Any]\\n+    metadata: Mapping[str, Any] = Field(alias=\\\"metadata_dict\\\")\\n \\n     class Config:\\n         orm_mode = True\\n\"]", "test_patch": "[\"diff --git a/ert_storage/testing/testclient.py b/ert_storage/testing/testclient.py\\nindex f2c43612..db497f93 100644\\n--- a/ert_storage/testing/testclient.py\\n+++ b/ert_storage/testing/testclient.py\\n@@ -235,17 +235,13 @@ def testclient_factory() -> Generator[_TestClient, None, None]:\\n         print(\\\"Using in-memory SQLite database for tests\\\")\\n \\n     if os.getenv(\\\"ERT_STORAGE_NO_ROLLBACK\\\", \\\"\\\"):\\n-        print(\\n-            \\\"Environment variable 'ERT_STORAGE_NO_ROLLBACK' not set or empty.\\\\n\\\"\\n-            \\\"Will perform rollbacks after every test.\\\"\\n-        )\\n-        rollback = False\\n-    else:\\n         print(\\n             \\\"Environment variable 'ERT_STORAGE_NO_ROLLBACK' is set.\\\\n\\\"\\n             \\\"Will keep data in database.\\\"\\n         )\\n         rollback = True\\n+    else:\\n+        rollback = False\\n \\n     from ert_storage.app import app\\n     from ert_storage.graphql import schema\\n\",\"diff --git a/tests/integration/conftest.py b/tests/integration/conftest.py\\nindex a02cbb1d..b45191ed 100644\\n--- a/tests/integration/conftest.py\\n+++ b/tests/integration/conftest.py\\n@@ -11,12 +11,19 @@ def client(ert_storage_client):\\n \\n @pytest.fixture\\n def create_ensemble(client):\\n-    def func(experiment_id, parameters=None, update_id=None, size=-1):\\n+    def func(experiment_id, parameters=None, responses=None, update_id=None, size=-1):\\n         if parameters is None:\\n             parameters = []\\n+        if responses is None:\\n+            responses = []\\n         resp = client.post(\\n             f\\\"/experiments/{experiment_id}/ensembles\\\",\\n-            json={\\\"parameters\\\": parameters, \\\"update_id\\\": update_id, \\\"size\\\": size},\\n+            json={\\n+                \\\"parameter_names\\\": parameters,\\n+                \\\"response_names\\\": responses,\\n+                \\\"update_id\\\": update_id,\\n+                \\\"size\\\": size,\\n+            },\\n         )\\n         return str(resp.json()[\\\"id\\\"])\\n \\n@@ -34,11 +41,9 @@ def func(name, priors={}):\\n \\n @pytest.fixture\\n def simple_ensemble(create_ensemble, create_experiment, request):\\n-    def func(parameters=None, update_id=None, size=-1):\\n+    def func(parameters=None, responses=None, update_id=None, size=-1):\\n         exp_id = create_experiment(request.node.name)\\n-        ens_id = create_ensemble(\\n-            exp_id, parameters=parameters, update_id=update_id, size=size\\n-        )\\n+        ens_id = create_ensemble(exp_id, parameters, responses, update_id, size)\\n         return ens_id\\n \\n     return func\\n\",\"diff --git a/tests/integration/gql/test_ensembles.py b/tests/integration/gql/test_ensembles.py\\nindex 6af44753..a33a2951 100644\\n--- a/tests/integration/gql/test_ensembles.py\\n+++ b/tests/integration/gql/test_ensembles.py\\n@@ -7,14 +7,14 @@\\n   ensemble(id: $id) {\\n     id\\n     size\\n-    inputs\\n+    parameterNames\\n   }\\n }\\n \\\"\\\"\\\"\\n \\n CREATE_ENSEMBLE = \\\"\\\"\\\"\\\\\\n mutation create($experimentId: ID!, $size: Int!, $params: [String]) {\\n-  createEnsemble(experimentId: $experimentId, size: $size, parameters: $params) {\\n+  createEnsemble(experimentId: $experimentId, size: $size, parameterNames: $params) {\\n     id\\n   }\\n }\\n@@ -27,7 +27,7 @@ def test_get_ensemble(client, simple_ensemble):\\n     r = client.gql_execute(GET_ENSEMBLE, variable_values={\\\"id\\\": eid})\\n \\n     assert r[\\\"data\\\"][\\\"ensemble\\\"][\\\"id\\\"] == str(eid)\\n-    assert r[\\\"data\\\"][\\\"ensemble\\\"][\\\"inputs\\\"] == eparams\\n+    assert r[\\\"data\\\"][\\\"ensemble\\\"][\\\"parameterNames\\\"] == eparams\\n \\n \\n def test_create_ensemble(client, create_experiment):\\n@@ -48,7 +48,7 @@ def test_create_ensemble(client, create_experiment):\\n     r = client.gql_execute(GET_ENSEMBLE, variable_values={\\\"id\\\": eid})\\n \\n     assert r[\\\"data\\\"][\\\"ensemble\\\"][\\\"id\\\"] == eid\\n-    assert r[\\\"data\\\"][\\\"ensemble\\\"][\\\"inputs\\\"] == eparams\\n+    assert r[\\\"data\\\"][\\\"ensemble\\\"][\\\"parameterNames\\\"] == eparams\\n     assert r[\\\"data\\\"][\\\"ensemble\\\"][\\\"size\\\"] == ensemble_size\\n \\n \\n\",\"diff --git a/tests/integration/gql/test_experiments.py b/tests/integration/gql/test_experiments.py\\nindex 4771d77d..98ff4cd2 100644\\n--- a/tests/integration/gql/test_experiments.py\\n+++ b/tests/integration/gql/test_experiments.py\\n@@ -8,7 +8,7 @@\\n     id\\n     ensembles {\\n       id\\n-      inputs\\n+      parameterNames\\n     }\\n   }\\n }\\n@@ -37,7 +37,7 @@\\n mutation($name: String, $size: Int!, $params: [String!]) {\\n   createExperiment(name: $name) {\\n     id\\n-    createEnsemble(size: $size, parameters: $params) {\\n+    createEnsemble(size: $size, parameterNames: $params) {\\n       id\\n     }\\n   }\\n@@ -99,7 +99,7 @@ def test_create_experiment_with_ensemble(client):\\n     assert r[\\\"data\\\"][\\\"experiment\\\"][\\\"id\\\"] == eid\\n     assert r[\\\"data\\\"][\\\"experiment\\\"][\\\"name\\\"] == ename\\n     assert len(r[\\\"data\\\"][\\\"experiment\\\"][\\\"ensembles\\\"]) == 1\\n-    assert r[\\\"data\\\"][\\\"experiment\\\"][\\\"ensembles\\\"][0][\\\"inputs\\\"] == eparams\\n+    assert r[\\\"data\\\"][\\\"experiment\\\"][\\\"ensembles\\\"][0][\\\"parameterNames\\\"] == eparams\\n \\n \\n def rand_name():\\n\",\"diff --git a/tests/integration/gql/test_priors.py b/tests/integration/gql/test_priors.py\\nindex 1b5c1744..4ec0af87 100644\\n--- a/tests/integration/gql/test_priors.py\\n+++ b/tests/integration/gql/test_priors.py\\n@@ -46,7 +46,7 @@ def test_get_prior_for_parameters(client, create_ensemble, make_random_priors):\\n     assert NUM_PARAMS_W_PRIORS < NUM_PRIORS\\n \\n     epriors = {rand_name(): prior.dict() for prior in make_random_priors(NUM_PRIORS)}\\n-    eparams = [rand_name() for _ in range(NUM_PARAMS_W_PRIORS)]\\n+    eparams = [rand_name() for _ in range(NUM_PARAMS)]\\n \\n     exp = client.post(\\n         \\\"/experiments\\\", json={\\\"name\\\": rand_name(), \\\"priors\\\": epriors}\\n@@ -61,7 +61,7 @@ def test_get_prior_for_parameters(client, create_ensemble, make_random_priors):\\n     ):\\n         client.post(\\n             f\\\"/ensembles/{ensid}/records/{param}/matrix\\\",\\n-            params={\\\"record_class\\\": \\\"parameter\\\", \\\"prior_id\\\": prior},\\n+            params={\\\"prior_id\\\": prior},\\n             json=np.random.rand(2, 3).tolist(),\\n         )\\n         param_to_prior[param] = prior_val\\n@@ -71,7 +71,6 @@ def test_get_prior_for_parameters(client, create_ensemble, make_random_priors):\\n     for _ in range(NUM_PARAMS_WO_PRIORS):\\n         resp = client.post(\\n             f\\\"/ensembles/{ensid}/records/{rand_name()}/matrix\\\",\\n-            params={\\\"record_class\\\": \\\"parameter\\\"},\\n             json=np.random.rand(2, 3).tolist(),\\n         )\\n         param_no_prior.add(resp.json()[\\\"id\\\"])\\n\",\"diff --git a/tests/integration/gql/test_responses.py b/tests/integration/gql/test_responses.py\\nindex a89bca8c..0e32b8d1 100644\\n--- a/tests/integration/gql/test_responses.py\\n+++ b/tests/integration/gql/test_responses.py\\n@@ -35,16 +35,16 @@\\n \\\"\\\"\\\"\\n \\n RESPONSE_NAMES = [\\n-    {\\\"name\\\": \\\"FOPR\\\"},\\n-    {\\\"name\\\": \\\"FOPT\\\"},\\n-    {\\\"name\\\": \\\"FGPT\\\"},\\n-    {\\\"name\\\": \\\"FGPR\\\"},\\n+    \\\"FOPR\\\",\\n+    \\\"FOPT\\\",\\n+    \\\"FGPT\\\",\\n+    \\\"FGPR\\\",\\n ]\\n \\n \\n def test_get_gql_response(client, create_experiment, create_ensemble):\\n     experiment_id = create_experiment(\\\"test_ensembles\\\")\\n-    ensemble_id = create_ensemble(experiment_id=experiment_id)\\n+    ensemble_id = create_ensemble(experiment_id=experiment_id, responses=RESPONSE_NAMES)\\n \\n     # 5 realizations of 8 values each\\n     matrices = np.random.rand(5, 8)\\n@@ -62,17 +62,17 @@ def test_get_gql_response(client, create_experiment, create_ensemble):\\n     for id_real in data_df:\\n         [\\n             client.post(\\n-                f\\\"/ensembles/{ensemble_id}/records/{resp_name['name']}/matrix\\\",\\n+                f\\\"/ensembles/{ensemble_id}/records/{resp_name}/matrix\\\",\\n                 data=data_df[id_real].to_csv().encode(),\\n                 headers={\\\"content-type\\\": \\\"application/x-dataframe\\\"},\\n-                params=dict(realization_index=id_real, record_class=\\\"response\\\"),\\n+                params={\\\"realization_index\\\": id_real},\\n             )\\n             for resp_name in RESPONSE_NAMES\\n         ]\\n \\n     r = client.gql_execute(GET_UNIQUE_RESPONSES, variable_values={\\\"id\\\": ensemble_id})\\n-    for response_name in RESPONSE_NAMES:\\n-        assert response_name in r[\\\"data\\\"][\\\"ensemble\\\"][\\\"uniqueResponses\\\"]\\n+    for response in r[\\\"data\\\"][\\\"ensemble\\\"][\\\"uniqueResponses\\\"]:\\n+        assert response[\\\"name\\\"] in RESPONSE_NAMES\\n \\n     # retrieve all responses and realizations\\n     r = client.gql_execute(GET_ALL_RESPONSES, variable_values={\\\"id\\\": ensemble_id})\\n@@ -80,9 +80,9 @@ def test_get_gql_response(client, create_experiment, create_ensemble):\\n     assert len(r[\\\"data\\\"][\\\"ensemble\\\"][\\\"responses\\\"]) == len(RESPONSE_NAMES) * 5\\n     for id_real, _ in enumerate(matrices):\\n         for response_name in RESPONSE_NAMES:\\n-            assert {\\\"name\\\": response_name[\\\"name\\\"], \\\"realizationIndex\\\": id_real} in r[\\n-                \\\"data\\\"\\n-            ][\\\"ensemble\\\"][\\\"responses\\\"]\\n+            assert {\\\"name\\\": response_name, \\\"realizationIndex\\\": id_real} in r[\\\"data\\\"][\\n+                \\\"ensemble\\\"\\n+            ][\\\"responses\\\"]\\n \\n     # use names attribute to retrieve only FOPR and FOPT realizations\\n     r = client.gql_execute(\\n\",\"diff --git a/tests/integration/test_experiments.py b/tests/integration/test_experiments.py\\nindex 21cf92ae..d10dc902 100644\\n--- a/tests/integration/test_experiments.py\\n+++ b/tests/integration/test_experiments.py\\n@@ -93,3 +93,17 @@ def test_delete_experiment(client, create_experiment, create_ensemble):\\n     for obs in observations:\\n         resp = client.get(f\\\"/observations/{obs['id']}\\\", check_status_code=None)\\n         assert resp.status_code == status.HTTP_404_NOT_FOUND\\n+\\n+\\n+def test_create_ensemble_with_overlap(client, create_experiment):\\n+    experiment_id = create_experiment(\\\"test_ensembles\\\")\\n+\\n+    client.post(\\n+        f\\\"/experiments/{experiment_id}/ensembles\\\",\\n+        json={\\n+            \\\"size\\\": 1,\\n+            \\\"parameter_names\\\": [\\\"foo\\\", \\\"bar\\\", \\\"coeff\\\", \\\"qux\\\"],\\n+            \\\"response_names\\\": [\\\"coeff\\\", \\\"fopr\\\", \\\"fopt\\\", \\\"fgpt\\\", \\\"fgpr\\\"],\\n+        },\\n+        check_status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\\n+    )\\n\",\"diff --git a/tests/integration/test_metadata.py b/tests/integration/test_metadata.py\\nindex 3bc5e9dc..bbbe390d 100644\\n--- a/tests/integration/test_metadata.py\\n+++ b/tests/integration/test_metadata.py\\n@@ -6,7 +6,8 @@ def post_ensemble(client):\\n     resp = client.post(\\\"/experiments\\\", json={\\\"name\\\": \\\"test_metadata\\\"})\\n     exp_id = resp.json()[\\\"id\\\"]\\n     resp = client.post(\\n-        f\\\"/experiments/{exp_id}/ensembles\\\", json={\\\"parameters\\\": [], \\\"size\\\": 0}\\n+        f\\\"/experiments/{exp_id}/ensembles\\\",\\n+        json={\\\"parameter_names\\\": [], \\\"response_names\\\": [], \\\"size\\\": 0},\\n     )\\n     ens_id = resp.json()[\\\"id\\\"]\\n     return f\\\"/ensembles/{ens_id}\\\"\\n\",\"diff --git a/tests/integration/test_record_infos.py b/tests/integration/test_record_infos.py\\nnew file mode 100644\\nindex 00000000..b6cf27db\\n--- /dev/null\\n+++ b/tests/integration/test_record_infos.py\\n@@ -0,0 +1,22 @@\\n+import io\\n+import numpy\\n+from fastapi import status\\n+\\n+\\n+def test_different_record_classes(client, simple_ensemble):\\n+    ensemble_id = simple_ensemble()\\n+\\n+    # Post matrix\\n+    client.post(\\n+        f\\\"/ensembles/{ensemble_id}/records/foo/matrix\\\",\\n+        params={\\\"realization_index\\\": 0},\\n+        json=[1, 2, 3],\\n+    )\\n+\\n+    # Post file under the same name should fail\\n+    client.post(\\n+        f\\\"/ensembles/{ensemble_id}/records/foo/file\\\",\\n+        params={\\\"realization_index\\\": 1},\\n+        files={\\\"file\\\": (\\\"foo\\\", io.BytesIO(b\\\"foo\\\"), \\\"application/octet-stream\\\")},\\n+        check_status_code=status.HTTP_409_CONFLICT,\\n+    )\\n\",\"diff --git a/tests/integration/test_records.py b/tests/integration/test_records.py\\nindex 86a8bace..a658910d 100644\\n--- a/tests/integration/test_records.py\\n+++ b/tests/integration/test_records.py\\n@@ -84,7 +84,6 @@ def test_ensemble_wide_parameters(client, simple_ensemble):\\n     client.post(\\n         f\\\"/ensembles/{ensemble_id}/records/coeffs/matrix\\\",\\n         data=f\\\"{PARAMETERS}\\\",\\n-        params={\\\"record_class\\\": \\\"parameter\\\"},\\n     )\\n \\n     # Fetch as ensemble-wide parameters\\n@@ -116,7 +115,6 @@ def test_ensemble_wide_parameters_dataframe(client, simple_ensemble, mimetype):\\n     client.post(\\n         f\\\"/ensembles/{ensemble_id}/records/coeffs/matrix\\\",\\n         data=data.to_csv(),\\n-        params={\\\"record_class\\\": \\\"parameter\\\"},\\n         headers={\\\"content-type\\\": mimetype},\\n     )\\n \\n@@ -157,7 +155,6 @@ def test_ensemble_wide_parameters_1d(client, simple_ensemble):\\n     client.post(\\n         f\\\"/ensembles/{ensemble_id}/records/coeffs/matrix\\\",\\n         json=[1, 2, 3, 4, 5],\\n-        params={\\\"record_class\\\": \\\"parameter\\\"},\\n         check_status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\\n     )\\n \\n@@ -383,20 +380,17 @@ def _generate_blob_chunks():\\n \\n \\n def test_responses(client, simple_ensemble):\\n-    ensemble_id = simple_ensemble()\\n+    ensemble_id = simple_ensemble(parameters=[\\\"rec2\\\"], responses=[\\\"rec3\\\"])\\n     records = [\\n-        (\\\"rec1\\\", \\\"[1, 2, 3, 4, 5]\\\", \\\"other\\\"),\\n-        (\\\"rec2\\\", \\\"[[4, 3, 2, 1]]\\\", \\\"parameter\\\"),\\n-        (\\\"rec3\\\", \\\"[[1, 2], [4, 5]]\\\", \\\"response\\\"),\\n-        (\\\"rec4\\\", \\\"[[1, 2], [4, 5]]\\\", None),\\n+        (\\\"rec1\\\", \\\"[1, 2, 3, 4, 5]\\\"),\\n+        (\\\"rec2\\\", \\\"[[4, 3, 2, 1]]\\\"),\\n+        (\\\"rec3\\\", \\\"[[1, 2], [4, 5]]\\\"),\\n+        (\\\"rec4\\\", \\\"[[1, 2], [4, 5]]\\\"),\\n     ]\\n-    for name, data, record_class in records:\\n+    for name, data in records:\\n         client.post(\\n             f\\\"/ensembles/{ensemble_id}/records/{name}/matrix\\\",\\n             data=data,\\n-            params={\\n-                \\\"record_class\\\": record_class,\\n-            },\\n         )\\n \\n     responses = client.get(f\\\"/ensembles/{ensemble_id}/responses\\\").json()\\n\",\"diff --git a/tests/integration/test_responses.py b/tests/integration/test_responses.py\\nindex c988637c..ee6474b9 100644\\n--- a/tests/integration/test_responses.py\\n+++ b/tests/integration/test_responses.py\\n@@ -7,7 +7,7 @@\\n \\n def test_get_response_data(client, create_experiment, create_ensemble):\\n     experiment_id = create_experiment(\\\"test_ensembles\\\")\\n-    ensemble_id = create_ensemble(experiment_id=experiment_id)\\n+    ensemble_id = create_ensemble(experiment_id=experiment_id, responses=[\\\"FOPR\\\"])\\n \\n     # 5 realizations of 8 values each\\n     matrices = np.random.rand(5, 8)\\n@@ -26,8 +26,8 @@ def test_get_response_data(client, create_experiment, create_ensemble):\\n         resp = client.post(\\n             f\\\"/ensembles/{ensemble_id}/records/{response_name}/matrix\\\",\\n             data=data_df[id_real].to_csv().encode(),\\n-            headers={\\\"content-type\\\": \\\"application/x-dataframe\\\"},\\n-            params=dict(realization_index=id_real, record_class=\\\"response\\\"),\\n+            headers={\\\"content-type\\\": \\\"text/csv\\\"},\\n+            params={\\\"realization_index\\\": id_real},\\n         )\\n \\n     resp = client.get(f\\\"/ensembles/{ensemble_id}/responses/{response_name}/data\\\")\\n@@ -41,7 +41,7 @@ def test_get_response_data(client, create_experiment, create_ensemble):\\n \\n def test_get_response_data_with_nan(client, create_experiment, create_ensemble):\\n     experiment_id = create_experiment(\\\"test_ensembles\\\")\\n-    ensemble_id = create_ensemble(experiment_id=experiment_id)\\n+    ensemble_id = create_ensemble(experiment_id=experiment_id, responses=[\\\"FOPR\\\"])\\n \\n     # 5 realizations of 8 values each\\n     matrices = np.random.rand(5, 8)\\n@@ -63,8 +63,8 @@ def test_get_response_data_with_nan(client, create_experiment, create_ensemble):\\n         resp = client.post(\\n             f\\\"/ensembles/{ensemble_id}/records/{response_name}/matrix\\\",\\n             data=data_df[id_real].to_csv().encode(),\\n-            headers={\\\"content-type\\\": \\\"application/x-dataframe\\\"},\\n-            params=dict(realization_index=id_real, record_class=\\\"response\\\"),\\n+            headers={\\\"content-type\\\": \\\"text/csv\\\"},\\n+            params={\\\"realization_index\\\": id_real},\\n         )\\n \\n     resp = client.get(f\\\"/ensembles/{ensemble_id}/responses/{response_name}/data\\\")\"]", "hints_text": ""}
